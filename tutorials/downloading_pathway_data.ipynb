{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Tutorial - Downloading and Formatting Pathway Data\n",
        "author: \"Shackett\"\n",
        "date: \"May 9th 2025\"\n",
        "---\n",
        "\n",
        "This notebook provides examples for downloading pathway information from a variety of data sources and formatting the results as `sbml_dfs` objects. Since it is often not possible to download just a subset of a data source for demonstration purposes, this notebook will download and cache raw and intermediate representations of each data source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: config\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(\"INFO\")\n",
        "\n",
        "import tutorial_utils\n",
        "config = tutorial_utils.NapistuConfig(\"config.yaml\", \"downloading_pathway_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: environment\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from napistu import utils\n",
        "from napistu.ingestion import bigg\n",
        "from napistu.ingestion import psi_mi\n",
        "from napistu.ingestion import reactome\n",
        "from napistu.ingestion import string\n",
        "from napistu.ingestion import trrust\n",
        "\n",
        "def _log(text: str):\n",
        "\n",
        "    banner_str = \"====================================\\n\"\n",
        "    logger.info(f\"\\n{banner_str}{text}\\n{banner_str}\")\n",
        "\n",
        "def _log_skipped(uri: str):\n",
        "    \"\"\" Log that a step was skipped. \"\"\"\n",
        "    logger.info(f\"{uri} exists or overwrite = False\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: globals\n",
        "OVERWRITE = config.overwrite\n",
        "SPECIES = config.species\n",
        "FN_BIGG_SBML_DIR = config.artifacts[\"bigg_sbml_dir\"]\n",
        "FN_BIGG_SBML_DFS = config.artifacts[\"bigg_sbml_dfs\"]\n",
        "FN_INTACT_DIR = config.artifacts[\"intact_dir\"]\n",
        "FN_INTACT_SBML_DFS = config.artifacts[\"intact_sbml_dfs\"]\n",
        "FN_REACTOME_SBML_DIR = config.artifacts[\"reactome_sbml_dir\"]\n",
        "FN_REACTOME_SBML_DFS = config.artifacts[\"reactome_sbml_dfs\"]\n",
        "FN_STRING_ALIASES = config.artifacts[\"string_aliases\"]\n",
        "FN_STRING_INTERACTIONS = config.artifacts[\"string_interactions\"]\n",
        "FN_STRING_SBML_DFS = config.artifacts[\"string_sbml_dfs\"]\n",
        "FN_TRRUST_RAW = config.artifacts[\"trrust_raw\"]\n",
        "FN_TRRUST_SBML_DFS = config.artifacts[\"trrust_sbml_dfs\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Species Agnostic Sources\n",
        "\n",
        "These sources include pathway information which can be broadly applied to a range of species. \n",
        "\n",
        "## STRING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:napistu_data/string_interactions.txt exists or overwrite = False\n",
            "INFO:root:napistu_data/string_aliases.txt exists or overwrite = False\n",
            "INFO:root:napistu_data/string_sbml_dfs.pickle exists or overwrite = False\n"
          ]
        }
      ],
      "source": [
        "#| label: string\n",
        "\n",
        "if not utils.path_exists(FN_STRING_INTERACTIONS) or OVERWRITE:\n",
        "    _log(f\"Downloading STRING interactions to {FN_STRING_INTERACTIONS}\")\n",
        "    string.download_string(FN_STRING_INTERACTIONS, species = SPECIES)\n",
        "else:\n",
        "    _log_skipped(FN_STRING_INTERACTIONS)\n",
        "\n",
        "if not utils.path_exists(FN_STRING_ALIASES) or OVERWRITE:\n",
        "    _log(f\"Downloading STRING aliases (systematic identifiers) to {FN_STRING_ALIASES}\")\n",
        "    string.download_string_aliases(FN_STRING_ALIASES, species = SPECIES)\n",
        "else:\n",
        "    _log_skipped(FN_STRING_ALIASES)\n",
        "\n",
        "if not utils.path_exists(FN_STRING_SBML_DFS) or OVERWRITE:\n",
        "    _log(f\"Combining interactions and aliases to create the STRING sbml_dfs at {FN_STRING_SBML_DFS}\")\n",
        "\n",
        "    sbml_dfs = string.convert_string_to_sbml_dfs(\n",
        "        FN_STRING_INTERACTIONS,\n",
        "        FN_STRING_ALIASES\n",
        "    )\n",
        "    sbml_dfs.validate()\n",
        "\n",
        "    utils.save_pickle(FN_STRING_SBML_DFS, sbml_dfs)\n",
        "\n",
        "else:\n",
        "    _log_skipped(FN_STRING_SBML_DFS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Species-Biased Sources\n",
        "\n",
        "These sources inform multiple species but their focal point is a single species. Here which has additional types of data \n",
        "\n",
        "## Reactome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:napistu_data/reactome_sbmls exists or overwrite = False\n",
            "INFO:root:napistu_data/reactome_sbml_dfs.pickle exists or overwrite = False\n"
          ]
        }
      ],
      "source": [
        "#| label: reactome\n",
        "\n",
        "if not os.path.isdir(FN_REACTOME_SBML_DIR) or OVERWRITE:\n",
        "    _log(f\"Download the Reactome pan-species tar-ball and unpack to a directory of .sbml files at {FN_REACTOME_SBML_DIR}\")\n",
        "    reactome.reactome_sbml_download(FN_REACTOME_SBML_DIR, overwrite=OVERWRITE)\n",
        "else:\n",
        "    _log_skipped(FN_REACTOME_SBML_DIR)\n",
        "\n",
        "if not utils.path_exists(FN_REACTOME_SBML_DFS) or OVERWRITE:\n",
        "    _log(f\"Merging Reactome .sbml files into an sbml_dfs model at {FN_REACTOME_SBML_DFS}\")\n",
        "\n",
        "    pw_index_uri = os.path.join(FN_REACTOME_SBML_DIR, \"pw_index.tsv\")\n",
        "    sbml_dfs = reactome.construct_reactome_consensus(\n",
        "        pw_index_uri, species=SPECIES, strict=False\n",
        "    )\n",
        "    sbml_dfs.validate()\n",
        "\n",
        "    utils.save_pickle(FN_REACTOME_SBML_DFS, sbml_dfs)\n",
        "else:\n",
        "    _log_skipped(FN_REACTOME_SBML_DFS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BiGG (metabolic models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:\n",
            "====================================\n",
            "Download multiple BiGG metabolic models to napistu_data/bigg_sbmls\n",
            "====================================\n",
            "\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): bigg.ucsd.edu:80\n",
            "DEBUG:urllib3.connectionpool:http://bigg.ucsd.edu:80 \"GET /static/models/Recon3D.xml HTTP/1.1\" 200 1240856\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): bigg.ucsd.edu:80\n",
            "DEBUG:urllib3.connectionpool:http://bigg.ucsd.edu:80 \"GET /static/models/iMM1415.xml HTTP/1.1\" 200 662517\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): bigg.ucsd.edu:80\n",
            "DEBUG:urllib3.connectionpool:http://bigg.ucsd.edu:80 \"GET /static/models/iMM904.xml HTTP/1.1\" 200 310805\n",
            "INFO:root:\n",
            "====================================\n",
            "Formatting a BiGG .sbml model as a sbml_dfs model at napistu_data/bigg_sbml_dfs.pickle\n",
            "====================================\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]INFO:napistu.consensus:processing recon3D\n",
            "WARNING:napistu.ingestion.sbml:Compartment c has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment l has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment m has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment r has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment e has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment x has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment n has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment g has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.ingestion.sbml:Compartment i has empty CVterms, mapping its c_Identifiers from the Compartment dict\n",
            "WARNING:napistu.consensus:19 entries didn't possess identifiers and thus cannot be merged\n",
            "INFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\n",
            "DEBUG:napistu.utils:label is not defined in table_schema; adding a constant (1)\n",
            "WARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\n",
            "WARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\n",
            "WARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\n",
            "WARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\n",
            "WARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\n",
            "WARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\n",
            "WARNING:napistu.sbml_dfs_core:compartmentalized_species included missing c_id values\n",
            "WARNING:napistu.sbml_dfs_core:Attempting to resolve with infer_uncompartmentalized_species_location()\n",
            "INFO:napistu.sbml_dfs_core:2213 species' compartmentalization inferred\n",
            "WARNING:napistu.sbml_dfs_core:35 species compartmentalization could not be inferred from other reaction particpants. Their compartmentalization will be set to the default of c\n",
            "WARNING:napistu.sbml_dfs_core:1 sbo_terms were not defined  (N=54877)\n",
            "WARNING:napistu.sbml_dfs_core:Attempting to resolve with infer_sbo_terms()\n",
            "INFO:napistu.sbml_dfs_core:Updating 54877 reaction_species' sbo_term\n",
            "100%|██████████| 1/1 [00:08<00:00,  8.12s/it]\n",
            "INFO:napistu.sbml_dfs_core:All compartmentalized species have compartments, returning input sbml_dfs\n",
            "INFO:napistu.ontologies.renaming:Updating the following ontologies: ncbigene -> ncbi_entrez_gene\n"
          ]
        }
      ],
      "source": [
        "#| label: bigg\n",
        "\n",
        "if not os.path.isdir(FN_BIGG_SBML_DIR) or OVERWRITE:\n",
        "    _log(f\"Download multiple BiGG metabolic models to {FN_BIGG_SBML_DIR}\")\n",
        "    bigg.bigg_sbml_download(FN_BIGG_SBML_DIR, overwrite = OVERWRITE)\n",
        "else:\n",
        "    _log_skipped(FN_BIGG_SBML_DIR)\n",
        "\n",
        "if not utils.path_exists(FN_BIGG_SBML_DFS) or OVERWRITE:\n",
        "    _log(f\"Formatting a BiGG .sbml model as a sbml_dfs model at {FN_BIGG_SBML_DFS}\")\n",
        "\n",
        "    pw_index_uri = os.path.join(FN_BIGG_SBML_DIR, \"pw_index.tsv\")\n",
        "    sbml_dfs = bigg.construct_bigg_consensus(pw_index_uri, species=SPECIES)\n",
        "    sbml_dfs.validate()\n",
        "\n",
        "    utils.save_pickle(FN_BIGG_SBML_DFS, sbml_dfs)\n",
        "else:\n",
        "    _log_skipped(FN_BIGG_SBML_DFS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Species-Specific Sources\n",
        "\n",
        "## TRRUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:napistu_data/trrust.csv exists or overwrite = False\n",
            "INFO:root:\n",
            "====================================\n",
            "Processing TRRUST as sbml_dfs at napistu_data/trrust_sbml_dfs.pickle\n",
            "====================================\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1724219e is not a valid pubmed id, it did not match the regex: ^[0-9]+$ returning None\n"
          ]
        }
      ],
      "source": [
        "#| label: trrust \n",
        "\n",
        "if not utils.path_exists(FN_TRRUST_RAW) or OVERWRITE:\n",
        "    _log(f\"Downloading TRRUST to {FN_TRRUST_RAW}\")\n",
        "    trrust.download_trrust(FN_TRRUST_RAW)\n",
        "else:\n",
        "    _log_skipped(FN_TRRUST_RAW)\n",
        "\n",
        "if not utils.path_exists(FN_TRRUST_SBML_DFS) or OVERWRITE:\n",
        "    _log(f\"Processing TRRUST as sbml_dfs at {FN_TRRUST_SBML_DFS}\")\n",
        "    sbml_dfs = trrust.convert_trrust_to_sbml_dfs(FN_TRRUST_RAW)\n",
        "    sbml_dfs.validate()\n",
        "\n",
        "    utils.save_pickle(FN_TRRUST_SBML_DFS, sbml_dfs)\n",
        "else:\n",
        "    _log_skipped(FN_TRRUST_SBML_DFS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IDEA"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
