{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package in development mode if needed\n",
    "# !pip install -e '.[mcp]'\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import the MCP components\n",
    "from napistu.mcp.server import create_server, start_server\n",
    "from napistu.mcp import documentation, codebase, tutorials, execution\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"napistu\")\n",
    "\n",
    "# Helper function to run async code in Jupyter\n",
    "async def run_async(coro):\n",
    "    return await coro\n",
    "\n",
    "# Create a dummy session context for execution components\n",
    "session_context = {}\n",
    "object_registry = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.mcp.profiles import get_profile\n",
    "# define the types of assets to load\n",
    "profile = get_profile(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vy/h0gsmzyd4wq4gprq_vwwfclh0000gn/T/ipykernel_54187/3321929391.py:4: RuntimeWarning: coroutine 'start_server' was never awaited\n",
      "  live_server = start_server(mcp_server)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# register the relevant components\n",
    "mcp = create_server(profile)\n",
    "# initialize the relevant components\n",
    "live_server = start_server(mcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Settings' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = mcp_server.settings\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33menable_documentation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GITHUB/napistu/tutorials/.venv/lib/python3.11/site-packages/pydantic/main.py:989\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Settings' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "settins = mcp_server.settings\n",
    "onfig = getattr(server, \"profile_config\", {})\n",
    "config.get(\"enable_documentation\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mcp.server.transport'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmcp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserver\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamableHttpTransport\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Configure the transport with explicit parameters\u001b[39;00m\n\u001b[32m      4\u001b[39m transport = StreamableHttpTransport(host=\u001b[33m\"\u001b[39m\u001b[33mlocalhost\u001b[39m\u001b[33m\"\u001b[39m, port=\u001b[32m8765\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mcp.server.transport'"
     ]
    }
   ],
   "source": [
    "from mcp.server.transport import StreamableHttpTransport\n",
    "\n",
    "# Configure the transport with explicit parameters\n",
    "transport = StreamableHttpTransport(host=\"localhost\", port=8765)\n",
    "print(f\"Starting server with transport: {transport}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Settings(debug=False, log_level='INFO', host='0.0.0.0', port=8000, mount_path='/', sse_path='/sse', message_path='/messages/', streamable_http_path='/mcp', json_response=False, stateless_http=False, warn_on_duplicate_resources=True, warn_on_duplicate_tools=True, warn_on_duplicate_prompts=True, dependencies=[], lifespan=None, auth=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(mcp_server, \"settings\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.mcp import documentation_utils\n",
    "from napistu.mcp.codebase_utils import read_read_the_docs\n",
    "\n",
    "from napistu.mcp.constants import READMES\n",
    "from napistu.mcp.constants import NAPISTU_PY_READTHEDOCS_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/main/README.md \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Napistu\\n\\nThe Napistu project is an approach for creating and working with genome-scale mechanistic networks. Pathways of interest can be created from multiple sources (e.g., Reactome, STRING, TRRUST), aggregated across sources, and refined to add additional information. This pathway representation can then be turned into a graphical network to identify molecular neighborhoods, find paths between molecules, and to carryout network propagation.\\n\\nNapistu is an active project which we hope will be used for both simple analyses (e.g., basically replacing GSEA) as well as more complex analyses (e.g., multimodal data integration). \\n\\nWith Napistu you can:\\n\\n- Represent a range of publicly-available data sources using a common data structure, `sbml_dfs`, which is meant to faithfully encode molecular biology and biochemistry.\\n- Aggregate complementary sources into a consensus model which allows high-quality but incomplete interactions to be supported by data sources which more comprehensive yet speculative.\\n- Translate pathways models into geneome-scale graphical networks.\\n\\n**Working with Pathways**\\n\\n- Methods for visualizing pathways overlaid with experimental data.\\n- Methods for interacting with the underlying pathway networks.\\n\\nThis repository includes tutorials and documentation for the project while the following repositories contain the core packages:\\n\\n- **[napistu-py](https://github.com/napistu/napistu-py)** - Napistu Python library: the core implementations of pathway representations and network-based searches.\\n- **[napistu-r](https://github.com/napistu/napistu-r)** - Napistu R library: R-based network visualization and a few utilities called from `napitsu-py`.\\n\\nNaptisu is a rebrand and extension of [Calico Pathway Resources (CPR)](https://github.com/calico/opencpr): see [History](https://github.com/napistu/napistu/wiki/History).\\n\\n# Using Napistu\\n\\n## Tutorials\\n\\nThese tutorials are intended as stand-alone demonstrations of Napistu's core functionality. Most examples will focus on small pathways so that results can easily be reproduced by users.\\n\\n- Downloading pathway data\\n- Understanding the `sbml_dfs` format\\n- Merging networks with the `consensus` module\\n- Using the CPR Command Line Interface (CLI)\\n- Formatting `sbml_dfs` as `cpr_graph` networks\\n- Suggesting mechanisms with network approaches\\n- Adding molecule- and reaction-level information to graphs\\n- R-based network visualization\\n\\n## Examples\\n\\nWe'll include examples here of how Napistu is used in the wild to address biological questions. Stay tuned!\\n\\n## Documentation\\n\\n- For bug and issue tracking we use [Github Issues](https://github.com/napistu/napistu/issues).\\n- Napistu's core algorithms and data structures are documented on the [Napistu Wiki](https://github.com/napistu/napistu/wiki).\\n\\n# Contributing to Napistu\\n\\n- See `conventions.md` for an overview of Napistu's code conventions.\\n- Github Actions is used to test the individual R and Python repositories. Ensure that tests pass before contributing a pull request.\\n- Claude Code is used to propose fixes for straight forward issues. It is currently manually triggered:\\n\\n```bash\\n# TO DO - add environment setup directions\\ngh auth login\\n./utils/claude-pr.sh \\n```\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readmes\n",
    "readme = await run_async(documentation_utils.load_readme_content(READMES[\"napistu\"]))\n",
    "readme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/api.html \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.html#module-napistu \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.consensus.html#module-napistu.consensus \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.constants.html#module-napistu.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.html#module-napistu.gcs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.constants.html#module-napistu.gcs.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.downloads.html#module-napistu.gcs.downloads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.identifiers.html#module-napistu.identifiers \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.indices.html#module-napistu.indices \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.html#module-napistu.ingestion \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.bigg.html#module-napistu.ingestion.bigg \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.constants.html#module-napistu.ingestion.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.cpr_edgelist.html#module-napistu.ingestion.cpr_edgelist \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.identifiers_etl.html#module-napistu.ingestion.identifiers_etl \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.obo.html#module-napistu.ingestion.obo \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.psi_mi.html#module-napistu.ingestion.psi_mi \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.reactome.html#module-napistu.ingestion.reactome \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.sbml.html#module-napistu.ingestion.sbml \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.string.html#module-napistu.ingestion.string \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.trrust.html#module-napistu.ingestion.trrust \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.yeast.html#module-napistu.ingestion.yeast \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.mechanism_matching.html#module-napistu.mechanism_matching \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.html#module-napistu.modify \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.constants.html#module-napistu.modify.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.curation.html#module-napistu.modify.curation \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.gaps.html#module-napistu.modify.gaps \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.pathwayannot.html#module-napistu.modify.pathwayannot \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.uncompartmentalize.html#module-napistu.modify.uncompartmentalize \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.html#module-napistu.network \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.constants.html#module-napistu.network.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.neighborhoods.html#module-napistu.network.neighborhoods \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_create.html#module-napistu.network.net_create \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_propagation.html#module-napistu.network.net_propagation \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_utils.html#module-napistu.network.net_utils \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.paths.html#module-napistu.network.paths \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.precompute.html#module-napistu.network.precompute \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.html#module-napistu.rpy2 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.callr.html#module-napistu.rpy2.callr \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.constants.html#module-napistu.rpy2.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.netcontextr.html#module-napistu.rpy2.netcontextr \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.rids.html#module-napistu.rpy2.rids \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_core.html#module-napistu.sbml_dfs_core \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_utils.html#module-napistu.sbml_dfs_utils \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.source.html#module-napistu.source \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.utils.html#module-napistu.utils \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'napistu': {'module': 'napistu',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.html#module-napistu',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {'consensus': {'url': 'napistu.consensus.html#module-napistu.consensus',\n",
       "    'description': ''},\n",
       "   'constants': {'url': 'napistu.constants.html#module-napistu.constants',\n",
       "    'description': 'Module to contain all constants for CPR'},\n",
       "   'gcs': {'url': 'napistu.gcs.html#module-napistu.gcs', 'description': ''},\n",
       "   'identifiers': {'url': 'napistu.identifiers.html#module-napistu.identifiers',\n",
       "    'description': ''},\n",
       "   'indices': {'url': 'napistu.indices.html#module-napistu.indices',\n",
       "    'description': ''},\n",
       "   'ingestion': {'url': 'napistu.ingestion.html#module-napistu.ingestion',\n",
       "    'description': ''},\n",
       "   'mechanism_matching': {'url': 'napistu.mechanism_matching.html#module-napistu.mechanism_matching',\n",
       "    'description': ''},\n",
       "   'modify': {'url': 'napistu.modify.html#module-napistu.modify',\n",
       "    'description': ''},\n",
       "   'network': {'url': 'napistu.network.html#module-napistu.network',\n",
       "    'description': ''},\n",
       "   'rpy2': {'url': 'napistu.rpy2.html#module-napistu.rpy2', 'description': ''},\n",
       "   'sbml_dfs_core': {'url': 'napistu.sbml_dfs_core.html#module-napistu.sbml_dfs_core',\n",
       "    'description': ''},\n",
       "   'sbml_dfs_utils': {'url': 'napistu.sbml_dfs_utils.html#module-napistu.sbml_dfs_utils',\n",
       "    'description': ''},\n",
       "   'source': {'url': 'napistu.source.html#module-napistu.source',\n",
       "    'description': ''},\n",
       "   'utils': {'url': 'napistu.utils.html#module-napistu.utils',\n",
       "    'description': ''}}},\n",
       " 'napistu.consensus': {'module': 'napistu.consensus',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.consensus.html#module-napistu.consensus',\n",
       "  'functions': {'_add_consensus_sources': {'name': '_add_consensus_sources',\n",
       "    'signature': 'napistu.consensus._add_consensus_sources(new_id_table:DataFrame,agg_table_harmonized:DataFrame,lookup_table:Series,table_schema:dict,pw_index:PWIndex|None)→DataFrame',\n",
       "    'id': 'napistu.consensus._add_consensus_sources',\n",
       "    'doc': 'Add source information to the consensus table. Parameters: \\uf0c1 new_id_table: pd.DataFrame Consensus table without source information agg_table_harmonized: pd.DataFrame Original table with cluster assignments lookup_table: pd.Series Maps old IDs to new consensus IDs table_schema: dict Schema for the table pw_index: indices.PWIndex | None An index of all tables being aggregated Returns: \\uf0c1 pd.DataFrame Consensus table with source information added'},\n",
       "   '_add_entity_data': {'name': '_add_entity_data',\n",
       "    'signature': 'napistu.consensus._add_entity_data(sbml_dfs:SBML_dfs,sbml_dfs_dict:dict[str,SBML_dfs],lookup_tables:dict)→SBML_dfs',\n",
       "    'id': 'napistu.consensus._add_entity_data',\n",
       "    'doc': 'Add entity data from component models to the consensus model. Parameters: \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs The consensus model being built sbml_dfs_dict: dict[str, sbml_dfs_core.SBML_dfs] A dictionary of SBML_dfs from different models lookup_tables: dict Dictionary of lookup tables for translating between old and new entity IDs Returns: \\uf0c1 sbml_dfs_core.SBML_dfs The updated consensus model'},\n",
       "   '_check_sbml_dfs': {'name': '_check_sbml_dfs',\n",
       "    'signature': 'napistu.consensus._check_sbml_dfs(sbml_dfs:SBML_dfs,model_label:str,N_examples:int|str=5)→None',\n",
       "    'id': 'napistu.consensus._check_sbml_dfs',\n",
       "    'doc': 'Check SBML_dfs for identifiers which are associated with different entities before a merge.'},\n",
       "   '_check_sbml_dfs_dict': {'name': '_check_sbml_dfs_dict',\n",
       "    'signature': 'napistu.consensus._check_sbml_dfs_dict(sbml_dfs_dict:dict[str,SBML_dfs])→None',\n",
       "    'id': 'napistu.consensus._check_sbml_dfs_dict',\n",
       "    'doc': 'Check models in SBML_dfs for problems which can be reported up-front Parameters : sbml_dfs_dict ( dict ( pd.DataFrame ) ) – a dict of sbml_dfs models; construct_consensus_model ( primarily used as an input for ) Returns : None'},\n",
       "   '_create_cluster_identifiers': {'name': '_create_cluster_identifiers',\n",
       "    'signature': 'napistu.consensus._create_cluster_identifiers(meta_identifiers:DataFrame,indexed_cluster:Series,sbml_df:DataFrame,ind_clusters:DataFrame,table_schema:dict)→DataFrame',\n",
       "    'id': 'napistu.consensus._create_cluster_identifiers',\n",
       "    'doc': 'Create identifier objects for each cluster. Parameters : meta_identifiers ( pd.DataFrame ) – All identifiers (including those filtered out by BQB) indexed_cluster ( pd.Series ) – Maps entity indices to cluster IDs sbml_df ( pd.DataFrame ) – Original table of entities ind_clusters ( pd.DataFrame ) – Cluster assignments from graph algorithm table_schema ( dict ) – Schema for the table, used to determine the correct identifier column name Returns : Table mapping clusters to their consensus identifiers, with the identifier column named according to the schema Return type : pd.DataFrame'},\n",
       "   '_create_consensus_entities': {'name': '_create_consensus_entities',\n",
       "    'signature': 'napistu.consensus._create_consensus_entities(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:PWIndex,defining_biological_qualifiers:list[str])→tuple[dict,dict]',\n",
       "    'id': 'napistu.consensus._create_consensus_entities',\n",
       "    'doc': 'Create consensus entities for all primary tables in the model. This helper function creates consensus compartments, species, compartmentalized species,\\nreactions, and reaction species by finding shared entities across source models. Parameters: \\uf0c1 sbml_dfs_dict: dict{cpr.SBML_dfs} A dictionary of SBML_dfs from different models pw_index: indices.PWIndex An index of all tables being aggregated defining_biological_qualifiers: list[str] Biological qualifier terms that define distinct entities Returns: \\uf0c1 tuple: dict of consensus entities tables dict of lookup tables'},\n",
       "   '_create_consensus_table': {'name': '_create_consensus_table',\n",
       "    'signature': 'napistu.consensus._create_consensus_table(agg_primary_table:DataFrame,lookup_table:Series,updated_identifiers:Series,table_schema:dict)→DataFrame',\n",
       "    'id': 'napistu.consensus._create_consensus_table',\n",
       "    'doc': 'Create a consensus table with merged entities. Parameters: \\uf0c1 agg_primary_table: pd.DataFrame Table of entities lookup_table: pd.Series Lookup table mapping old IDs to new IDs updated_identifiers: pd.Series Series mapping new IDs to merged identifier objects table_schema: dict Schema for the table Returns: \\uf0c1 pd.DataFrame Consensus table with one row per unique entity'},\n",
       "   '_create_entity_consensus': {'name': '_create_entity_consensus',\n",
       "    'signature': 'napistu.consensus._create_entity_consensus(membership_lookup:DataFrame,table_schema:dict)→tuple[DataFrame,Series]',\n",
       "    'id': 'napistu.consensus._create_entity_consensus',\n",
       "    'doc': 'Create consensus entities based on membership. Parameters: \\uf0c1 membership_lookup: pd.DataFrame Table mapping entities to their member strings table_schema: dict Schema for the table Returns: \\uf0c1 tuple: Consensus entities DataFrame Lookup table mapping old IDs to new IDs'},\n",
       "   '_create_entity_lookup_table': {'name': '_create_entity_lookup_table',\n",
       "    'signature': 'napistu.consensus._create_entity_lookup_table(agg_table_harmonized:DataFrame,table_schema:dict)→Series',\n",
       "    'id': 'napistu.consensus._create_entity_lookup_table',\n",
       "    'doc': 'Create a lookup table mapping original entity IDs to new consensus IDs. Parameters: \\uf0c1 agg_table_harmonized: pd.DataFrame Table with cluster assignments for each entity table_schema: dict Schema for the table Returns: \\uf0c1 pd.Series Lookup table mapping old entity IDs to new consensus IDs'},\n",
       "   '_create_member_string': {'name': '_create_member_string',\n",
       "    'signature': 'napistu.consensus._create_member_string(x:list[str])→str',\n",
       "    'id': 'napistu.consensus._create_member_string',\n",
       "    'doc': ''},\n",
       "   '_create_membership_lookup': {'name': '_create_membership_lookup',\n",
       "    'signature': 'napistu.consensus._create_membership_lookup(agg_tbl:DataFrame,table_schema:dict)→DataFrame',\n",
       "    'id': 'napistu.consensus._create_membership_lookup',\n",
       "    'doc': 'Create a lookup table for entity membership. Parameters: \\uf0c1 agg_tbl: pd.DataFrame Table with member information table_schema: dict Schema for the table Returns: \\uf0c1 pd.DataFrame Lookup table mapping entity IDs to member strings'},\n",
       "   '_filter_identifiers_by_qualifier': {'name': '_filter_identifiers_by_qualifier',\n",
       "    'signature': 'napistu.consensus._filter_identifiers_by_qualifier(meta_identifiers:DataFrame,defining_biological_qualifiers:list[str])→DataFrame',\n",
       "    'id': 'napistu.consensus._filter_identifiers_by_qualifier',\n",
       "    'doc': 'Filter identifiers to only include those with specific biological qualifiers. Parameters: \\uf0c1 meta_identifiers: pd.DataFrame Table of identifiers defining_biological_qualifiers: list[str] List of biological qualifier types to keep Returns: \\uf0c1 pd.DataFrame Filtered identifiers'},\n",
       "   '_handle_entries_without_identifiers': {'name': '_handle_entries_without_identifiers',\n",
       "    'signature': 'napistu.consensus._handle_entries_without_identifiers(sbml_df:DataFrame,valid_identifiers:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.consensus._handle_entries_without_identifiers',\n",
       "    'doc': 'Handle entities that don’t have identifiers by adding dummy identifiers. Parameters: \\uf0c1 sbml_df: pd.DataFrame Original table of entities valid_identifiers: pd.DataFrame Table of identifiers that passed filtering Returns: \\uf0c1 pd.DataFrame Valid identifiers with dummy entries added'},\n",
       "   '_merge_entity_data_create_consensus': {'name': '_merge_entity_data_create_consensus',\n",
       "    'signature': 'napistu.consensus._merge_entity_data_create_consensus(entity_data_dict:dict,lookup_table:Series,entity_schema:dict,an_entity_data_type:str,table:str)→DataFrame',\n",
       "    'id': 'napistu.consensus._merge_entity_data_create_consensus',\n",
       "    'doc': 'Merge Entity Data - Report Mismatches Report cases where a single “new” id is associated with multiple different values of entity_var Args entity_data_dict (dict): dictionary containing all model’s “an_entity_data_type” dictionaries\\nlookup_table (pd.Series): a series where the index is an old model and primary key and the value is the new consensus id entity_schema (dict): schema for “table”\\nan_entity_data_type (str): data_type from species/reactions_data in entity_data_dict\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns : consensus_entity_data (pd.DataFrame) table where index is primary key of “table” and values are all distinct annotations from “an_entity_data_type”.'},\n",
       "   '_merge_entity_data_report_mismatches': {'name': '_merge_entity_data_report_mismatches',\n",
       "    'signature': 'napistu.consensus._merge_entity_data_report_mismatches(combined_entity_data:DataFrame,entity_schema:dict,an_entity_data_type:str,table:str)→None',\n",
       "    'id': 'napistu.consensus._merge_entity_data_report_mismatches',\n",
       "    'doc': 'Merge Entity Data - Report Mismatches Report cases where a single “new” id is associated with multiple different values of entity_var Args combined_entity_data (pd.DataFrame): indexed by table primary key containing all data from “an_entity_data_type” entity_schema (dict): schema for “table”\\nan_entity_data_type (str): data_type from species/reactions_data in combined_entity_data\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns : None'},\n",
       "   '_merge_entity_identifiers': {'name': '_merge_entity_identifiers',\n",
       "    'signature': 'napistu.consensus._merge_entity_identifiers(agg_primary_table:DataFrame,lookup_table:Series,table_schema:dict)→Series',\n",
       "    'id': 'napistu.consensus._merge_entity_identifiers',\n",
       "    'doc': 'Merge identifiers from multiple entities. Parameters: \\uf0c1 agg_primary_table: pd.DataFrame Table of entities lookup_table: pd.Series Lookup table mapping old IDs to new IDs table_schema: dict Schema for the table Returns: \\uf0c1 pd.Series Series mapping new IDs to merged identifier objects'},\n",
       "   '_prepare_consensus_table': {'name': '_prepare_consensus_table',\n",
       "    'signature': 'napistu.consensus._prepare_consensus_table(agg_table_harmonized:DataFrame,table_schema:dict,cluster_consensus_identifiers:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.consensus._prepare_consensus_table',\n",
       "    'doc': 'Prepare a consensus table with one row per unique entity. Parameters: \\uf0c1 agg_table_harmonized: pd.DataFrame Table with nameness scores and cluster assignments table_schema: dict Schema for the table cluster_consensus_identifiers: pd.DataFrame Consensus identifiers for each cluster Returns: \\uf0c1 pd.DataFrame New consensus table with merged entities'},\n",
       "   '_prepare_identifier_edgelist': {'name': '_prepare_identifier_edgelist',\n",
       "    'signature': 'napistu.consensus._prepare_identifier_edgelist(valid_identifiers:DataFrame,sbml_df:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.consensus._prepare_identifier_edgelist',\n",
       "    'doc': 'Prepare an edgelist for clustering identifiers. Parameters: \\uf0c1 valid_identifiers: pd.DataFrame Table of identifiers sbml_df: pd.DataFrame Original table of entities Returns: \\uf0c1 pd.DataFrame Edgelist connecting entities to their identifiers'},\n",
       "   '_prepare_member_table': {'name': '_prepare_member_table',\n",
       "    'signature': \"napistu.consensus._prepare_member_table(sbml_dfs_dict:dict[str,SBML_dfs],defined_by:str,defined_lookup_tables:dict,table_schema:dict,defined_by_schema:dict,defining_attrs:list[str],table:str='reactions')→tuple[DataFrame,str]\",\n",
       "    'id': 'napistu.consensus._prepare_member_table',\n",
       "    'doc': 'Prepare a table of members and validate their structure. Parameters: \\uf0c1 sbml_dfs_dict: dict[str, sbml_dfs_core.SBML_dfs] Dictionary of SBML_dfs from different models defined_by: str Name of the table whose entries define membership defined_lookup_tables: dict Lookup tables for updating IDs table_schema: dict Schema for the main table defined_by_schema: dict Schema for the defining table defining_attrs: list[str] Attributes that define a unique member table: str Name of the main table (default: REACTIONS) Returns: \\uf0c1 tuple: Updated aggregated table with member strings Name of the foreign key'},\n",
       "   '_resolve_reversibility': {'name': '_resolve_reversibility',\n",
       "    'signature': 'napistu.consensus._resolve_reversibility(sbml_dfs_dict:dict[str,SBML_dfs],rxn_consensus_species:DataFrame,rxn_lookup_table:Series)→DataFrame',\n",
       "    'id': 'napistu.consensus._resolve_reversibility',\n",
       "    'doc': 'For a set of merged reactions determine what their consensus reaction reversibilities are'},\n",
       "   '_test_same_schema': {'name': '_test_same_schema',\n",
       "    'signature': 'napistu.consensus._test_same_schema(sbml_dfs_dict:dict[str,SBML_dfs])→None',\n",
       "    'id': 'napistu.consensus._test_same_schema',\n",
       "    'doc': 'Ensure that all sbml_dfs in the dict have the same schema'},\n",
       "   '_update_foreign_keys': {'name': '_update_foreign_keys',\n",
       "    'signature': 'napistu.consensus._update_foreign_keys(agg_tbl:DataFrame,table_schema:dict,fk_lookup_tables:dict)→DataFrame',\n",
       "    'id': 'napistu.consensus._update_foreign_keys',\n",
       "    'doc': 'Update one or more foreign keys based on old-to-new foreign key lookup table(s).'},\n",
       "   '_validate_consensus_table': {'name': '_validate_consensus_table',\n",
       "    'signature': 'napistu.consensus._validate_consensus_table(new_id_table:DataFrame,sbml_df:DataFrame)→None',\n",
       "    'id': 'napistu.consensus._validate_consensus_table',\n",
       "    'doc': 'Validate that the new consensus table has the same structure as the original. Parameters: \\uf0c1 new_id_table: pd.DataFrame Newly created consensus table sbml_df: pd.DataFrame Original table from which consensus was built Raises: \\uf0c1 ValueError If index names or columns don’t match'},\n",
       "   '_validate_meta_identifiers': {'name': '_validate_meta_identifiers',\n",
       "    'signature': 'napistu.consensus._validate_meta_identifiers(meta_identifiers:DataFrame)→None',\n",
       "    'id': 'napistu.consensus._validate_meta_identifiers',\n",
       "    'doc': 'Flag cases where meta identifers are totally missing or BQB codes are not included'},\n",
       "   'build_consensus_identifiers': {'name': 'build_consensus_identifiers',\n",
       "    'signature': \"napistu.consensus.build_consensus_identifiers(sbml_df:DataFrame,table_schema:dict,defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→tuple[Series,DataFrame]\",\n",
       "    'id': 'napistu.consensus.build_consensus_identifiers',\n",
       "    'doc': 'Build consensus identifiers by clustering entities that share biological identifiers. This function takes a set of entities spanning multiple models and finds all unique entities\\nby grouping them according to the provided biological qualifiers. It returns a mapping from\\noriginal entities to clusters and a DataFrame of consensus identifier objects for each cluster. Parameters : sbml_df ( pd.DataFrame ) – Table of entities from multiple models, with model in the index (as produced by unnest_SBML_df). table_schema ( dict ) – Schema for the table being processed. defining_biological_qualifiers ( list [ str ] , optional ) – List of biological qualifier types to use for grouping. Defaults to BQB_DEFINING_ATTRS. Returns : indexed_cluster ( pd.Series ) – Series mapping the index from sbml_df onto a set of clusters which define unique entities. cluster_consensus_identifiers_df ( pd.DataFrame ) – DataFrame mapping clusters to consensus identifiers (Identifiers objects).'},\n",
       "   'construct_consensus_model': {'name': 'construct_consensus_model',\n",
       "    'signature': 'napistu.consensus.construct_consensus_model(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:PWIndex,dogmatic:bool=True)→SBML_dfs',\n",
       "    'id': 'napistu.consensus.construct_consensus_model',\n",
       "    'doc': 'Construct a Consensus Model by merging shared entities across pathway models. This function takes a dictionary of pathway models and merges shared entities (compartments, species, reactions, etc.)\\ninto a single consensus model, using a set of rules for entity identity and merging. Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – A dictionary of SBML_dfs objects from different models, keyed by model name. pw_index ( indices.PWIndex ) – An index of all tables being aggregated, used for cross-referencing entities. dogmatic ( bool , default=True ) – If True, preserve genes, transcripts, and proteins as separate species. If False, merge them when possible. Returns : A consensus SBML_dfs object containing the merged model. Return type : sbml_dfs_core.SBML_dfs'},\n",
       "   'construct_meta_entities_fk': {'name': 'construct_meta_entities_fk',\n",
       "    'signature': \"napistu.consensus.construct_meta_entities_fk(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:DataFrame,table:str='compartmentalized_species',fk_lookup_tables:dict={},extra_defining_attrs:list=[])→tuple[DataFrame,Series]\",\n",
       "    'id': 'napistu.consensus.construct_meta_entities_fk',\n",
       "    'doc': 'Construct Meta Entities Defined by Foreign Keys Aggregating across one entity type for a set of pathway\\nmodels merge entities which are defined by their foreign keys. Parameters: \\uf0c1 sbml_df_dict: dict{“model”: cpr.SBML_dfs} A dictionary of cpr.SBML_dfs pw_index: indices.PWIndex An index of all tables being aggregated table: A table/entity set from the sbml_dfs to work-with fk_lookup_tables: dict Dictionary containing lookup tables for all foreign keys used by the table extra_defining_attrs: list List of terms which uniquely define a reaction species in addition\\nto the foreign keys. A common case is when a species is a modifier\\nand a substrate in a reaction. Returns: \\uf0c1 new_id_table: pd.DataFrame Matching the schema of one of the tables within sbml_df_dict lookup_table: pd.Series Matches the index of the aggregated entities to new_ids'},\n",
       "   'construct_meta_entities_identifiers': {'name': 'construct_meta_entities_identifiers',\n",
       "    'signature': \"napistu.consensus.construct_meta_entities_identifiers(sbml_dfs_dict:dict,pw_index:PWIndex,table:str,fk_lookup_tables:dict={},defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→tuple[DataFrame,Series]\",\n",
       "    'id': 'napistu.consensus.construct_meta_entities_identifiers',\n",
       "    'doc': 'Construct meta-entities by merging entities across models that share identifiers. Aggregates a single entity type from a set of pathway models and merges entities that share identifiers\\n(as defined by the provided biological qualifiers). Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – A dictionary of SBML_dfs objects from different models, keyed by model name. pw_index ( indices.PWIndex ) – An index of all tables being aggregated. table ( str ) – The name of the table/entity set to aggregate (e.g., ‘species’, ‘compartments’). fk_lookup_tables ( dict , optional ) – Dictionary containing lookup tables for all foreign keys used by the table (default: empty dict). defining_biological_qualifiers ( list [ str ] , optional ) – List of BQB codes which define distinct entities. Defaults to BQB_DEFINING_ATTRS. Returns : new_id_table ( pd.DataFrame ) – Table matching the schema of one of the input models, with merged entities. lookup_table ( pd.Series ) – Series mapping the index of the aggregated entities to new consensus IDs.'},\n",
       "   'construct_meta_entities_members': {'name': 'construct_meta_entities_members',\n",
       "    'signature': \"napistu.consensus.construct_meta_entities_members(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:PWIndex|None,table:str='reactions',defined_by:str='reaction_species',defined_lookup_tables:dict={},defining_attrs:list[str]=['sc_id','stoichiometry'])→tuple[DataFrame,Series]\",\n",
       "    'id': 'napistu.consensus.construct_meta_entities_members',\n",
       "    'doc': 'Construct Meta Entities Defined by Membership Aggregating across one entity type for a set of pathway models, merge entities with the same members. Parameters: \\uf0c1 sbml_df_dict: dict{“model”: cpr.SBML_dfs} A dictionary of cpr.SBML_dfs pw_index: indices.PWIndex An index of all tables being aggregated table: str A table/entity set from the sbml_dfs to work-with defined_by: dict A table/entity set whose entries are members of “table” defined_lookup_tables: {pd.Series} Lookup table for updating the ids of “defined_by” defining_attrs: [str] A list of attributes which jointly define a unique entity Returns: \\uf0c1 new_id_table: pd.DataFrame Matching the schema of one of the tables within sbml_df_dict lookup_table: pd.Series Matches the index of the aggregated entities to new_ids'},\n",
       "   'construct_sbml_dfs_dict': {'name': 'construct_sbml_dfs_dict',\n",
       "    'signature': 'napistu.consensus.construct_sbml_dfs_dict(pw_index:DataFrame,strict:bool=True)→dict[str,SBML_dfs]',\n",
       "    'id': 'napistu.consensus.construct_sbml_dfs_dict',\n",
       "    'doc': 'Construct a dictionary of SBML_dfs objects from a pathway index. This function converts all models in the pathway index into SBML_dfs objects and adds them to a dictionary.\\nOptionally, it can skip erroneous files with a warning instead of raising an error. Parameters : pw_index ( pd.DataFrame ) – An index of all tables being aggregated, containing model metadata and file paths. strict ( bool , default=True ) – If True, raise an error on any file that cannot be loaded. If False, skip erroneous files with a warning. Returns : A dictionary mapping model names to SBML_dfs objects. Return type : dict[str, sbml_dfs_core.SBML_dfs ]'},\n",
       "   'create_consensus_sources': {'name': 'create_consensus_sources',\n",
       "    'signature': 'napistu.consensus.create_consensus_sources(agg_tbl:DataFrame,lookup_table:Series,table_schema:dict,pw_index:PWIndex|None)→Series',\n",
       "    'id': 'napistu.consensus.create_consensus_sources',\n",
       "    'doc': 'Create Consensus Sources Annotate the source of to-be-merged species with the models they came from, and combine with existing annotations. Parameters: \\uf0c1 agg_tbl: pd.DataFrame A table containing existing source.Source objects and a many-1\\n“new_id” of their post-aggregation consensus entity lookup_table: pd.Series A series where the index are old identifiers and the values are\\npost-aggregation new identifiers table_schema: dict Summary of the schema for the operant entitye type pw_index: indices.PWIndex An index of all tables being aggregated Returns: \\uf0c1 new_sources: pd.DataFrame Mapping where the index is new identifiers and values are aggregated source.Source objects'},\n",
       "   'merge_entity_data': {'name': 'merge_entity_data',\n",
       "    'signature': 'napistu.consensus.merge_entity_data(sbml_dfs_dict:dict[str,SBML_dfs],lookup_table:Series,table:str)→dict',\n",
       "    'id': 'napistu.consensus.merge_entity_data',\n",
       "    'doc': 'Merge Entity Data Report cases where a single “new” id is associated with multiple different values of entity_var Args sbml_dfs_dict (dict): dictionary where values are to-be-merged model nnames and values are sbml_dfs_core.SBML_dfs lookup_table (pd.Series): a series where the index is an old model and primary key and the value is the new consensus id table (str): table whose data is being consolidates (currently species or reactions) Returns : dictionary containing pd.DataFrames which aggregate all of the individual entity_data tables in “sbml_dfs_dict” Return type : entity_data (dict)'},\n",
       "   'post_consensus_source_check': {'name': 'post_consensus_source_check',\n",
       "    'signature': 'napistu.consensus.post_consensus_source_check(sbml_dfs:SBML_dfs,table_name:str)→DataFrame',\n",
       "    'id': 'napistu.consensus.post_consensus_source_check',\n",
       "    'doc': 'Provide sources of tables in a consensus model; the output df will be used to determine whether models are merged.'},\n",
       "   'post_consensus_species_ontology_check': {'name': 'post_consensus_species_ontology_check',\n",
       "    'signature': 'napistu.consensus.post_consensus_species_ontology_check(sbml_dfs:SBML_dfs)→set[str]',\n",
       "    'id': 'napistu.consensus.post_consensus_species_ontology_check',\n",
       "    'doc': 'Check and return the set of ontologies shared by different sources in a consensus model’s species table. This function examines the species table in a consensus SBML_dfs object, determines the ontologies\\npresent for each source model, and returns the intersection of ontologies shared by all sources. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The consensus SBML_dfs object containing merged species from multiple models. Returns : Set of ontology terms shared by all sources in the consensus model’s species table. Return type : set[str]'},\n",
       "   'pre_consensus_compartment_check': {'name': 'pre_consensus_compartment_check',\n",
       "    'signature': 'napistu.consensus.pre_consensus_compartment_check(sbml_dfs_dict:dict[str,SBML_dfs],tablename:str)→tuple[list,dict]',\n",
       "    'id': 'napistu.consensus.pre_consensus_compartment_check',\n",
       "    'doc': 'Find compartments shared across models.'},\n",
       "   'pre_consensus_ontology_check': {'name': 'pre_consensus_ontology_check',\n",
       "    'signature': 'napistu.consensus.pre_consensus_ontology_check(sbml_dfs_dict:dict[str,SBML_dfs],tablename:str)→tuple[list,DataFrame]',\n",
       "    'id': 'napistu.consensus.pre_consensus_ontology_check',\n",
       "    'doc': 'Check for shared ontologies across source models for a given table. For compartments, species, or reactions tables, this function returns the set of ontologies\\nshared among all SBML_dfs in the input dictionary, as well as a DataFrame summarizing ontologies per model. Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – Dictionary of SBML_dfs objects from different models, keyed by model name. tablename ( str ) – Name of the table to check (should be one of ‘compartments’, ‘species’, or ‘reactions’). Returns : shared_onto_list ( list ) – List of ontologies shared by all models for the specified table. sbml_dict_onto_df ( pd.DataFrame ) – DataFrame summarizing ontologies present in each model for the specified table.'},\n",
       "   'reduce_to_consensus_ids': {'name': 'reduce_to_consensus_ids',\n",
       "    'signature': \"napistu.consensus.reduce_to_consensus_ids(sbml_df:DataFrame,table_schema:dict,pw_index:PWIndex|None=None,defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→tuple[DataFrame,Series]\",\n",
       "    'id': 'napistu.consensus.reduce_to_consensus_ids',\n",
       "    'doc': 'Reduce a table of entities to unique entries based on consensus identifiers. This function clusters entities that share identifiers (as defined by the provided biological qualifiers)\\nand produces a new table of unique entities, along with a lookup table mapping original entities to consensus IDs. Parameters : sbml_df ( pd.DataFrame ) – Table of entities from multiple models, with model in the index (as produced by unnest_SBML_df). table_schema ( dict ) – Schema for the table being reduced. pw_index ( indices.PWIndex , optional ) – An index of all tables being aggregated (default: None). defining_biological_qualifiers ( list [ str ] , optional ) – List of biological qualifier types which define distinct entities. Defaults to BQB_DEFINING_ATTRS. Returns : new_id_table ( pd.DataFrame ) – Table matching the schema of one of the input models, with merged entities. lookup_table ( pd.Series ) – Series mapping the index of the aggregated entities to new consensus IDs.'},\n",
       "   'report_consensus_merges': {'name': 'report_consensus_merges',\n",
       "    'signature': 'napistu.consensus.report_consensus_merges(lookup_table:Series,table_schema:dict,agg_tbl:DataFrame|None=None,sbml_dfs_dict:dict[str,SBML_dfs]|None=None,n_example_merges:int=3)→None',\n",
       "    'id': 'napistu.consensus.report_consensus_merges',\n",
       "    'doc': 'Report Consensus Merges Print a summary of merges that occurred Parameters: \\uf0c1 lookup_table pd.Series An index of “model” and the entities primary key with values of new_id table_schema dict Schema of the table being merged agg_tbl pd.DataFrame or None Contains the original model, primary keys and a label. Required if the primary key is not r_id (i.e., reactions) sbml_dfs_dict pd.DataFrame or None The dict of full models across all models. Used to create reaction formulas if the primary key is r_id n_example_merges int Number of example merges to report details on Returns: \\uf0c1 None'},\n",
       "   'unnest_SBML_df': {'name': 'unnest_SBML_df',\n",
       "    'signature': 'napistu.consensus.unnest_SBML_df(sbml_dfs_dict:dict[str,SBML_dfs],table:str)→DataFrame',\n",
       "    'id': 'napistu.consensus.unnest_SBML_df',\n",
       "    'doc': 'Unnest and concatenate a specific table from multiple SBML_dfs models. This function merges corresponding tables from a set of models into a single DataFrame,\\nadding the model name as an index level. Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – A dictionary of SBML_dfs objects from different models, keyed by model name. table ( str ) – The name of the table to aggregate (e.g., ‘species’, ‘reactions’, ‘compartments’). Returns : A concatenated table with a MultiIndex of model and entity ID. Return type : pd.DataFrame'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.constants': {'module': 'napistu.constants',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.constants.html#module-napistu.constants',\n",
       "  'functions': {'get_biological_qualifier_codes': {'name': 'get_biological_qualifier_codes',\n",
       "    'signature': 'napistu.constants.get_biological_qualifier_codes()',\n",
       "    'id': 'napistu.constants.get_biological_qualifier_codes',\n",
       "    'doc': ''}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.gcs': {'module': 'napistu.gcs',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.html#module-napistu.gcs',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {'constants': {'url': 'napistu.gcs.constants.html#module-napistu.gcs.constants',\n",
       "    'description': ''},\n",
       "   'downloads': {'url': 'napistu.gcs.downloads.html#module-napistu.gcs.downloads',\n",
       "    'description': ''}}},\n",
       " 'napistu.gcs.constants': {'module': 'napistu.gcs.constants',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.constants.html#module-napistu.gcs.constants',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.gcs.downloads': {'module': 'napistu.gcs.downloads',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.downloads.html#module-napistu.gcs.downloads',\n",
       "  'functions': {'_get_gcs_asset_path': {'name': '_get_gcs_asset_path',\n",
       "    'signature': 'napistu.gcs.downloads._get_gcs_asset_path(asset:str,subasset:str|None=None)→str',\n",
       "    'id': 'napistu.gcs.downloads._get_gcs_asset_path',\n",
       "    'doc': 'Get the GCS path for a given asset and subasset. Parameters : asset ( str ) – The name of the asset. subasset ( Optional [ str ] ) – The name of the subasset. Returns : The GCS path for the asset or subasset. Return type : str'},\n",
       "   '_initialize_data_dir': {'name': '_initialize_data_dir',\n",
       "    'signature': \"napistu.gcs.downloads._initialize_data_dir(data_dir:str,init_msg:str='The`data_dir`{data_dir}doesnotexist.')→None\",\n",
       "    'id': 'napistu.gcs.downloads._initialize_data_dir',\n",
       "    'doc': 'Create a data directory if it doesn’t exist.'},\n",
       "   '_remove_asset_files_if_needed': {'name': '_remove_asset_files_if_needed',\n",
       "    'signature': 'napistu.gcs.downloads._remove_asset_files_if_needed(asset:str,data_dir:str)',\n",
       "    'id': 'napistu.gcs.downloads._remove_asset_files_if_needed',\n",
       "    'doc': 'Remove asset archive and any extracted directory from data_dir. Parameters : asset ( str ) – The asset key (e.g., ‘test_pathway’). data_dir ( str ) – The directory where assets are stored.'},\n",
       "   '_validate_gcs_asset': {'name': '_validate_gcs_asset',\n",
       "    'signature': 'napistu.gcs.downloads._validate_gcs_asset(asset:str)→None',\n",
       "    'id': 'napistu.gcs.downloads._validate_gcs_asset',\n",
       "    'doc': 'Validate a GCS asset by name.'},\n",
       "   '_validate_gcs_subasset': {'name': '_validate_gcs_subasset',\n",
       "    'signature': 'napistu.gcs.downloads._validate_gcs_subasset(asset:str,subasset:str)→None',\n",
       "    'id': 'napistu.gcs.downloads._validate_gcs_subasset',\n",
       "    'doc': 'Validate a subasset as belonging to a given asset.'},\n",
       "   'download_public_napistu_asset': {'name': 'download_public_napistu_asset',\n",
       "    'signature': 'napistu.gcs.downloads.download_public_napistu_asset(asset:str,out_path:str)→None',\n",
       "    'id': 'napistu.gcs.downloads.download_public_napistu_asset',\n",
       "    'doc': 'Download Public Napistu Asset Parameters : asset ( str ) – The name of a Napistu public asset stored in Google Cloud Storage (GCS) out_path ( list ) – Local location where the file should be saved. Returns : None'},\n",
       "   'load_public_napistu_asset': {'name': 'load_public_napistu_asset',\n",
       "    'signature': \"napistu.gcs.downloads.load_public_napistu_asset(asset:str,data_dir:str,subasset:str|None=None,init_msg:str='The`data_dir`{data_dir}doesnotexist.',overwrite:bool=False)→str\",\n",
       "    'id': 'napistu.gcs.downloads.load_public_napistu_asset',\n",
       "    'doc': 'Load Public Napistu Asset Download the asset asset to data_dir if it doesn’t\\nalready exist and return a path asset: the file to download (which will be unpacked if its a .tar.gz)\\nsubasset: the name of a subasset to load from within the asset bundle\\ndata_dir: the local directory where assets should be stored\\ninit_msg: message to display if data_dir does not exist\\noverwrite: if True, always download the asset and re-extract it, even if it already exists Returns : the path to a local file Return type : asset_path'}},\n",
       "  'classes': {'_NapistuAssetValidator': {'name': '_NapistuAssetValidator',\n",
       "    'signature': 'classnapistu.gcs.downloads._NapistuAssetValidator(*,file:str,subassets:dict[str,str]|None,public_url:str)',\n",
       "    'id': 'napistu.gcs.downloads._NapistuAssetValidator',\n",
       "    'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 file : str \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict]. public_url : str \\uf0c1 subassets : dict [ str , str ] | None \\uf0c1',\n",
       "    'methods': {},\n",
       "    'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "      'signature': '_abc_impl=<_abc._abc_dataobject>',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetValidator._abc_impl',\n",
       "      'doc': ''},\n",
       "     'file': {'name': 'file',\n",
       "      'signature': 'file:str',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetValidator.file',\n",
       "      'doc': ''},\n",
       "     'model_config': {'name': 'model_config',\n",
       "      'signature': 'model_config:ClassVar[ConfigDict]={}',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetValidator.model_config',\n",
       "      'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'},\n",
       "     'public_url': {'name': 'public_url',\n",
       "      'signature': 'public_url:str',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetValidator.public_url',\n",
       "      'doc': ''},\n",
       "     'subassets': {'name': 'subassets',\n",
       "      'signature': 'subassets:dict[str,str]|None',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetValidator.subassets',\n",
       "      'doc': ''}}},\n",
       "   '_NapistuAssetsValidator': {'name': '_NapistuAssetsValidator',\n",
       "    'signature': 'classnapistu.gcs.downloads._NapistuAssetsValidator(*,assets:dict[str,_NapistuAssetValidator])',\n",
       "    'id': 'napistu.gcs.downloads._NapistuAssetsValidator',\n",
       "    'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 assets : dict [ str , _NapistuAssetValidator ] \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].',\n",
       "    'methods': {},\n",
       "    'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "      'signature': '_abc_impl=<_abc._abc_dataobject>',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetsValidator._abc_impl',\n",
       "      'doc': ''},\n",
       "     'assets': {'name': 'assets',\n",
       "      'signature': 'assets:dict[str,_NapistuAssetValidator]',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetsValidator.assets',\n",
       "      'doc': ''},\n",
       "     'model_config': {'name': 'model_config',\n",
       "      'signature': 'model_config:ClassVar[ConfigDict]={}',\n",
       "      'id': 'napistu.gcs.downloads._NapistuAssetsValidator.model_config',\n",
       "      'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.identifiers': {'module': 'napistu.identifiers',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.identifiers.html#module-napistu.identifiers',\n",
       "  'functions': {'_check_species_identifiers_table': {'name': '_check_species_identifiers_table',\n",
       "    'signature': \"napistu.identifiers._check_species_identifiers_table(species_identifiers:DataFrame,required_vars:set={'bqb','identifier','ontology','s_id','s_name'})\",\n",
       "    'id': 'napistu.identifiers._check_species_identifiers_table',\n",
       "    'doc': ''},\n",
       "   '_count_reactome_species': {'name': '_count_reactome_species',\n",
       "    'signature': 'napistu.identifiers._count_reactome_species(reactome_series:Series)→Series',\n",
       "    'id': 'napistu.identifiers._count_reactome_species',\n",
       "    'doc': 'Count the number of species tags in a set of reactome IDs'},\n",
       "   '_format_Identifiers_pubmed': {'name': '_format_Identifiers_pubmed',\n",
       "    'signature': 'napistu.identifiers._format_Identifiers_pubmed(pubmed_id:str)→Identifiers',\n",
       "    'id': 'napistu.identifiers._format_Identifiers_pubmed',\n",
       "    'doc': 'Format Identifiers for a single PubMed ID. These will generally be used in an r_Identifiers field.'},\n",
       "   '_infer_primary_reactome_species': {'name': '_infer_primary_reactome_species',\n",
       "    'signature': 'napistu.identifiers._infer_primary_reactome_species(reactome_series:Series)→tuple[str,int]',\n",
       "    'id': 'napistu.identifiers._infer_primary_reactome_species',\n",
       "    'doc': 'Infer the best supported species based on a set of Reactome identifiers'},\n",
       "   '_prepare_species_identifiers': {'name': '_prepare_species_identifiers',\n",
       "    'signature': 'napistu.identifiers._prepare_species_identifiers(sbml_dfs:SBML_dfs,dogmatic:bool=False,species_identifiers:DataFrame|None=None)→DataFrame',\n",
       "    'id': 'napistu.identifiers._prepare_species_identifiers',\n",
       "    'doc': 'Accepts and validates species_identifiers, or extracts a fresh table if None.'},\n",
       "   '_reactome_id_species': {'name': '_reactome_id_species',\n",
       "    'signature': 'napistu.identifiers._reactome_id_species(reactome_id:str)→str',\n",
       "    'id': 'napistu.identifiers._reactome_id_species',\n",
       "    'doc': 'Extract the species code from a Reactome ID'},\n",
       "   '_validate_assets_sbml_ids': {'name': '_validate_assets_sbml_ids',\n",
       "    'signature': 'napistu.identifiers._validate_assets_sbml_ids(sbml_dfs:SBML_dfs,identifiers_df:DataFrame)→None',\n",
       "    'id': 'napistu.identifiers._validate_assets_sbml_ids',\n",
       "    'doc': 'Check an sbml_dfs file and identifiers table for inconsistencies.'},\n",
       "   '_validate_bqb': {'name': '_validate_bqb',\n",
       "    'signature': 'napistu.identifiers._validate_bqb(bqb)',\n",
       "    'id': 'napistu.identifiers._validate_bqb',\n",
       "    'doc': ''},\n",
       "   'check_reactome_identifier_compatibility': {'name': 'check_reactome_identifier_compatibility',\n",
       "    'signature': 'napistu.identifiers.check_reactome_identifier_compatibility(reactome_series_a:Series,reactome_series_b:Series)→None',\n",
       "    'id': 'napistu.identifiers.check_reactome_identifier_compatibility',\n",
       "    'doc': 'Check Reactome Identifier Compatibility Determine whether two sets of Reactome identifiers are from the same species. Parameters : reactome_series_a – pd.Series\\na Series containing Reactome identifiers reactome_series_b – pd.Series\\na Series containing Reactome identifiers Returns : None'},\n",
       "   'create_uri_url': {'name': 'create_uri_url',\n",
       "    'signature': 'napistu.identifiers.create_uri_url(ontology:str,identifier:str,strict:bool=True)→str',\n",
       "    'id': 'napistu.identifiers.create_uri_url',\n",
       "    'doc': 'Create URI URL Convert from an identifier and ontology to a URL reference for the identifier Parameters:\\nontology (str): An ontology for organizing genes, metabolites, etc.\\nidentifier (str): A systematic identifier from the “ontology” ontology.\\nstrict (bool): if strict then throw errors for invalid IDs otherwise return None Returns:\\nurl (str): A url representing a unique identifier'},\n",
       "   'cv_to_Identifiers': {'name': 'cv_to_Identifiers',\n",
       "    'signature': 'napistu.identifiers.cv_to_Identifiers(entity)',\n",
       "    'id': 'napistu.identifiers.cv_to_Identifiers',\n",
       "    'doc': 'Convert an SBML controlled vocabulary element into a cpr Identifiers object. Parameters:\\nentity: libsbml.Species An entity (species, reaction, compartment, …) with attached CV terms Returns:'},\n",
       "   'ensembl_id_to_url_regex': {'name': 'ensembl_id_to_url_regex',\n",
       "    'signature': 'napistu.identifiers.ensembl_id_to_url_regex(identifier:str,ontology:str)→tuple[str,str]',\n",
       "    'id': 'napistu.identifiers.ensembl_id_to_url_regex',\n",
       "    'doc': 'Ensembl ID to URL and Regex Map an ensembl ID to a validation regex and its canonical url on ensembl Parameters : identifier – str\\nA standard identifier from ensembl genes, transcripts, or proteins ontology – str\\nThe standard ontology (ensembl_gene, ensembl_transcript, or ensembl_protein) Returns : a regex which should match a valid entry in this ontology\\nurl: the id’s url on ensembl Return type : id_regex'},\n",
       "   'format_uri': {'name': 'format_uri',\n",
       "    'signature': 'napistu.identifiers.format_uri(uri:str,biological_qualifier_type:str|None=None)→Identifiers',\n",
       "    'id': 'napistu.identifiers.format_uri',\n",
       "    'doc': 'Convert a RDF URI into an Identifier object'},\n",
       "   'format_uri_url': {'name': 'format_uri_url',\n",
       "    'signature': 'napistu.identifiers.format_uri_url(uri:str)→dict',\n",
       "    'id': 'napistu.identifiers.format_uri_url',\n",
       "    'doc': ''},\n",
       "   'format_uri_url_identifiers_dot_org': {'name': 'format_uri_url_identifiers_dot_org',\n",
       "    'signature': 'napistu.identifiers.format_uri_url_identifiers_dot_org(split_path:list[str])',\n",
       "    'id': 'napistu.identifiers.format_uri_url_identifiers_dot_org',\n",
       "    'doc': 'Parse identifiers.org identifiers The identifiers.org identifier have two different formats:\\n1. http://identifiers.org /<ontology>/<id>\\n2. http://identifiers.org /<ontology>:<id> Currently we are identifying the newer format 2. by\\nlooking for the : in the second element of the split path. Also the ontology is converted to lower case letters. Parameters : split_path ( list [ str ] ) – split url path Returns : ontology, identifier Return type : tuple[str, str]'},\n",
       "   'merge_identifiers': {'name': 'merge_identifiers',\n",
       "    'signature': 'napistu.identifiers.merge_identifiers(identifier_series:Series)→Identifiers',\n",
       "    'id': 'napistu.identifiers.merge_identifiers',\n",
       "    'doc': 'Aggregate Identifiers Merge a pd.Series of Identifiers objects into a single Identifiers object Args:\\nidentifier_series: pd.Series A pd.Series of of identifiers.Identifiers objects Returns:\\nAn identifiers.Identifiers object'},\n",
       "   'parse_ensembl_id': {'name': 'parse_ensembl_id',\n",
       "    'signature': 'napistu.identifiers.parse_ensembl_id(input_str:str)→tuple[str,str,str]',\n",
       "    'id': 'napistu.identifiers.parse_ensembl_id',\n",
       "    'doc': 'Parse Ensembl ID Extract the molecule type and species name from a string containing an ensembl identifier. Parameters : input_str ( str ) – A string containing an ensembl gene, transcript, or protein identifier Returns : The substring matching the full identifier\\nmolecule_type (str): The ontology the identifier belongs to: G -> ensembl_gene T -> ensembl_transcript P -> ensembl_protein species (str): The species name the identifier belongs to Return type : identifier (str)'}},\n",
       "  'classes': {'Identifiers': {'name': 'Identifiers',\n",
       "    'signature': 'classnapistu.identifiers.Identifiers(id_list:list,verbose:bool=False)',\n",
       "    'id': 'napistu.identifiers.Identifiers',\n",
       "    'doc': 'Bases: object Identifiers for a single entity or relationship. ids \\uf0c1 a list of identifiers which are each a dict containing an ontology and identifier Type : list verbose \\uf0c1 extra reporting, defaults to False Type : bool print ( ) \\uf0c1 Print a table of identifiers filter ( ontologies , summarize ) \\uf0c1 Returns a bool of whether 1+ of the ontologies was represented hoist ( ontology ) \\uf0c1 Returns value(s) from an ontology __init__ ( id_list : list , verbose : bool = False ) → None \\uf0c1 Tracks a set of identifiers and the ontologies they belong to. Parameters : id_list ( list ) – a list of identifier dictionaries containing ontology, identifier, and optionally url Return type : None. filter ( ontologies , summarize = True ) \\uf0c1 Returns a bool of whether 1+ of the ontologies was represented hoist ( ontology : str , squeeze : bool = True ) → str | list [ str ] | None \\uf0c1 Returns value(s) from an ontology Parameters : ontology ( str ) – the ontology of interest squeeze ( bool ) – if True, return a single value if possible Returns : the value(s) of an ontology of interest Return type : str or list print ( ) \\uf0c1 Print a table of identifiers',\n",
       "    'methods': {'print': {'name': 'print',\n",
       "      'signature': 'print()',\n",
       "      'id': 'id2',\n",
       "      'doc': 'Print a table of identifiers'},\n",
       "     'filter': {'name': 'filter',\n",
       "      'signature': 'filter(ontologies,summarize=True)',\n",
       "      'id': 'id0',\n",
       "      'doc': 'Returns a bool of whether 1+ of the ontologies was represented'},\n",
       "     'hoist': {'name': 'hoist',\n",
       "      'signature': 'hoist(ontology:str,squeeze:bool=True)→str|list[str]|None',\n",
       "      'id': 'id1',\n",
       "      'doc': 'Returns value(s) from an ontology Parameters : ontology ( str ) – the ontology of interest squeeze ( bool ) – if True, return a single value if possible Returns : the value(s) of an ontology of interest Return type : str or list'},\n",
       "     '__init__': {'name': '__init__',\n",
       "      'signature': '__init__(id_list:list,verbose:bool=False)→None',\n",
       "      'id': 'napistu.identifiers.Identifiers.__init__',\n",
       "      'doc': 'Tracks a set of identifiers and the ontologies they belong to. Parameters : id_list ( list ) – a list of identifier dictionaries containing ontology, identifier, and optionally url Return type : None.'}},\n",
       "    'attributes': {'ids': {'name': 'ids',\n",
       "      'signature': 'ids',\n",
       "      'id': 'napistu.identifiers.Identifiers.ids',\n",
       "      'doc': 'a list of identifiers which are each a dict containing an ontology and identifier Type : list'},\n",
       "     'verbose': {'name': 'verbose',\n",
       "      'signature': 'verbose',\n",
       "      'id': 'napistu.identifiers.Identifiers.verbose',\n",
       "      'doc': 'extra reporting, defaults to False Type : bool'}}},\n",
       "   '_IdentifierValidator': {'name': '_IdentifierValidator',\n",
       "    'signature': 'classnapistu.identifiers._IdentifierValidator(*,ontology:str,identifier:str,url:str|None=None,bqb:str|None=None)',\n",
       "    'id': 'napistu.identifiers._IdentifierValidator',\n",
       "    'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 bqb : str | None \\uf0c1 identifier : str \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict]. ontology : str \\uf0c1 url : str | None \\uf0c1',\n",
       "    'methods': {},\n",
       "    'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "      'signature': '_abc_impl=<_abc._abc_dataobject>',\n",
       "      'id': 'napistu.identifiers._IdentifierValidator._abc_impl',\n",
       "      'doc': ''},\n",
       "     'bqb': {'name': 'bqb',\n",
       "      'signature': 'bqb:str|None',\n",
       "      'id': 'napistu.identifiers._IdentifierValidator.bqb',\n",
       "      'doc': ''},\n",
       "     'identifier': {'name': 'identifier',\n",
       "      'signature': 'identifier:str',\n",
       "      'id': 'napistu.identifiers._IdentifierValidator.identifier',\n",
       "      'doc': ''},\n",
       "     'model_config': {'name': 'model_config',\n",
       "      'signature': 'model_config:ClassVar[ConfigDict]={}',\n",
       "      'id': 'napistu.identifiers._IdentifierValidator.model_config',\n",
       "      'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'},\n",
       "     'ontology': {'name': 'ontology',\n",
       "      'signature': 'ontology:str',\n",
       "      'id': 'napistu.identifiers._IdentifierValidator.ontology',\n",
       "      'doc': ''},\n",
       "     'url': {'name': 'url',\n",
       "      'signature': 'url:str|None',\n",
       "      'id': 'napistu.identifiers._IdentifierValidator.url',\n",
       "      'doc': ''}}},\n",
       "   '_IdentifiersValidator': {'name': '_IdentifiersValidator',\n",
       "    'signature': 'classnapistu.identifiers._IdentifiersValidator(*,id_list:list[_IdentifierValidator])',\n",
       "    'id': 'napistu.identifiers._IdentifiersValidator',\n",
       "    'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 id_list : list [ _IdentifierValidator ] \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].',\n",
       "    'methods': {},\n",
       "    'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "      'signature': '_abc_impl=<_abc._abc_dataobject>',\n",
       "      'id': 'napistu.identifiers._IdentifiersValidator._abc_impl',\n",
       "      'doc': ''},\n",
       "     'id_list': {'name': 'id_list',\n",
       "      'signature': 'id_list:list[_IdentifierValidator]',\n",
       "      'id': 'napistu.identifiers._IdentifiersValidator.id_list',\n",
       "      'doc': ''},\n",
       "     'model_config': {'name': 'model_config',\n",
       "      'signature': 'model_config:ClassVar[ConfigDict]={}',\n",
       "      'id': 'napistu.identifiers._IdentifiersValidator.model_config',\n",
       "      'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.indices': {'module': 'napistu.indices',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.indices.html#module-napistu.indices',\n",
       "  'functions': {'adapt_pw_index': {'name': 'adapt_pw_index',\n",
       "    'signature': 'napistu.indices.adapt_pw_index(source:str|PWIndex,species:str|Iterable[str]|None,outdir:str|None=None)→PWIndex',\n",
       "    'id': 'napistu.indices.adapt_pw_index',\n",
       "    'doc': 'Adapts a pw_index Helpful to filter for species before reconstructing. Parameters : source ( str | PWIndex ) – uri for pw_index.csv file or PWIndex object species ( str ) outdir ( str | None , optional ) – Optional directory to write pw_index to.\\nDefaults to None. Returns : Filtered pw index Return type : PWIndex'}},\n",
       "  'classes': {'PWIndex': {'name': 'PWIndex',\n",
       "    'signature': 'classnapistu.indices.PWIndex(pw_index:PathLike[str]|str|DataFrame,pw_index_base_path=None,validate_paths=True)',\n",
       "    'id': 'napistu.indices.PWIndex',\n",
       "    'doc': 'Bases: object Pathway Index Organizing metadata (and optionally paths) of individual pathway representations index \\uf0c1 A table describing the location and contents of pathway files. Type : pd.DataFrame base_path \\uf0c1 Path to directory of indexed files Type : str filter ( sources , species ) \\uf0c1 Filter index based on pathway source an/or category search ( query ) \\uf0c1 Filter index to pathways matching the search query __init__ ( pw_index : PathLike [ str ] | str | DataFrame , pw_index_base_path = None , validate_paths = True ) → None \\uf0c1 Tracks pathway file locations and contents. Parameters : pw_index ( str or None ) – Path to index file or a pd.DataFrame containing the contents of PWIndex.index pw_index_base_path ( str or None ) – A Path that relative paths in pw_index will reference validate_paths ( bool ) – If True then paths constructed from base_path + file will be tested for existence.\\nIf False then paths will not be validated and base_path attribute will be set to None Return type : None _check_files ( ) \\uf0c1 Verifies that all files in the pwindex are present Raises : FileNotFoundError – Error if a file not present filter ( sources : str | Iterable [ str ] | None = None , species : str | Iterable [ str ] | None = None ) \\uf0c1 Filter Pathway Index Parameters : sources ( str | Iterable [ str ] | None , optional ) – A list of valid sources or None for all species ( str | Iterable [ str ] | None , optional ) – A list of valid species or None all all search ( query ) \\uf0c1 Search Pathway Index Parameters:\\nquery: str Filter to rows of interest based on case-insensitive match to names. Returns:\\nNone',\n",
       "    'methods': {'filter': {'name': 'filter',\n",
       "      'signature': 'filter(sources:str|Iterable[str]|None=None,species:str|Iterable[str]|None=None)',\n",
       "      'id': 'id0',\n",
       "      'doc': 'Filter Pathway Index Parameters : sources ( str | Iterable [ str ] | None , optional ) – A list of valid sources or None for all species ( str | Iterable [ str ] | None , optional ) – A list of valid species or None all all'},\n",
       "     'search': {'name': 'search',\n",
       "      'signature': 'search(query)',\n",
       "      'id': 'id1',\n",
       "      'doc': 'Search Pathway Index Parameters:\\nquery: str Filter to rows of interest based on case-insensitive match to names. Returns:\\nNone'},\n",
       "     '__init__': {'name': '__init__',\n",
       "      'signature': '__init__(pw_index:PathLike[str]|str|DataFrame,pw_index_base_path=None,validate_paths=True)→None',\n",
       "      'id': 'napistu.indices.PWIndex.__init__',\n",
       "      'doc': 'Tracks pathway file locations and contents. Parameters : pw_index ( str or None ) – Path to index file or a pd.DataFrame containing the contents of PWIndex.index pw_index_base_path ( str or None ) – A Path that relative paths in pw_index will reference validate_paths ( bool ) – If True then paths constructed from base_path + file will be tested for existence.\\nIf False then paths will not be validated and base_path attribute will be set to None Return type : None'},\n",
       "     '_check_files': {'name': '_check_files',\n",
       "      'signature': '_check_files()',\n",
       "      'id': 'napistu.indices.PWIndex._check_files',\n",
       "      'doc': 'Verifies that all files in the pwindex are present Raises : FileNotFoundError – Error if a file not present'}},\n",
       "    'attributes': {'index': {'name': 'index',\n",
       "      'signature': 'index',\n",
       "      'id': 'napistu.indices.PWIndex.index',\n",
       "      'doc': 'A table describing the location and contents of pathway files. Type : pd.DataFrame'},\n",
       "     'base_path': {'name': 'base_path',\n",
       "      'signature': 'base_path',\n",
       "      'id': 'napistu.indices.PWIndex.base_path',\n",
       "      'doc': 'Path to directory of indexed files Type : str'}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion': {'module': 'napistu.ingestion',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.html#module-napistu.ingestion',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {'bigg': {'url': 'napistu.ingestion.bigg.html#module-napistu.ingestion.bigg',\n",
       "    'description': ''},\n",
       "   'constants': {'url': 'napistu.ingestion.constants.html#module-napistu.ingestion.constants',\n",
       "    'description': ''},\n",
       "   'cpr_edgelist': {'url': 'napistu.ingestion.cpr_edgelist.html#module-napistu.ingestion.cpr_edgelist',\n",
       "    'description': 'Module with helper functions to deal with edgelists'},\n",
       "   'identifiers_etl': {'url': 'napistu.ingestion.identifiers_etl.html#module-napistu.ingestion.identifiers_etl',\n",
       "    'description': ''},\n",
       "   'obo': {'url': 'napistu.ingestion.obo.html#module-napistu.ingestion.obo',\n",
       "    'description': ''},\n",
       "   'psi_mi': {'url': 'napistu.ingestion.psi_mi.html#module-napistu.ingestion.psi_mi',\n",
       "    'description': ''},\n",
       "   'reactome': {'url': 'napistu.ingestion.reactome.html#module-napistu.ingestion.reactome',\n",
       "    'description': ''},\n",
       "   'sbml': {'url': 'napistu.ingestion.sbml.html#module-napistu.ingestion.sbml',\n",
       "    'description': ''},\n",
       "   'string': {'url': 'napistu.ingestion.string.html#module-napistu.ingestion.string',\n",
       "    'description': ''},\n",
       "   'trrust': {'url': 'napistu.ingestion.trrust.html#module-napistu.ingestion.trrust',\n",
       "    'description': ''},\n",
       "   'yeast': {'url': 'napistu.ingestion.yeast.html#module-napistu.ingestion.yeast',\n",
       "    'description': ''}}},\n",
       " 'napistu.ingestion.bigg': {'module': 'napistu.ingestion.bigg',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.bigg.html#module-napistu.ingestion.bigg',\n",
       "  'functions': {'annotate_recon': {'name': 'annotate_recon',\n",
       "    'signature': 'napistu.ingestion.bigg.annotate_recon(raw_model_path:str,annotated_model_path:str)→None',\n",
       "    'id': 'napistu.ingestion.bigg.annotate_recon',\n",
       "    'doc': 'Annotate Recon3D\\nAdd compartment annotations to Recon3D so it can be merged with other pathways'},\n",
       "   'bigg_sbml_download': {'name': 'bigg_sbml_download',\n",
       "    'signature': 'napistu.ingestion.bigg.bigg_sbml_download(bg_pathway_root:str,overwrite:bool=False)→None',\n",
       "    'id': 'napistu.ingestion.bigg.bigg_sbml_download',\n",
       "    'doc': 'BiGG SBML Download Download SBML models from BiGG. Currently just the human Recon3D model Parameters:\\nbg_pathway_root (str): Paths to a directory where a “sbml” directory should be created.\\noverwrite (bool): Overwrite an existing output directory. Returns:\\nNone'},\n",
       "   'construct_bigg_consensus': {'name': 'construct_bigg_consensus',\n",
       "    'signature': 'napistu.ingestion.bigg.construct_bigg_consensus(pw_index_inp:str|PWIndex,species:str|Iterable[str]|None=None,outdir:str|None=None)→SBML_dfs',\n",
       "    'id': 'napistu.ingestion.bigg.construct_bigg_consensus',\n",
       "    'doc': 'Constructs a BiGG SBML DFs Pathway Representation Attention: curently this does work only for a singly model. Integraiton of multiple\\nmodels is not supported yet in BiGG. Parameters : pw_index_inp ( str | indices.PWIndex ) – PWIndex or uri pointing to PWIndex species ( str | Iterable [ str ] | None ) – one or more species to filter by. Default: no filtering outdir ( str | None , optional ) – output directory used to cache results. Defaults to None. Returns : A consensus SBML Return type : sbml_dfs_core.SBML_dfs'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.constants': {'module': 'napistu.ingestion.constants',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.constants.html#module-napistu.ingestion.constants',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.cpr_edgelist': {'module': 'napistu.ingestion.cpr_edgelist',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.cpr_edgelist.html#module-napistu.ingestion.cpr_edgelist',\n",
       "  'functions': {'count_fraction_of_reciprocal_interactions': {'name': 'count_fraction_of_reciprocal_interactions',\n",
       "    'signature': 'napistu.ingestion.cpr_edgelist.count_fraction_of_reciprocal_interactions(edgelist:DataFrame,extra_defining_vars:list=[])→float',\n",
       "    'id': 'napistu.ingestion.cpr_edgelist.count_fraction_of_reciprocal_interactions',\n",
       "    'doc': 'Count the fraction of A-B edges which also show up as B-A edges Parameters : edgelist ( pd.DataFrame ) – edgelist (pd.DataFrame): edgelist where the first two\\ncolumns are assumed to be the edge vertices extra_defining_vars ( list ) – list (which can be empty) of variables which define\\na unique interaction beyond the vertices Returns : fraction of A-B edges which are also included as B-A edges Return type : fraction (float)'},\n",
       "   'remove_reciprocal_interactions': {'name': 'remove_reciprocal_interactions',\n",
       "    'signature': 'napistu.ingestion.cpr_edgelist.remove_reciprocal_interactions(edgelist:DataFrame,extra_defining_vars:list=[])→DataFrame',\n",
       "    'id': 'napistu.ingestion.cpr_edgelist.remove_reciprocal_interactions',\n",
       "    'doc': 'Remove reciprocal edges from an edgelist (i.e., if B-A always exists for every A-B then remove B-A) Parameters : edgelist ( pd.DataFrame ) – edgelist (pd.DataFrame): edgelist where the first two\\ncolumns are assumed to be the edge vertices extra_defining_vars ( list ) – list (which can be empty) of variables which define\\na unique interaction beyond the vertices Returns : edgelist with B-A edges removed and A-B retained Return type : indegenerate_edgelist (pd.DataFrame)'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.identifiers_etl': {'module': 'napistu.ingestion.identifiers_etl',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.identifiers_etl.html#module-napistu.ingestion.identifiers_etl',\n",
       "  'functions': {'read_sbo_ontology': {'name': 'read_sbo_ontology',\n",
       "    'signature': \"napistu.ingestion.identifiers_etl.read_sbo_ontology(url:str='https://raw.githubusercontent.com/EBI-BioModels/SBO/master/SBO_OBO.obo',verbose:bool=False)→DataFrame\",\n",
       "    'id': 'napistu.ingestion.identifiers_etl.read_sbo_ontology',\n",
       "    'doc': 'Read SBO Ontology\\nRead the Systems Biology Ontology (SBO) identifiers and reformat the obo results into a pd.DataFrame. Params: url (str): url to the obo specification file\\nverbose (bool): throw warnings when attributes are overwritten Returns : pd.DataFrame'},\n",
       "   'read_yeast_identifiers': {'name': 'read_yeast_identifiers',\n",
       "    'signature': \"napistu.ingestion.identifiers_etl.read_yeast_identifiers(url:str='https://www.uniprot.org/docs/yeast.txt')\",\n",
       "    'id': 'napistu.ingestion.identifiers_etl.read_yeast_identifiers',\n",
       "    'doc': 'Read Yeast Identifiers\\nGenerate a pd.DataFrame which maps between yeast identifiers including\\ncommon and systematic (OLN) names, as well as Swiss-Prot and SGD identifiers. Params: url (str): url to the identifier file Returns : pd.DataFrame with one row per gene'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.obo': {'module': 'napistu.ingestion.obo',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.obo.html#module-napistu.ingestion.obo',\n",
       "  'functions': {'_download_go_basic_obo': {'name': '_download_go_basic_obo',\n",
       "    'signature': \"napistu.ingestion.obo._download_go_basic_obo(local_obo_path:str='/tmp/go-basic.obo')→None\",\n",
       "    'id': 'napistu.ingestion.obo._download_go_basic_obo',\n",
       "    'doc': 'Download an OBO file containing GO categories and their relations (but not the genes in each category).'},\n",
       "   '_find_obo_attrib_dups': {'name': '_find_obo_attrib_dups',\n",
       "    'signature': 'napistu.ingestion.obo._find_obo_attrib_dups(one_term)→list',\n",
       "    'id': 'napistu.ingestion.obo._find_obo_attrib_dups',\n",
       "    'doc': 'Identify attributes which are present multiple times.'},\n",
       "   '_format_entry_tuple': {'name': '_format_entry_tuple',\n",
       "    'signature': 'napistu.ingestion.obo._format_entry_tuple(line_str:str)→tuple|None',\n",
       "    'id': 'napistu.ingestion.obo._format_entry_tuple',\n",
       "    'doc': 'Split and return a colon-separated tuple.'},\n",
       "   '_isa_str_list_to_dict_list': {'name': '_isa_str_list_to_dict_list',\n",
       "    'signature': 'napistu.ingestion.obo._isa_str_list_to_dict_list(isa_list:list)→list[dict[str,Any]]',\n",
       "    'id': 'napistu.ingestion.obo._isa_str_list_to_dict_list',\n",
       "    'doc': 'Split parent-child relationships from individual strings to dictionaries where parent and child are separated.'},\n",
       "   '_reformat_obo_entry_as_dict': {'name': '_reformat_obo_entry_as_dict',\n",
       "    'signature': 'napistu.ingestion.obo._reformat_obo_entry_as_dict(one_term,degenerate_attribs)→dict',\n",
       "    'id': 'napistu.ingestion.obo._reformat_obo_entry_as_dict',\n",
       "    'doc': ''},\n",
       "   'create_go_ancestors_df': {'name': 'create_go_ancestors_df',\n",
       "    'signature': 'napistu.ingestion.obo.create_go_ancestors_df(parent_child_graph:Graph)→DataFrame',\n",
       "    'id': 'napistu.ingestion.obo.create_go_ancestors_df',\n",
       "    'doc': 'Create GO Ancestors DataFrame Parameters : parent_child_graph ( ig.Graph ) – a DAG formed from parent-child relationships. Returns : a table with: go_id: GO ID of a CC GO term of interest ancestor_id: An ancestor (parent, parent of parent, …)’s GO CC ID Return type : go_ancestors_df (pd.DataFrame)'},\n",
       "   'create_go_parents_df': {'name': 'create_go_parents_df',\n",
       "    'signature': 'napistu.ingestion.obo.create_go_parents_df(go_basic_obo_df:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.ingestion.obo.create_go_parents_df',\n",
       "    'doc': 'Create the GO Parents Table Reformat a table with GO attributes into a table with child-parent relationships Parameters : go_basic_obo_df ( pd.DataFrame ) – Table generated from parsing go-basic.obo with\\nobo.format_obo_dict_as_df Returns : a table with: parent_id: GO ID of parent (from an is-a entry) parent_name: common name of parent (from an is-a entry) child_id: GO ID from the index Return type : go_parents_df (pd.DataFrame)'},\n",
       "   'create_parent_child_graph': {'name': 'create_parent_child_graph',\n",
       "    'signature': 'napistu.ingestion.obo.create_parent_child_graph(go_parents_df:DataFrame)→Graph',\n",
       "    'id': 'napistu.ingestion.obo.create_parent_child_graph',\n",
       "    'doc': 'Create Parent:Child Graph Format the Simple GO CC Ontology as a Directed Acyclic Graph (DAG). Parameters : go_parents_df ( pd.DataFrame ) – a table with:\\n- parent_id: GO ID of parent (from an is-a entry)\\n- parent_name: common name of parent (from an is-a entry)\\n- child_id: GO ID from the index Returns : a DAG formed from parent-child relationships. Return type : parent_child_graph (ig.Graph)'},\n",
       "   'format_obo_dict_as_df': {'name': 'format_obo_dict_as_df',\n",
       "    'signature': 'napistu.ingestion.obo.format_obo_dict_as_df(obo_term_dict:dict)→DataFrame',\n",
       "    'id': 'napistu.ingestion.obo.format_obo_dict_as_df',\n",
       "    'doc': 'Format an OBO Dict as a DataFrame Reorganize a dictionary of tuples into a DataFrame Parameters : term_dict ( dict ) – dictionary where keys are ids and values are tuples\\ncontaining (attribute, value) pairs Returns obo_df (pd.DataFrame): A pd.DataFrame with one row per identifier and one columns for unique attribute'},\n",
       "   'read_obo_as_dict': {'name': 'read_obo_as_dict',\n",
       "    'signature': 'napistu.ingestion.obo.read_obo_as_dict(local_obo_path:str)→dict',\n",
       "    'id': 'napistu.ingestion.obo.read_obo_as_dict',\n",
       "    'doc': 'Read OBO as Dictionary The Open Biological and Biomedical Ontologies (OBO) format is a standard format\\nfor representing ontologies. Many parsers exist for obo but since we are not\\nrelying extensively on it and we are trying to minimize dependencies here we provide a\\nfew functions for parsing standard obo formats. Parameters : local_obo_path ( str ) – path to a local obo file. Returns term_dict (dict): dictionary where keys are ids and values are tuples containing (attribute, value) pairs'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.psi_mi': {'module': 'napistu.ingestion.psi_mi',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.psi_mi.html#module-napistu.ingestion.psi_mi',\n",
       "  'functions': {'_download_intact_species': {'name': '_download_intact_species',\n",
       "    'signature': \"napistu.ingestion.psi_mi._download_intact_species(species:str,output_dir_path:str='/tmp/intact_tmp',overwrite:bool=False)\",\n",
       "    'id': 'napistu.ingestion.psi_mi._download_intact_species',\n",
       "    'doc': 'Download IntAct Species Download the PSM-30 XML files from IntAct for a species of interest. Parameters : species ( str ) – The species name (Genus species) to work with output_dir_path ( str ) – Local directory to create an unzip files into overwrite ( bool ) – Overwrite an existing output directory. Default: False Returns : None'},\n",
       "   '_format_entry': {'name': '_format_entry',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry(an_entry)→dict[str,Any]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry',\n",
       "    'doc': 'Extract a single XML entry of interactors and interactions.'},\n",
       "   '_format_entry_experiment': {'name': '_format_entry_experiment',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_experiment(an_entry)→dict[str,str]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_experiment',\n",
       "    'doc': 'Format experiment-level information in an XML entry.'},\n",
       "   '_format_entry_interaction': {'name': '_format_entry_interaction',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_interaction(interaction)→dict[str,Any]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_interaction',\n",
       "    'doc': 'Format a single interaction in an XML interaction list.'},\n",
       "   '_format_entry_interaction_participants': {'name': '_format_entry_interaction_participants',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_interaction_participants(interaction_participant)→dict[str,str]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_interaction_participants',\n",
       "    'doc': 'Format the participants in an XML interaction.'},\n",
       "   '_format_entry_interactions': {'name': '_format_entry_interactions',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_interactions(an_entry)→list[dict[str,Any]]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_interactions',\n",
       "    'doc': 'Format the molecular interaction in an XML entry.'},\n",
       "   '_format_entry_interactor': {'name': '_format_entry_interactor',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_interactor(interactor)→dict[str,Any]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_interactor',\n",
       "    'doc': 'Format a single molecular interactor in an interaction list XML node.'},\n",
       "   '_format_entry_interactor_list': {'name': '_format_entry_interactor_list',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_interactor_list(an_entry)→list[dict[str,Any]]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_interactor_list',\n",
       "    'doc': 'Format the molecular interactors in an XML entry.'},\n",
       "   '_format_entry_interactor_xrefs': {'name': '_format_entry_interactor_xrefs',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_interactor_xrefs(interactor)→list[dict[str,str]]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_interactor_xrefs',\n",
       "    'doc': 'Format the cross-references of a single interactor.'},\n",
       "   '_format_entry_source': {'name': '_format_entry_source',\n",
       "    'signature': 'napistu.ingestion.psi_mi._format_entry_source(an_entry)→dict[str,str]',\n",
       "    'id': 'napistu.ingestion.psi_mi._format_entry_source',\n",
       "    'doc': 'Format the source describing the provenance of an XML entry.'},\n",
       "   'format_psi': {'name': 'format_psi',\n",
       "    'signature': \"napistu.ingestion.psi_mi.format_psi(xml_path:str,xml_namespace:str='{http://psi.hupo.org/mi/mif300}')→list[dict[str,Any]]\",\n",
       "    'id': 'napistu.ingestion.psi_mi.format_psi',\n",
       "    'doc': 'Format PSI 3.0 Format an .xml file containing molecular interactions following the PSI 3.0 format. Parameters : xml_path ( str ) – path to a .xml file xml_namespace ( str ) – Namespace for the xml file Returns : a list containing molecular interaction entry dicts of the format: source : dict containing the database that interactions were drawn from. experiment : a simple summary of the experimental design and the publication. interactor_list : list containing dictionaries annotating the molecules\\n(defined by their “interactor_id”) involved in interactions. interactions_list : list containing dictionaries annotating molecular\\ninteractions involving a set of “interactor_id”s. Return type : entry_list (list)'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.reactome': {'module': 'napistu.ingestion.reactome',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.reactome.html#module-napistu.ingestion.reactome',\n",
       "  'functions': {'_build_reactome_pw_index': {'name': '_build_reactome_pw_index',\n",
       "    'signature': 'napistu.ingestion.reactome._build_reactome_pw_index(output_dir:str,file_ext:str,species_filter:Iterable[str]|None=None)→DataFrame',\n",
       "    'id': 'napistu.ingestion.reactome._build_reactome_pw_index',\n",
       "    'doc': 'Build a reactome pathway index Builds the index based on available files and cross-checkes it with the\\nexpected reactome pathway list. Parameters : output_dir ( str ) – File directory file_ext ( str ) – File extension species_filter ( Optional [ Iterable [ str ] ] , optional ) – Filter the expected\\npathway list based on a list of species. Eg in cases only one species available. Defaults to None. Returns : pathway index Return type : pd.DataFrame'},\n",
       "   '_check_reactome_pw_index': {'name': '_check_reactome_pw_index',\n",
       "    'signature': 'napistu.ingestion.reactome._check_reactome_pw_index(pw_index:PWIndex,reactome_pathway_list:list)',\n",
       "    'id': 'napistu.ingestion.reactome._check_reactome_pw_index',\n",
       "    'doc': 'Compare local files defined in the pathway index to a list of Reactome’s pathways.'},\n",
       "   '_get_reactome_pathway_list': {'name': '_get_reactome_pathway_list',\n",
       "    'signature': 'napistu.ingestion.reactome._get_reactome_pathway_list()',\n",
       "    'id': 'napistu.ingestion.reactome._get_reactome_pathway_list',\n",
       "    'doc': 'Reactome Pathway List\\nProduce a pd.DataFrame listing all pathways in reactome and their internal ids Parameters : None Returns : pd.DataFrame containing pathway_id, name and species'},\n",
       "   'construct_reactome_consensus': {'name': 'construct_reactome_consensus',\n",
       "    'signature': 'napistu.ingestion.reactome.construct_reactome_consensus(pw_index_inp:str|PWIndex,species:str|Iterable[str]|None=None,outdir:str|None=None,strict:bool=True)→SBML_dfs',\n",
       "    'id': 'napistu.ingestion.reactome.construct_reactome_consensus',\n",
       "    'doc': 'Constructs a basic consensus model by merging all models from a pw_index Parameters : pw_index_inp ( str | indices.PWIndex ) – PWIndex or uri pointing to PWIndex species ( str | Iterable [ str ] | None ) – one or more species to filter by. Default: no filtering outdir ( str | None , optional ) – output directory used to cache results. Defaults to None. strict ( bool ) – should failure of loading any given model throw an exception? If False a warning is thrown. Returns : A consensus SBML Return type : sbml_dfs_core.SBML_dfs'},\n",
       "   'reactome_sbml_download': {'name': 'reactome_sbml_download',\n",
       "    'signature': 'napistu.ingestion.reactome.reactome_sbml_download(output_dir_path:str,overwrite:bool=False)',\n",
       "    'id': 'napistu.ingestion.reactome.reactome_sbml_download',\n",
       "    'doc': 'Reactome SBML Download Download Reactome SBML (systems biology markup language) for all reactome species. Parameters : output_dir_path ( str ) – Paths to a directory where .sbml files should be saved. overwrite ( bool ) – Overwrite an existing output directory. Default: False'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.sbml': {'module': 'napistu.ingestion.sbml',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.sbml.html#module-napistu.ingestion.sbml',\n",
       "  'functions': {'_get_gene_product_dict': {'name': '_get_gene_product_dict',\n",
       "    'signature': 'napistu.ingestion.sbml._get_gene_product_dict(gp)',\n",
       "    'id': 'napistu.ingestion.sbml._get_gene_product_dict',\n",
       "    'doc': 'Read a gene product node from an sbml file.'},\n",
       "   'add_sbml_annotations': {'name': 'add_sbml_annotations',\n",
       "    'signature': 'napistu.ingestion.sbml.add_sbml_annotations(sbml_model:SBML,annotations:DataFrame,save_path:str)→None',\n",
       "    'id': 'napistu.ingestion.sbml.add_sbml_annotations',\n",
       "    'doc': 'Add SBML Annotations Add additional identifiers to an sbml file and save the updated document Parameters:\\nsbml_model: SBML A .sbml model annotations: pd.DataFrame A table of annotations to add containing an “id” matching the\\nprimary key of an entity, “type” matching the type of entity,\\nand “uri” representing the annotation to add. save_path: str Path to save the model to Returns:\\nNone'},\n",
       "   'sbml_df_from_sbml': {'name': 'sbml_df_from_sbml',\n",
       "    'signature': 'napistu.ingestion.sbml.sbml_df_from_sbml(self,sbml_model:SBML)',\n",
       "    'id': 'napistu.ingestion.sbml.sbml_df_from_sbml',\n",
       "    'doc': ''},\n",
       "   'setup_cspecies': {'name': 'setup_cspecies',\n",
       "    'signature': 'napistu.ingestion.sbml.setup_cspecies(sbml_model:SBML)→DataFrame',\n",
       "    'id': 'napistu.ingestion.sbml.setup_cspecies',\n",
       "    'doc': 'Setup Compartmentalized Species Read all compartmentalized species from a model\\nand setup as a pd.DataFrame.\\nThis operation is functionalized to test the subsequent call of\\nconsensus.reduce_to_consensus_ids()\\nwhich collapses compartmentalized_species -> species\\nbased on shared identifiers.'}},\n",
       "  'classes': {'SBML': {'name': 'SBML',\n",
       "    'signature': 'classnapistu.ingestion.sbml.SBML(sbml_path:str)',\n",
       "    'id': 'napistu.ingestion.sbml.SBML',\n",
       "    'doc': 'Bases: object System Biology Markup Language Connections. document \\uf0c1 Connection to the SBML document model \\uf0c1 Connection to the SBML model summary ( ) \\uf0c1 Prints a summary of the sbml model sbml_errors ( reduced_log , return_df ) \\uf0c1 Print a summary of all errors in the SBML file __init__ ( sbml_path : str ) → None \\uf0c1 Connects to an SBML file Parameters : sbml_path ( str ) – path to a .sbml file. Return type : None. sbml_errors ( reduced_log : bool = True , return_df : bool = False ) \\uf0c1 Format and print all SBML errors Parameters : reduced_log ( bool ) – Reduced log aggregates errors across categories an severity levels return_df ( bool ) – If False then print a log, if True then return a pd.DataFrame Return type : None or pd.DataFrame. summary ( ) → DataFrame \\uf0c1 Returns a pd.DataFrame summary of an SBML model.',\n",
       "    'methods': {'summary': {'name': 'summary',\n",
       "      'signature': 'summary()→DataFrame',\n",
       "      'id': 'id1',\n",
       "      'doc': 'Returns a pd.DataFrame summary of an SBML model.'},\n",
       "     'sbml_errors': {'name': 'sbml_errors',\n",
       "      'signature': 'sbml_errors(reduced_log:bool=True,return_df:bool=False)',\n",
       "      'id': 'id0',\n",
       "      'doc': 'Format and print all SBML errors Parameters : reduced_log ( bool ) – Reduced log aggregates errors across categories an severity levels return_df ( bool ) – If False then print a log, if True then return a pd.DataFrame Return type : None or pd.DataFrame.'},\n",
       "     '__init__': {'name': '__init__',\n",
       "      'signature': '__init__(sbml_path:str)→None',\n",
       "      'id': 'napistu.ingestion.sbml.SBML.__init__',\n",
       "      'doc': 'Connects to an SBML file Parameters : sbml_path ( str ) – path to a .sbml file. Return type : None.'}},\n",
       "    'attributes': {'document': {'name': 'document',\n",
       "      'signature': 'document',\n",
       "      'id': 'napistu.ingestion.sbml.SBML.document',\n",
       "      'doc': 'Connection to the SBML document'},\n",
       "     'model': {'name': 'model',\n",
       "      'signature': 'model',\n",
       "      'id': 'napistu.ingestion.sbml.SBML.model',\n",
       "      'doc': 'Connection to the SBML model'}}},\n",
       "   'SBML_reaction': {'name': 'SBML_reaction',\n",
       "    'signature': 'classnapistu.ingestion.sbml.SBML_reaction(sbml_reaction:Reaction)',\n",
       "    'id': 'napistu.ingestion.sbml.SBML_reaction',\n",
       "    'doc': 'Bases: object System Biology Markup Language Model Reactions. reaction_dict \\uf0c1 dictionary of reaction-level attributes, id, name, identifiers Type : dict species \\uf0c1 table of substrates, products, and modifiers Type : pd.DataFrame __init__ ( sbml_reaction : Reaction ) → None \\uf0c1 Convenience class for working with sbml reactions',\n",
       "    'methods': {'__init__': {'name': '__init__',\n",
       "      'signature': '__init__(sbml_reaction:Reaction)→None',\n",
       "      'id': 'napistu.ingestion.sbml.SBML_reaction.__init__',\n",
       "      'doc': 'Convenience class for working with sbml reactions'}},\n",
       "    'attributes': {'reaction_dict': {'name': 'reaction_dict',\n",
       "      'signature': 'reaction_dict',\n",
       "      'id': 'napistu.ingestion.sbml.SBML_reaction.reaction_dict',\n",
       "      'doc': 'dictionary of reaction-level attributes, id, name, identifiers Type : dict'},\n",
       "     'species': {'name': 'species',\n",
       "      'signature': 'species',\n",
       "      'id': 'napistu.ingestion.sbml.SBML_reaction.species',\n",
       "      'doc': 'table of substrates, products, and modifiers Type : pd.DataFrame'}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.string': {'module': 'napistu.ingestion.string',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.string.html#module-napistu.ingestion.string',\n",
       "  'functions': {'_build_interactor_edgelist': {'name': '_build_interactor_edgelist',\n",
       "    'signature': \"napistu.ingestion.string._build_interactor_edgelist(edgelist:DataFrame,upstream_col_name:str='protein1',downstream_col_name:str='protein2',add_reverse_interactions:bool=False,sbo_term:str='interactor',compartment:str='cellular_component')→DataFrame\",\n",
       "    'id': 'napistu.ingestion.string._build_interactor_edgelist',\n",
       "    'doc': 'Format STRING interactions as reactions.'},\n",
       "   '_build_species_df': {'name': '_build_species_df',\n",
       "    'signature': \"napistu.ingestion.string._build_species_df(edgelist:DataFrame,aliases:DataFrame,alias_to_identifier:dict,source_col:str='protein1',target_col:str='protein2')→DataFrame\",\n",
       "    'id': 'napistu.ingestion.string._build_species_df',\n",
       "    'doc': 'Builds the species dataframe from the edgelist and aliases Parameters : edgelist ( pd.DataFrame ) – edgelist aliases ( pd.DataFrame ) – aliases alias_to_identifier ( dict [ str , tuple [ str , str ] ] ) – map from an alias source to an ontology and a qualifier Returns : species dataframe Return type : pd.DataFrame'},\n",
       "   '_build_string_reaction_name': {'name': '_build_string_reaction_name',\n",
       "    'signature': 'napistu.ingestion.string._build_string_reaction_name(from_col:Series,to_col:Series)→Series',\n",
       "    'id': 'napistu.ingestion.string._build_string_reaction_name',\n",
       "    'doc': 'Helper to build the reaction name for string reactions Parameters : from_col ( pd.Series ) – from species to_col ( pd.Series ) – to species Returns : new name column Return type : pd.Series'},\n",
       "   '_get_identifiers': {'name': '_get_identifiers',\n",
       "    'signature': 'napistu.ingestion.string._get_identifiers(row:DataFrame,alias_to_identifier:dict[str,tuple[str,str]],dat_alias:DataFrame)→Identifiers',\n",
       "    'id': 'napistu.ingestion.string._get_identifiers',\n",
       "    'doc': 'Helper function to get identifiers from a row of the string alias file Parameters : row ( pd.DataFrame ) – grouped dataframe alias_to_identifier ( dict [ str , tuple [ str , str ] ] ) – map from an alias source to an ontology and a qualifier dat_alias ( pd.DataFrame ) – Helper dataframe with index=string_protein_id\\nand columns=source (the source name), alias (the identifier) Returns : An Identifiers object containing all identifiers Return type : identifiers.Identifiers'},\n",
       "   '_read_string': {'name': '_read_string',\n",
       "    'signature': 'napistu.ingestion.string._read_string(string_uri:str)→DataFrame',\n",
       "    'id': 'napistu.ingestion.string._read_string',\n",
       "    'doc': 'Reads string from uri Parameters : string_uri ( str ) – string uri Returns : string edgelist Return type : pd.DataFrame'},\n",
       "   '_read_string_aliases': {'name': '_read_string_aliases',\n",
       "    'signature': 'napistu.ingestion.string._read_string_aliases(string_aliases_uri:str)→DataFrame',\n",
       "    'id': 'napistu.ingestion.string._read_string_aliases',\n",
       "    'doc': 'Reads string from uri Parameters : string_aliases_uri ( str ) – string aliases uri Returns : string aliases Return type : pd.DataFrame'},\n",
       "   'convert_string_to_sbml_dfs': {'name': 'convert_string_to_sbml_dfs',\n",
       "    'signature': 'napistu.ingestion.string.convert_string_to_sbml_dfs(string_uri:str,string_aliases_uri:str)→SBML_dfs',\n",
       "    'id': 'napistu.ingestion.string.convert_string_to_sbml_dfs',\n",
       "    'doc': 'Ingests string to sbml dfs Parameters : string_uri ( str ) – string uri string_aliases_uri ( str ) – string aliases uri Returns : sbml dfs Return type : sbml_dfs_core.SBML_dfs'},\n",
       "   'download_string': {'name': 'download_string',\n",
       "    'signature': 'napistu.ingestion.string.download_string(target_uri:str,species:str)→None',\n",
       "    'id': 'napistu.ingestion.string.download_string',\n",
       "    'doc': 'Downloads string to the target uri Parameters : target_uri ( str ) – target url species ( str ) – A species name: e.g., Homo sapiens Returns : None'},\n",
       "   'download_string_aliases': {'name': 'download_string_aliases',\n",
       "    'signature': 'napistu.ingestion.string.download_string_aliases(target_uri:str,species:str)→None',\n",
       "    'id': 'napistu.ingestion.string.download_string_aliases',\n",
       "    'doc': 'Downloads string aliases to the target uri Parameters : target_uri ( str ) – target url species ( str ) – A species name: e.g., Homo sapiens Returns : None'},\n",
       "   'get_string_species_url': {'name': 'get_string_species_url',\n",
       "    'signature': 'napistu.ingestion.string.get_string_species_url(species:str,asset:str,version:float=11.5)→str',\n",
       "    'id': 'napistu.ingestion.string.get_string_species_url',\n",
       "    'doc': 'STRING Species URL\\nConstruct urls for downloading specific STRING tables\\n:param species: A species name: e.g., Homo sapiens.\\n:type species: str\\n:param asset: The type of table to be downloaded. Currently “interactions” or “aliases”.\\n:type asset: str\\n:param version: The version of STRING to work with.\\n:type version: float Returns : The download url Return type : str'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.trrust': {'module': 'napistu.ingestion.trrust',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.trrust.html#module-napistu.ingestion.trrust',\n",
       "  'functions': {'_format_pubmed_for_interactions': {'name': '_format_pubmed_for_interactions',\n",
       "    'signature': 'napistu.ingestion.trrust._format_pubmed_for_interactions(pubmed_set)',\n",
       "    'id': 'napistu.ingestion.trrust._format_pubmed_for_interactions',\n",
       "    'doc': 'Format a set of pubmed ids as an Identifiers object.'},\n",
       "   '_get_uniprot_2_symbol_mapping': {'name': '_get_uniprot_2_symbol_mapping',\n",
       "    'signature': 'napistu.ingestion.trrust._get_uniprot_2_symbol_mapping()→DataFrame',\n",
       "    'id': 'napistu.ingestion.trrust._get_uniprot_2_symbol_mapping',\n",
       "    'doc': 'Create a mapping from Uniprot IDs to human gene symbols.'},\n",
       "   '_read_trrust': {'name': '_read_trrust',\n",
       "    'signature': 'napistu.ingestion.trrust._read_trrust(trrust_uri:str)→DataFrame',\n",
       "    'id': 'napistu.ingestion.trrust._read_trrust',\n",
       "    'doc': 'Read trrust csv Parameters : trrust_uri ( str ) – uri to the trrust csv Returns : Data Frame Return type : pd.DataFrame'},\n",
       "   '_summarize_trrust_pairs': {'name': '_summarize_trrust_pairs',\n",
       "    'signature': 'napistu.ingestion.trrust._summarize_trrust_pairs(pair_data:DataFrame)→Series',\n",
       "    'id': 'napistu.ingestion.trrust._summarize_trrust_pairs',\n",
       "    'doc': 'Summarize a TF->target relationship based on the sign and source of the interaction.'},\n",
       "   'convert_trrust_to_sbml_dfs': {'name': 'convert_trrust_to_sbml_dfs',\n",
       "    'signature': 'napistu.ingestion.trrust.convert_trrust_to_sbml_dfs(trrust_uri:str)→SBML_dfs',\n",
       "    'id': 'napistu.ingestion.trrust.convert_trrust_to_sbml_dfs',\n",
       "    'doc': 'Ingests trrust to sbml dfs Parameters : trrust_uri ( str ) – trrust uri Returns : sbml_dfs'},\n",
       "   'download_trrust': {'name': 'download_trrust',\n",
       "    'signature': 'napistu.ingestion.trrust.download_trrust(target_uri:str)→None',\n",
       "    'id': 'napistu.ingestion.trrust.download_trrust',\n",
       "    'doc': 'Downloads trrust to the target uri Parameters : target_uri ( str ) – target url Returns : None'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.ingestion.yeast': {'module': 'napistu.ingestion.yeast',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.yeast.html#module-napistu.ingestion.yeast',\n",
       "  'functions': {'_summarize_idea_pairs': {'name': '_summarize_idea_pairs',\n",
       "    'signature': 'napistu.ingestion.yeast._summarize_idea_pairs(pairs_data:DataFrame)→Series',\n",
       "    'id': 'napistu.ingestion.yeast._summarize_idea_pairs',\n",
       "    'doc': 'Rollup multiple records of a TF->target pair into a single summary.'},\n",
       "   'convert_idea_kinetics_to_sbml_dfs': {'name': 'convert_idea_kinetics_to_sbml_dfs',\n",
       "    'signature': 'napistu.ingestion.yeast.convert_idea_kinetics_to_sbml_dfs(idea_path:str)→SBML_dfs',\n",
       "    'id': 'napistu.ingestion.yeast.convert_idea_kinetics_to_sbml_dfs',\n",
       "    'doc': 'Convert IDEA Kinetics to SBML DFs Format yeast induction regulator->target relationships as a directed graph. Parameters : idea_path – Path to the IDEA Kinetics file. Returns : an SBML_dfs object containing molecular species and their interactions.\\nKinetic attributes are included as reactions_data. Return type : SBML_dfs'},\n",
       "   'download_idea': {'name': 'download_idea',\n",
       "    'signature': 'napistu.ingestion.yeast.download_idea(output_dir:str)→None',\n",
       "    'id': 'napistu.ingestion.yeast.download_idea',\n",
       "    'doc': ''}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.mechanism_matching': {'module': 'napistu.mechanism_matching',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.mechanism_matching.html#module-napistu.mechanism_matching',\n",
       "  'functions': {'_aggregate_grouped_columns': {'name': '_aggregate_grouped_columns',\n",
       "    'signature': \"napistu.mechanism_matching._aggregate_grouped_columns(df:DataFrame,numeric_cols,non_numeric_cols,numeric_aggregator,feature_id_var:str='feature_id',numeric_agg:str='weighted_mean')→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching._aggregate_grouped_columns',\n",
       "    'doc': 'Aggregate numeric and non-numeric columns for grouped DataFrame.\\nAssumes deduplication by feature_id within each s_id has already been performed.\\nReturns the combined DataFrame.'},\n",
       "   '_edgelist_to_scids_if_needed': {'name': '_edgelist_to_scids_if_needed',\n",
       "    'signature': 'napistu.mechanism_matching._edgelist_to_scids_if_needed(edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,ontologies:set)→DataFrame',\n",
       "    'id': 'napistu.mechanism_matching._edgelist_to_scids_if_needed',\n",
       "    'doc': 'Map a set of edgelist species to cspecies or skip if cspecies were provided.'},\n",
       "   '_ensure_feature_id_var': {'name': '_ensure_feature_id_var',\n",
       "    'signature': \"napistu.mechanism_matching._ensure_feature_id_var(df:DataFrame,feature_id_var:str='feature_id')→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching._ensure_feature_id_var',\n",
       "    'doc': 'Ensure the DataFrame has a feature_id column, creating one if it doesn’t exist. Parameters : df ( pd.DataFrame ) – DataFrame to check/modify feature_id_var ( str , default=FEATURE_ID_VAR_DEFAULT ) – Name of the feature ID column Returns : DataFrame with guaranteed feature_id column Return type : pd.DataFrame'},\n",
       "   '_get_numeric_aggregator': {'name': '_get_numeric_aggregator',\n",
       "    'signature': \"napistu.mechanism_matching._get_numeric_aggregator(method:str='weighted_mean',feature_id_var:str='feature_id')→callable\",\n",
       "    'id': 'napistu.mechanism_matching._get_numeric_aggregator',\n",
       "    'doc': 'Get aggregation function for numeric columns with various methods. Parameters : method ( str , default=\"weighted_mean\" ) – Aggregation method to use:\\n- “weighted_mean”: weighted by inverse of feature_id frequency (default)\\n- “mean”: simple arithmetic mean\\n- “first”: first value after sorting by feature_id_var (requires feature_id_var)\\n- “max”: maximum value feature_id_var ( str , default=\"feature_id\" ) – Name of the column specifying a measured feature - used for sorting and weighting Returns : Aggregation function to use with groupby Return type : callable Raises : ValueError – If method is not recognized'},\n",
       "   '_log_feature_species_mapping_stats': {'name': '_log_feature_species_mapping_stats',\n",
       "    'signature': \"napistu.mechanism_matching._log_feature_species_mapping_stats(pathway_species:DataFrame,feature_id_var:str='feature_id')\",\n",
       "    'id': 'napistu.mechanism_matching._log_feature_species_mapping_stats',\n",
       "    'doc': 'Log statistics about the mapping between feature_id and s_id in the pathway_species DataFrame.'},\n",
       "   '_split_numeric_non_numeric_columns': {'name': '_split_numeric_non_numeric_columns',\n",
       "    'signature': 'napistu.mechanism_matching._split_numeric_non_numeric_columns(df:DataFrame,always_non_numeric=None)',\n",
       "    'id': 'napistu.mechanism_matching._split_numeric_non_numeric_columns',\n",
       "    'doc': 'Utility to split DataFrame columns into numeric and non-numeric, always treating specified columns as non-numeric. Parameters : df ( pd.DataFrame ) – The DataFrame to split. always_non_numeric ( list or set , optional ) – Columns to always treat as non-numeric (e.g., [‘feature_id’]). Returns : numeric_cols ( pd.Index ) – Columns considered numeric (int64, float64, and not in always_non_numeric). non_numeric_cols ( pd.Index ) – Columns considered non-numeric (object, string, etc., plus always_non_numeric).'},\n",
       "   '_validate_wide_ontologies': {'name': '_validate_wide_ontologies',\n",
       "    'signature': 'napistu.mechanism_matching._validate_wide_ontologies(wide_df:DataFrame,ontologies:str|Set[str]|Dict[str,str]|None=None)→Set[str]',\n",
       "    'id': 'napistu.mechanism_matching._validate_wide_ontologies',\n",
       "    'doc': 'Validate ontology specifications against the wide DataFrame and ONTOLOGIES_LIST. Parameters : wide_df ( pd.DataFrame ) – DataFrame with one column per ontology and a results column ontologies ( Optional [ Union [ str , Set [ str ] , Dict [ str , str ] ] ] ) – Either:\\n- String specifying a single ontology column\\n- Set of columns to treat as ontologies\\n- Dict mapping wide column names to ontology names\\n- None to automatically detect ontology columns based on ONTOLOGIES_LIST Returns : Set of validated ontology names. For dictionary mappings, returns the target ontology names. Return type : Set[str] Raises : ValueError – If validation fails for any ontology specification or no valid ontologies are found'},\n",
       "   'bind_wide_results': {'name': 'bind_wide_results',\n",
       "    'signature': \"napistu.mechanism_matching.bind_wide_results(sbml_dfs:SBML_dfs,results_df:DataFrame,results_name:str,ontologies:Set[str]|Dict[str,str]|None=None,dogmatic:bool=False,species_identifiers:DataFrame|None=None,feature_id_var:str='feature_id',numeric_agg:str='weighted_mean',keep_id_col:bool=True,verbose:bool=False)→SBML_dfs\",\n",
       "    'id': 'napistu.mechanism_matching.bind_wide_results',\n",
       "    'doc': 'Binds wide results to a sbml_dfs object. Take a table with molecular species-level attributes tied to systematic identifiers and match them to an sbml_dfs_model transferring these attributes to species_data Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The sbml_dfs object to bind the results to. results_df ( pd.DataFrame ) – The table containing the results to bind. results_name ( str ) – The name of the results to bind. ontologies ( Optional [ Union [ Set [ str ] , Dict [ str , str ] ] ] , default=None ) – Either:\\n- Set of columns to treat as ontologies (these should be entries in ONTOLOGIES_LIST )\\n- Dict mapping wide column names to ontology names in the ONTOLOGIES_LIST controlled vocabulary\\n- None to automatically detect valid ontology columns based on ONTOLOGIES_LIST dogmatic ( bool ) – Whether to respect differences between genes, transcripts, and proteins (True) or ignore them (False). species_identifiers ( Optional [ pd.DataFrame ] ) – Systematic identifiers for the molecular species “sbml_dfs”. If None this will be generate on-the-fly. feature_id_var ( str ) – The name of the column in the results_df that contains the feature identifiers. If this does not exist it will be created. numeric_agg ( str ) – The aggregation method to use for resolving degeneracy. keep_id_col ( bool ) – Whether to keep the identifier column in the results_df. verbose ( bool ) – Whether to log cases of 1-to-many and many-to-one mapping and to indicate the behavior for resolving degeneracy Returns : sbml_dfs – The sbml_dfs object with the results bound. Return type : sbml_dfs_core.SBML_dfs'},\n",
       "   'edgelist_to_pathway_species': {'name': 'edgelist_to_pathway_species',\n",
       "    'signature': \"napistu.mechanism_matching.edgelist_to_pathway_species(formatted_edgelist:DataFrame,species_identifiers:DataFrame,ontologies:set,feature_id_var:str='feature_id',verbose:bool=False)→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching.edgelist_to_pathway_species',\n",
       "    'doc': 'Edgelist to Pathway Species Match an edgelist of molecular species pairs to their corresponding species in a pathway representation. Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and “identifier_downstream” variables used to to match entries species_identifiers: pd.DataFrame A table of molecular species identifiers produced from sbml_dfs.get_identifiers(“species”) generally using\\nsbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species feature_id_var: str, default=FEATURE_ID_VAR_DEFAULT Variable in “formatted_edgelist” containing feature ids verbose: bool, default=False Whether to print verbose output Returns:\\nedges_on_pathway: pd.DataFrame formatted_edgelist with upstream features mapped\\nto “s_id_upstream” and downstream species mapped\\nto “s_id_downstream”'},\n",
       "   'edgelist_to_scids': {'name': 'edgelist_to_scids',\n",
       "    'signature': 'napistu.mechanism_matching.edgelist_to_scids(formatted_edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,ontologies:set)',\n",
       "    'id': 'napistu.mechanism_matching.edgelist_to_scids',\n",
       "    'doc': 'Edgelist to Compartmentalized Species IDds Map an edgelist of possible mechanistic interactions onto a\\npathadex pathway Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and\\n“identifier_downstream” variables used to to match entries sbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model species_identifiers: pd.DataFrame A table of molecular species identifiers produced from\\nsbml_dfs.get_identifiers(“species”) generally using sbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species Returns:\\nedgelist_w_scids: pd.DataFrame formatted_edgelist with upstream features mapped to “sc_id_upstream” and\\ndownstream species mapped to “sc_id_downstream”'},\n",
       "   'features_to_pathway_species': {'name': 'features_to_pathway_species',\n",
       "    'signature': \"napistu.mechanism_matching.features_to_pathway_species(feature_identifiers:DataFrame,species_identifiers:DataFrame,ontologies:set,feature_identifiers_var:str='identifier',feature_id_var:str='feature_id',expand_identifiers:bool=False,identifier_delimiter:str='/',verbose:bool=False)→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching.features_to_pathway_species',\n",
       "    'doc': 'Features to Pathway Species Match a table of molecular species to their corresponding species in a pathway representation. Parameters:\\nfeature_identifiers: pd.DataFrame pd.Dataframe containing a “feature_identifiers_var” variable used to match entries species_identifiers: pd.DataFrame A table of molecular species identifiers produced from sbml_dfs.get_identifiers(“species”)\\ngenerally using sbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species feature_identifiers_var: str Variable in “feature_identifiers” containing identifiers expand_identifiers: bool, default=False If True, split identifiers in feature_identifiers_var by identifier_delimiter and explode into multiple rows identifier_delimiter: str, default=”/” Delimiter to use for splitting identifiers if expand_identifiers is True verbose: bool, default=False If True, log mapping statistics at the end of the function Returns:\\npathway_species: pd.DataFrame species_identifiers joined to feature_identifiers based on shared identifiers'},\n",
       "   'filter_to_direct_mechanistic_interactions': {'name': 'filter_to_direct_mechanistic_interactions',\n",
       "    'signature': 'napistu.mechanism_matching.filter_to_direct_mechanistic_interactions(formatted_edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,ontologies:set)→DataFrame',\n",
       "    'id': 'napistu.mechanism_matching.filter_to_direct_mechanistic_interactions',\n",
       "    'doc': 'Filter to Direct Mechanistic Interactions Filter an edgelist to direct mechanistic interactions Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and “identifier_downstream” variables used to to match entries sbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model species_identifiers: pd.DataFrame A table of molecular species identifiers\\nproduced from sbml_dfs.get_identifiers(“species”) generally\\nusing sbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species Returns:\\nedgelist_w_direct_mechanistic_interactions: pd.DataFrame formatted_edgelist filtered to mechanistic reactions present in the pathway representation'},\n",
       "   'filter_to_indirect_mechanistic_interactions': {'name': 'filter_to_indirect_mechanistic_interactions',\n",
       "    'signature': 'napistu.mechanism_matching.filter_to_indirect_mechanistic_interactions(formatted_edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,cpr_graph:Graph,ontologies:set,precomputed_distances=None,max_path_length=10)',\n",
       "    'id': 'napistu.mechanism_matching.filter_to_indirect_mechanistic_interactions',\n",
       "    'doc': 'Filter to Indirect Mechanistic Interactions Filter an edgelist to indirect mechanistic interactions.\\nIndirect relationships are identified by searching a\\nnetwork for paths from an upstream species to a downstream species Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and\\n“identifier_downstream” variables used to to match entries sbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model species_identifiers: pandas.DataFrame A table of molecular species identifiers produced from\\nsbml_dfs.get_identifiers(“species”) generally using sbml_dfs_core.export_sbml_dfs() cpr_graph: igraph.Graph A network representation of the sbml_dfs model ontologies: set A set of ontologies used to match features to pathway species precomputed_distances: None or a pd.DataFrame containing path lengths and weights between pairs of cspecies. max_path_length: int Maximum number of steps to consider. Returns:\\nedgelist_w_indirect_mechanistic_interactions: pd.DataFrame formatted_edgelist filtered to mechanistic reactions which can be described\\nby an indirect mechanism. The mechanism is described by a path weight, length,\\nand a vpath and epath list of vertices and edges which were traversed to create the path.'},\n",
       "   'match_by_ontology_and_identifier': {'name': 'match_by_ontology_and_identifier',\n",
       "    'signature': \"napistu.mechanism_matching.match_by_ontology_and_identifier(feature_identifiers:DataFrame,species_identifiers:DataFrame,ontologies:str|Set[str]|List[str],feature_identifiers_var:str='identifier',verbose:bool=False)→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching.match_by_ontology_and_identifier',\n",
       "    'doc': 'Match features to pathway species based on both ontology and identifier matches.\\nPerforms separate matching for each ontology and concatenates the results. Parameters : feature_identifiers ( pd.DataFrame ) – DataFrame containing feature identifiers and results.\\nMust have columns [ontology, feature_identifiers_var, results] species_identifiers ( pd.DataFrame ) – DataFrame containing species identifiers from pathway.\\nMust have columns [ontology, identifier] ontologies ( Union [ str , Set [ str ] , List [ str ] ] ) – Ontologies to match on. Can be:\\n- A single ontology string\\n- A set of ontology strings\\n- A list of ontology strings feature_identifiers_var ( str , default=\"identifier\" ) – Name of the identifier column in feature_identifiers verbose ( bool , default=False ) – Whether to print verbose output Returns : Concatenated results of matching for each ontology.\\nContains all columns from features_to_pathway_species() Return type : pd.DataFrame Examples >>> # Match using a single ontology >>> result = match_by_ontology_and_identifier ( ... feature_identifiers = features_df , ... species_identifiers = species_df , ... ontologies = \"uniprot\" ... ) >>> # Match using multiple ontologies >>> result = match_by_ontology_and_identifier ( ... feature_identifiers = features_df , ... species_identifiers = species_df , ... ontologies = { \"uniprot\" , \"chebi\" } ... )'},\n",
       "   'match_features_to_wide_pathway_species': {'name': 'match_features_to_wide_pathway_species',\n",
       "    'signature': \"napistu.mechanism_matching.match_features_to_wide_pathway_species(wide_df:DataFrame,species_identifiers:DataFrame,ontologies:Set[str]|Dict[str,str]|None=None,feature_identifiers_var:str='identifier',feature_id_var:str='feature_id',verbose:bool=False)→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching.match_features_to_wide_pathway_species',\n",
       "    'doc': 'Convert a wide-format DataFrame with multiple ontology columns to long format,\\nand match features to pathway species by ontology and identifier. Parameters : wide_df ( pd.DataFrame ) – DataFrame with ontology identifier columns and any number of results columns.\\nAll non-ontology columns are treated as results. species_identifiers ( pd.DataFrame ) – DataFrame as required by features_to_pathway_species ontologies ( Optional [ Union [ Set [ str ] , Dict [ str , str ] ] ] , default=None ) – Either:\\n- Set of columns to treat as ontologies (these should be entries in ONTOLOGIES_LIST )\\n- Dict mapping wide column names to ontology names in the ONTOLOGIES_LIST controlled vocabulary\\n- None to automatically detect valid ontology columns based on ONTOLOGIES_LIST feature_identifiers_var ( str , default=\"identifier\" ) – Name for the identifier column in the long format feature_id_var ( str , default=FEATURE_ID_VAR_DEFAULT ) – Name for the feature id column in the long format verbose ( bool , default=False ) – Whether to print verbose output Returns : Output of match_by_ontology_and_identifier Return type : pd.DataFrame Examples >>> # Example with auto-detected ontology columns and multiple results >>> wide_df = pd . DataFrame ({ ... \\'uniprot\\' : [ \\'P12345\\' , \\'Q67890\\' ], ... \\'chebi\\' : [ \\'15377\\' , \\'16810\\' ], ... \\'log2fc\\' : [ 1.0 , 2.0 ], ... \\'pvalue\\' : [ 0.01 , 0.05 ] ... }) >>> result = match_features_to_wide_pathway_species ( ... wide_df = wide_df , ... species_identifiers = species_identifiers ... ) >>> # Example with custom ontology mapping >>> wide_df = pd . DataFrame ({ ... \\'protein_id\\' : [ \\'P12345\\' , \\'Q67890\\' ], ... \\'compound_id\\' : [ \\'15377\\' , \\'16810\\' ], ... \\'expression\\' : [ 1.0 , 2.0 ], ... \\'confidence\\' : [ 0.8 , 0.9 ] ... }) >>> result = match_features_to_wide_pathway_species ( ... wide_df = wide_df , ... species_identifiers = species_identifiers , ... ontologies = { \\'protein_id\\' : \\'uniprot\\' , \\'compound_id\\' : \\'chebi\\' } ... )'},\n",
       "   'resolve_matches': {'name': 'resolve_matches',\n",
       "    'signature': \"napistu.mechanism_matching.resolve_matches(matched_data:DataFrame,feature_id_var:str='feature_id',index_col:str='s_id',numeric_agg:str='weighted_mean',keep_id_col:bool=True)→DataFrame\",\n",
       "    'id': 'napistu.mechanism_matching.resolve_matches',\n",
       "    'doc': 'Resolve many-to-1 and 1-to-many matches in matched data. Parameters : matched_data ( pd.DataFrame ) – DataFrame containing matched data with columns:\\n- feature_id_var: identifier column (e.g. feature_id)\\n- index_col: index column (e.g. s_id)\\n- other columns: data columns to be aggregated feature_id_var ( str , default=\"feature_id\" ) – Name of the identifier column index_col ( str , default=\"s_id\" ) – Name of the column to use as index numeric_agg ( str , default=\"weighted_mean\" ) – Method to aggregate numeric columns:\\n- “weighted_mean”: weighted by inverse of feature_id frequency (default)\\n- “mean”: simple arithmetic mean\\n- “first”: first value after sorting by feature_id_var (requires feature_id_var)\\n- “max”: maximum value keep_id_col ( bool , default=True ) – Whether to keep and rollup the feature_id_var in the output.\\nIf False, feature_id_var will be dropped from the output. Returns : DataFrame with resolved matches:\\n- Many-to-1: numeric columns are aggregated using specified method\\n- 1-to-many: adds a count column showing number of matches\\n- Index is set to index_col and named accordingly Return type : pd.DataFrame Raises : KeyError – If feature_id_var is not present in the DataFrame TypeError – If DataFrame contains unsupported data types (boolean or datetime)'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.modify': {'module': 'napistu.modify',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.html#module-napistu.modify',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {'constants': {'url': 'napistu.modify.constants.html#module-napistu.modify.constants',\n",
       "    'description': 'Module to contain constants for the modify submodule'},\n",
       "   'curation': {'url': 'napistu.modify.curation.html#module-napistu.modify.curation',\n",
       "    'description': ''},\n",
       "   'gaps': {'url': 'napistu.modify.gaps.html#module-napistu.modify.gaps',\n",
       "    'description': ''},\n",
       "   'pathwayannot': {'url': 'napistu.modify.pathwayannot.html#module-napistu.modify.pathwayannot',\n",
       "    'description': ''},\n",
       "   'uncompartmentalize': {'url': 'napistu.modify.uncompartmentalize.html#module-napistu.modify.uncompartmentalize',\n",
       "    'description': ''}}},\n",
       " 'napistu.modify.constants': {'module': 'napistu.modify.constants',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.constants.html#module-napistu.modify.constants',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.modify.curation': {'module': 'napistu.modify.curation',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.curation.html#module-napistu.modify.curation',\n",
       "  'functions': {'_expand_entities_by_fks': {'name': '_expand_entities_by_fks',\n",
       "    'signature': 'napistu.modify.curation._expand_entities_by_fks(sbml_dfs:SBML_dfs,pk_dict:dict)→dict',\n",
       "    'id': 'napistu.modify.curation._expand_entities_by_fks',\n",
       "    'doc': 'Expand Entities By Foreign Keys Starting with a dictionary of foreign keys, add all primary keys that are defined by these foreign keys Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model pk_dict: dict Dictionary where keys are types of primary keys in sbml_dfs returns : pk_dict – Input where additional primary keys may have been added rtype : dict'},\n",
       "   '_find_invalid_entities': {'name': '_find_invalid_entities',\n",
       "    'signature': 'napistu.modify.curation._find_invalid_entities(sbml_dfs:SBML_dfs,invalid_entities:DataFrame)→dict[str,set]',\n",
       "    'id': 'napistu.modify.curation._find_invalid_entities',\n",
       "    'doc': 'Find Invalid Entities Based on a set of entity names or attributes, find each entities\\ncorresponding primary key Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model invalid_entities: pd.DataFrame A table containing entities to be removed (“remove”),\\nthe table where the entity resides (“table”) and variable used\\nto find the entity (“variable”) returns : invalid_entities_dict – A dictionary containing the primary keys of invalid entities rtype : dict'},\n",
       "   '_format_explicit_reaction_species': {'name': '_format_explicit_reaction_species',\n",
       "    'signature': 'napistu.modify.curation._format_explicit_reaction_species(curation_dict:dict[str,DataFrame])→DataFrame|None',\n",
       "    'id': 'napistu.modify.curation._format_explicit_reaction_species',\n",
       "    'doc': 'Format reaction species which are deirectly defined among curated species.'},\n",
       "   '_format_implicit_reaction_species': {'name': '_format_implicit_reaction_species',\n",
       "    'signature': 'napistu.modify.curation._format_implicit_reaction_species(curation_dict:dict[str,DataFrame])→DataFrame',\n",
       "    'id': 'napistu.modify.curation._format_implicit_reaction_species',\n",
       "    'doc': 'Construct reaction species which are defined in reactions’ stoichiometry.'},\n",
       "   '_remove_entities': {'name': '_remove_entities',\n",
       "    'signature': 'napistu.modify.curation._remove_entities(sbml_dfs:SBML_dfs,pk_dict:dict)→SBML_dfs',\n",
       "    'id': 'napistu.modify.curation._remove_entities',\n",
       "    'doc': 'Remove Entities Remove entities whose primary keys are in pk_dict Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model pk_dict: dict Dictionary where keys are types of primary keys in sbml_dfs returns : sbml_dfs – Input with some entities removed rtype : sbml_dfs_core.SBML_dfs'},\n",
       "   'curate_sbml_dfs': {'name': 'curate_sbml_dfs',\n",
       "    'signature': 'napistu.modify.curation.curate_sbml_dfs(curation_dir:str,sbml_dfs:SBML_dfs,verbose:bool=True)→SBML_dfs',\n",
       "    'id': 'napistu.modify.curation.curate_sbml_dfs',\n",
       "    'doc': 'Curate SBML_dfs Update a pathway model using manual annotations. The current workflow is to:\\n- annotate pathways in https://docs.google.com/spreadsheets/d/1waVXSVMOthL5QAT0PITgLMDdXGHIS50LZ2P1_F_c-6s/edit#gid=101210748 - parse annotations into flat files using parse_manual_annotation.Rmd\\n- call this function to format flat files and update a current SBML_dfs pathway model Params \\uf0c1 curation_dir: str Directory containing annotations generated using parse_manual_annotation.Rmd sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model verbose: bool Extra reporting returns : sbml_df – A curated pathway model rtype : sbml_dfs_core.SBML_dfs'},\n",
       "   'format_curated_entities': {'name': 'format_curated_entities',\n",
       "    'signature': \"napistu.modify.curation.format_curated_entities(entity_type:str,new_curated_entities:dict[Any,DataFrame],new_entities:dict[str,DataFrame],sbml_dfs:SBML_dfs,curation_id:str='Calicocurations')→DataFrame\",\n",
       "    'id': 'napistu.modify.curation.format_curated_entities',\n",
       "    'doc': 'Format Curated Entities Convert entities from the curation format to the stucture of SBML_dfs tables Params \\uf0c1 entity_type: str The type of entity to update (e.g., reactions, species, …) new_curated_entities: dict Curation pd.DataFrames generated using read_pathway_curations new_entities: dict Curations formatted as sbml_dfs_core.SBML_dfs tables sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model curation_id: str Name to use as a pathway id in source.Source objects returns : new_entity_df – Input for entity_type formatted as an SBML_dfs table rtype : pd.DataFrame'},\n",
       "   'format_curations': {'name': 'format_curations',\n",
       "    'signature': 'napistu.modify.curation.format_curations(curation_dict:dict[str,DataFrame],sbml_dfs:SBML_dfs)→dict[str,DataFrame]',\n",
       "    'id': 'napistu.modify.curation.format_curations',\n",
       "    'doc': 'Format Curations Format manual curations into a set of table that can be appended to an sbml_dfs’s tables Params \\uf0c1 curation_dict: Curations imported using read_pathway_curations sbml_dfs: A pathway model returns : new_entities – Curations formatted as sbml_dfs_core.SBML_dfs tables rtype : dict'},\n",
       "   'read_pathway_curations': {'name': 'read_pathway_curations',\n",
       "    'signature': 'napistu.modify.curation.read_pathway_curations(curation_dir:str)→dict[str,DataFrame]',\n",
       "    'id': 'napistu.modify.curation.read_pathway_curations',\n",
       "    'doc': 'Read Pathway Curations Load curations that were prepared by parse_manual_annotations.Rmd Params \\uf0c1 curation_dir: str Directory containing annotations generated using parse_manual_annotation.Rmd returns : curations – Dictionary containing different types of annoations rtype : dict'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.modify.gaps': {'module': 'napistu.modify.gaps',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.gaps.html#module-napistu.modify.gaps',\n",
       "  'functions': {'_add_new_exchange_cspecies': {'name': '_add_new_exchange_cspecies',\n",
       "    'signature': 'napistu.modify.gaps._add_new_exchange_cspecies(new_exchange_cspecies:set,sbml_dfs:SBML_dfs,exchange_compartment_id:str,exchange_compartment:str,gap_filling_source_obj:Source)→DataFrame',\n",
       "    'id': 'napistu.modify.gaps._add_new_exchange_cspecies',\n",
       "    'doc': 'Add new compartmentalized species to the exchange compartment. Parameters : new_exchange_cspecies ( set ) – Set of s_ids needing new compartmentalized species in the exchange compartment. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object exchange_compartment_id ( str ) – The compartment ID for the exchange compartment exchange_compartment ( str ) – The name of the exchange compartment gap_filling_source_obj ( source.Source ) – Source object for gap-filling Returns : DataFrame of new compartmentalized species to add. Return type : pd.DataFrame'},\n",
       "   '_build_transport_rxn_edgelist': {'name': '_build_transport_rxn_edgelist',\n",
       "    'signature': 'napistu.modify.gaps._build_transport_rxn_edgelist(updated_sbml_dfs:SBML_dfs,species_needing_transport_rxns:ndarray,exchange_compartment_id:str)→DataFrame',\n",
       "    'id': 'napistu.modify.gaps._build_transport_rxn_edgelist',\n",
       "    'doc': 'Build the edgelist for new transport reactions, ensuring only one reversible reaction per compartment pair. Parameters : updated_sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The updated SBML_dfs object species_needing_transport_rxns ( np.ndarray ) – Vector of molecular species (s_ids) with no or insufficient transportation reactions exchange_compartment_id ( str ) – The compartment ID for the exchange compartment Returns : Edgelist for new transport reactions. Return type : pd.DataFrame'},\n",
       "   '_create_new_reaction_species': {'name': '_create_new_reaction_species',\n",
       "    'signature': 'napistu.modify.gaps._create_new_reaction_species(transport_rxn_edgelist:DataFrame,sbml_dfs:SBML_dfs)→DataFrame',\n",
       "    'id': 'napistu.modify.gaps._create_new_reaction_species',\n",
       "    'doc': 'Create new reaction species DataFrame for gap-filling transport reactions. Parameters : transport_rxn_edgelist ( pd.DataFrame ) – Edgelist for new transport reactions. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object Returns : DataFrame of new reaction species to add. Return type : pd.DataFrame'},\n",
       "   '_create_new_reactions': {'name': '_create_new_reactions',\n",
       "    'signature': 'napistu.modify.gaps._create_new_reactions(transport_rxn_edgelist:DataFrame,sbml_dfs:SBML_dfs,gap_filling_id_obj:Identifiers,gap_filling_source_obj:Source)→DataFrame',\n",
       "    'id': 'napistu.modify.gaps._create_new_reactions',\n",
       "    'doc': 'Create new reactions DataFrame for gap-filling transport reactions. Parameters : transport_rxn_edgelist ( pd.DataFrame ) – Edgelist for new transport reactions. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object gap_filling_id_obj ( identifiers.Identifiers ) – Identifiers object for gap-filling gap_filling_source_obj ( source.Source ) – Source object for gap-filling Returns : DataFrame of new reactions to add. Return type : pd.DataFrame'},\n",
       "   '_eval_existing_inter_cspecies_paths': {'name': '_eval_existing_inter_cspecies_paths',\n",
       "    'signature': 'napistu.modify.gaps._eval_existing_inter_cspecies_paths(comp_specs:DataFrame,existing_cspecies_paths:DataFrame)→dict',\n",
       "    'id': 'napistu.modify.gaps._eval_existing_inter_cspecies_paths',\n",
       "    'doc': 'Evaluate whether paths between compartments found in _find_existing_inter_cspecies_paths cover all of the compartments where the protein exists. Parameters : comp_specs ( pd.DataFrame ) – Compartmentalized species for a single s_id existing_cspecies_paths ( pd.DataFrame ) – An edgelist of a from and to compartmentalized species and a label of the path connecting them. Returns : type: the status category the species falls in\\nmsg: an optional message describing the type Return type : dict'},\n",
       "   '_find_existing_inter_cspecies_paths': {'name': '_find_existing_inter_cspecies_paths',\n",
       "    'signature': 'napistu.modify.gaps._find_existing_inter_cspecies_paths(comp_specs:DataFrame,uniprot_id:str,directed_graph:Graph,partial_protein_cspecies:DataFrame)→DataFrame|None',\n",
       "    'id': 'napistu.modify.gaps._find_existing_inter_cspecies_paths',\n",
       "    'doc': 'Find which compartments a protein exists in can be reached from one another by traversing a directed graph of reactions and molecular species including the protein. Parameters : comp_specs ( pd.DataFrame ) – Compartmentalized species for a single s_id uniprot_id ( str ) – The Uniprot ID for the protein of interest directed_graph ( ig.Graph ) – An igraph version of the sbml_dfs model partial_protein_cspecies ( pd.DataFrame ) – A table of proteins included in each species ID (this includes BQB_HAS_PART qualifiers in addition to the BQB_IS qualifiers which generally define distinct species Returns : An edgelist of a from and to compartmentalized species and a label of the path connecting them. Return type : pd.DataFrame or None'},\n",
       "   '_find_new_exchange_cspecies': {'name': '_find_new_exchange_cspecies',\n",
       "    'signature': 'napistu.modify.gaps._find_new_exchange_cspecies(species_needing_transport_rxns:ndarray,sbml_dfs:SBML_dfs,exchange_compartment_id:str)→set',\n",
       "    'id': 'napistu.modify.gaps._find_new_exchange_cspecies',\n",
       "    'doc': 'Find species which need exchange reactions but are not currently present in the exchange compartment. Parameters : species_needing_transport_rxns ( np.ndarray ) – Vector of molecular species (s_ids) with no or insufficient transportation reactions sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object exchange_compartment_id ( str ) – The compartment ID for the exchange compartment Returns : Set of s_ids needing new compartmentalized species in the exchange compartment. Return type : set'},\n",
       "   '_identify_species_needing_transport_reactions': {'name': '_identify_species_needing_transport_reactions',\n",
       "    'signature': 'napistu.modify.gaps._identify_species_needing_transport_reactions(sbml_dfs:SBML_dfs)→ndarray',\n",
       "    'id': 'napistu.modify.gaps._identify_species_needing_transport_reactions',\n",
       "    'doc': 'Identify molecular species needing transport reactions so all of the compartments where it exists are connected. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic model containing a set of molecular species which exist\\nin multiple compartments and are interconverted by reactions Returns : Vector of molecular species (s_ids) with no or insufficient transportation reactions Return type : np.ndarray'},\n",
       "   '_log_protein_transport_gapfilling': {'name': '_log_protein_transport_gapfilling',\n",
       "    'signature': 'napistu.modify.gaps._log_protein_transport_gapfilling(species_transport_status_df:DataFrame)→None',\n",
       "    'id': 'napistu.modify.gaps._log_protein_transport_gapfilling',\n",
       "    'doc': 'Log summary statistics and example messages for protein transport gapfilling. Parameters : species_transport_status_df ( pd.DataFrame ) – DataFrame summarizing transport status for each species'},\n",
       "   'add_transportation_reactions': {'name': 'add_transportation_reactions',\n",
       "    'signature': \"napistu.modify.gaps.add_transportation_reactions(sbml_dfs:SBML_dfs,exchange_compartment:str='cytosol')→SBML_dfs\",\n",
       "    'id': 'napistu.modify.gaps.add_transportation_reactions',\n",
       "    'doc': 'Add transportation reactions to connect all forms of a protein across compartments. Identifies proteins whose various compartmentalized forms cannot reach one\\nanother via existing transportation reactions and then adds transportation\\nreactions which connect all forms of a protein. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic model containing a set of molecular species which exist\\nin multiple compartments and are interconverted by reactions. exchange_compartment ( str , optional ) – The name of an exchange compartment matching a c_name from sbml_dfs.compartments. Returns : The input sbml_dfs with additional transport reactions and compartmentalized species\\n(in the exchange compartment) added. Return type : sbml_dfs_core.SBML_dfs'},\n",
       "   'update_sbml_df_with_exchange': {'name': 'update_sbml_df_with_exchange',\n",
       "    'signature': \"napistu.modify.gaps.update_sbml_df_with_exchange(species_needing_transport_rxns:ndarray,sbml_dfs:SBML_dfs,exchange_compartment:str='cytosol')→SBML_dfs\",\n",
       "    'id': 'napistu.modify.gaps.update_sbml_df_with_exchange',\n",
       "    'doc': 'Add transportation reactions between all locations of a set of molecular species by\\nincluding bidirectional exchange reactions through an exchange compartment. This function is modular and delegates to helper functions for each logical step:\\n- Finding new exchange compartmentalized species\\n- Adding new compartmentalized species\\n- Building the transport reaction edgelist\\n- Creating new reactions\\n- Creating new reaction species\\n- Updating and validating the sbml_dfs Parameters : species_needing_transport_rxns ( np.ndarray ) – Vector of molecular species (s_ids) with no or insufficient transportation reactions sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic model containing a set of molecular species which exist\\nin multiple compartments and are interconverted by reactions exchange_compartment ( str , optional ) – The name of an exchange compartment matching a c_name from sbml_dfs.compartments Returns : The input sbml_dfs with additional transport reactions and compartmentalized species\\n(in the exchange compartment) added. Return type : sbml_dfs_core.SBML_dfs'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.modify.pathwayannot': {'module': 'napistu.modify.pathwayannot',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.pathwayannot.html#module-napistu.modify.pathwayannot',\n",
       "  'functions': {'_add_complex_formation_compartmentalized_species': {'name': '_add_complex_formation_compartmentalized_species',\n",
       "    'signature': 'napistu.modify.pathwayannot._add_complex_formation_compartmentalized_species(sbml_dfs:SBML_dfs,merged_membership:DataFrame,new_species_for_sbml_dfs:DataFrame,complex_component_species_ids:DataFrame)→tuple[DataFrame,DataFrame]',\n",
       "    'id': 'napistu.modify.pathwayannot._add_complex_formation_compartmentalized_species',\n",
       "    'doc': 'Add Complex Formation - Compartmentalized Species Define all compartmentalized species in complexes and format newly created compartmentalized species Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network merged_membership ( pd.DataFrame ) – A table of complexes and their component members new_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.species complex_component_species_ids ( pd.DataFrame ) – All complex components Returns : new_compartmentalized_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.compartmentalized_species updated_compartmentalized_membership ( pd.DataFrame ) – Compartmentalized complex components with updated IDs'},\n",
       "   '_add_entity_sets_reactions': {'name': '_add_entity_sets_reactions',\n",
       "    'signature': 'napistu.modify.pathwayannot._add_entity_sets_reactions(sbml_dfs:SBML_dfs,new_compartmentalized_species_for_sbml_dfs:DataFrame,updated_compartmentalized_membership:DataFrame)→tuple[DataFrame,DataFrame]',\n",
       "    'id': 'napistu.modify.pathwayannot._add_entity_sets_reactions',\n",
       "    'doc': 'Add Entity Sets - Reactions Create reactions which indicate membership in an entity set Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network new_compartmentalized_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.compartmentalized_species updated_compartmentalized_membership ( pd.DataFrame ) – Compartmentalized complex components with updated IDs Returns : new_reactions_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.reactions new_reaction_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.reaction_species'},\n",
       "   '_add_entity_sets_species': {'name': '_add_entity_sets_species',\n",
       "    'signature': 'napistu.modify.pathwayannot._add_entity_sets_species(sbml_dfs:SBML_dfs,reactome_members:DataFrame)→tuple[DataFrame,DataFrame,DataFrame]',\n",
       "    'id': 'napistu.modify.pathwayannot._add_entity_sets_species',\n",
       "    'doc': 'Add Entity Sets - Species Define all species which are part of “entity sets” in the pathway Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network reactome_members ( pd.DataFrame ) – A table of all Reactome entity sets members - obtained using a Neo4j query Returns : merged_membership ( pd.DataFrame ) – A table of complexes and their component members new_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.species set_component_species_ids ( pd.DataFrame ) – All set components'},\n",
       "   '_merge_reactome_crossref_ids': {'name': '_merge_reactome_crossref_ids',\n",
       "    'signature': 'napistu.modify.pathwayannot._merge_reactome_crossref_ids(current_molecular_ids:DataFrame,select_reactome_ids:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.modify.pathwayannot._merge_reactome_crossref_ids',\n",
       "    'doc': 'Merge Reactome CrossRef IDs Combine existing molecular IDs with Reactome crossref identifiers. Params \\uf0c1 current_molecular_ids: pd.DataFrame Molecular features in the current pathway model select_reactome_ids: pd.DataFrame Crossref identifiers produced by _format_reactome_crossref_ids() returns : merged_crossrefs – Molecular feature sids matched to crossref annotations rtype : pd.DataFrame'},\n",
       "   '_read_neo4j_members': {'name': '_read_neo4j_members',\n",
       "    'signature': 'napistu.modify.pathwayannot._read_neo4j_members(neo4j_members:str)→DataFrame',\n",
       "    'id': 'napistu.modify.pathwayannot._read_neo4j_members',\n",
       "    'doc': 'Read a table containing entity sets (members) derived from Reactome’s Neo4J database.'},\n",
       "   '_read_reactome_crossref_ids': {'name': '_read_reactome_crossref_ids',\n",
       "    'signature': 'napistu.modify.pathwayannot._read_reactome_crossref_ids(crossref_path:str)→DataFrame',\n",
       "    'id': 'napistu.modify.pathwayannot._read_reactome_crossref_ids',\n",
       "    'doc': 'Format Reactome CrossRef IDs Read and reformat Reactome’s crossref identifiers Params \\uf0c1 crossref_path: str Path to the cross ref file extracted from Reactome’s Neo4j database returns : select_reactome_ids – Crossref identifiers rtype : pd.DataFrame'},\n",
       "   'add_complex_formation': {'name': 'add_complex_formation',\n",
       "    'signature': 'napistu.modify.pathwayannot.add_complex_formation(sbml_dfs:SBML_dfs)',\n",
       "    'id': 'napistu.modify.pathwayannot.add_complex_formation',\n",
       "    'doc': 'Add Complex Formation Using Reactome-style complex annotations,\\nwhere complex components are an attribute of complexes,\\nadd explicit complex formation reactions. Reactome represents complexers using BQB_HAS_PART\\nannotations, which are extracted into identifiers.Identifiers\\nobjects. This is sufficient to define membership but does\\nnot include stoichiometry. Also, in this approach components\\nare defined by their identifiers (URIs) rather than internal\\ns_ids/sc_ids.'},\n",
       "   'add_complex_formation_species': {'name': 'add_complex_formation_species',\n",
       "    'signature': 'napistu.modify.pathwayannot.add_complex_formation_species(sbml_dfs:SBML_dfs)→tuple[DataFrame,DataFrame,DataFrame]',\n",
       "    'id': 'napistu.modify.pathwayannot.add_complex_formation_species',\n",
       "    'doc': 'Add Complex Formation - Species Define all species in complexes and format newly created species Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network Returns : merged_membership ( pd.DataFrame ) – A table of complexes and their component members new_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.species complex_component_species_ids ( pd.DataFrame ) – All complex components'},\n",
       "   'add_entity_sets': {'name': 'add_entity_sets',\n",
       "    'signature': 'napistu.modify.pathwayannot.add_entity_sets(sbml_dfs:SBML_dfs,neo4j_members:str)→SBML_dfs',\n",
       "    'id': 'napistu.modify.pathwayannot.add_entity_sets',\n",
       "    'doc': 'Add Entity Sets Reactome represents some sets of interchangeable molecules as “entity sets”.\\nCommon examples are ligands for a receptor. This function add members\\nof each entity set as a “is a” style reaction. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network neo4j_members ( str ) – Path to a table containing Reactome entity sets and corresponding members.\\nThis is currently extracted manually with Neo4j. Returns : sbml_dfs – An updated database which includes entity set species and formation reactions Return type : sbml_dfs_core.SBML_dfs'},\n",
       "   'add_reactome_identifiers': {'name': 'add_reactome_identifiers',\n",
       "    'signature': 'napistu.modify.pathwayannot.add_reactome_identifiers(sbml_dfs:SBML_dfs,crossref_path:str)→SBML_dfs',\n",
       "    'id': 'napistu.modify.pathwayannot.add_reactome_identifiers',\n",
       "    'doc': 'Add Reactome Identifiers Add reactome-specific identifiers to existing species Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model crossref_path: Path to the cross ref file extracted from Reactome’s Neo4j database returns : sbml_dfs – A pathway model with updated species’ identifiers rtype : sbml_dfs_core.SBML_dfs'},\n",
       "   'drop_cofactors': {'name': 'drop_cofactors',\n",
       "    'signature': 'napistu.modify.pathwayannot.drop_cofactors(sbml_dfs:SBML_dfs)→SBML_dfs',\n",
       "    'id': 'napistu.modify.pathwayannot.drop_cofactors',\n",
       "    'doc': 'Drop Cofactors Remove reaction species when they are acting as cofactors Parameters: \\uf0c1 sbml_dfs: SBML_dfs A pathway model Returns: \\uf0c1 sbml_dfs (SBML_dfs): A pathway model with some reaction species filtered'},\n",
       "   'filter_one_reactions_cofactors': {'name': 'filter_one_reactions_cofactors',\n",
       "    'signature': 'napistu.modify.pathwayannot.filter_one_reactions_cofactors(one_rxns_species:DataFrame,filter_type:str,cofactor_filter:dict)→Series',\n",
       "    'id': 'napistu.modify.pathwayannot.filter_one_reactions_cofactors',\n",
       "    'doc': 'Filter One Reaction’s Cofactors Apply a cofactor filter to one reaction’s species Parameters: \\uf0c1 one_rxns_species (pd.DataFrame): Rows of reactions species containing cofactors filter_type: str Reason to filter species with this filter cofactor_filter: dict Species included in filter Returns: \\uf0c1 pd.Series with index of rsc_ids and values containing the reason why a reaction species is a cofactor, or None if filter was not triggered.'},\n",
       "   'identify_cofactors': {'name': 'identify_cofactors',\n",
       "    'signature': 'napistu.modify.pathwayannot.identify_cofactors(sbml_dfs:SBML_dfs)→Series',\n",
       "    'id': 'napistu.modify.pathwayannot.identify_cofactors',\n",
       "    'doc': 'Identify Cofactors Find cofactors which are playing a supporting role in a reaction (e.g., ATP -> ADP or water). Parameters: \\uf0c1 sbml_dfs: SBML_dfs A pathway model Returns: \\uf0c1 pd.Series with index of rsc_ids and values containing the reason why a reaction species is a cofactor'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.modify.uncompartmentalize': {'module': 'napistu.modify.uncompartmentalize',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.uncompartmentalize.html#module-napistu.modify.uncompartmentalize',\n",
       "  'functions': {'_create_stubbed_index': {'name': '_create_stubbed_index',\n",
       "    'signature': 'napistu.modify.uncompartmentalize._create_stubbed_index()→PWIndex',\n",
       "    'id': 'napistu.modify.uncompartmentalize._create_stubbed_index',\n",
       "    'doc': 'Create a default pathway index for the uncompartmentalized model.'},\n",
       "   '_create_stubbed_source': {'name': '_create_stubbed_source',\n",
       "    'signature': 'napistu.modify.uncompartmentalize._create_stubbed_source()→Source',\n",
       "    'id': 'napistu.modify.uncompartmentalize._create_stubbed_source',\n",
       "    'doc': 'Create a default Source object for the uncompartmetnalized model.'},\n",
       "   '_filter_trivial_reactions': {'name': '_filter_trivial_reactions',\n",
       "    'signature': 'napistu.modify.uncompartmentalize._filter_trivial_reactions(rxn_consensus_species:pd.DataFrame,rxnspec_consensus_instances:pd.DataFrame)→tuple[pd.Dataframe,pd.DataFrame]',\n",
       "    'id': 'napistu.modify.uncompartmentalize._filter_trivial_reactions',\n",
       "    'doc': 'Filter Trivial Reactions Filter reaction species which cancel out as substrates and products in the same reaction. Parameters : rxn_consensus_species ( pd.DataFrame ) – reactions rxnspec_consensus_instances ( pd.DataFrame ) – reaction species Returns : reactions with trivial reactions dropped\\nreaction_species (pd.DataFrame): reaction species with trivial reaction species dropped Return type : reactions (pd.DataFrame)'},\n",
       "   '_uncompartmentalize_cspecies': {'name': '_uncompartmentalize_cspecies',\n",
       "    'signature': 'napistu.modify.uncompartmentalize._uncompartmentalize_cspecies(sbml_dfs:sbml_dfs_core.SBML_dfs,stubbed_compartment:identifiers.Identifiers)→tuple[pd.Dataframe,pd.DataFrame]',\n",
       "    'id': 'napistu.modify.uncompartmentalize._uncompartmentalize_cspecies',\n",
       "    'doc': 'Convert compartmetnalized species into uncompartmentalized ones.'},\n",
       "   '_uncompartmentalize_reactions': {'name': '_uncompartmentalize_reactions',\n",
       "    'signature': 'napistu.modify.uncompartmentalize._uncompartmentalize_reactions(sbml_dfs:SBML_dfs,compspec_lookup_table:Series)→tuple[DataFrame,DataFrame]',\n",
       "    'id': 'napistu.modify.uncompartmentalize._uncompartmentalize_reactions',\n",
       "    'doc': 'Update reactions and reaction species to include uncompartmentalized species'},\n",
       "   'uncompartmentalize_sbml_dfs': {'name': 'uncompartmentalize_sbml_dfs',\n",
       "    'signature': 'napistu.modify.uncompartmentalize.uncompartmentalize_sbml_dfs(sbml_dfs:SBML_dfs)→SBML_dfs',\n",
       "    'id': 'napistu.modify.uncompartmentalize.uncompartmentalize_sbml_dfs',\n",
       "    'doc': 'Uncompartmentalize SBML_dfs Take a compartmentalized mechanistic model and merge all of the compartments. Parameters : rxn_consensus_species ( pd.DataFrame ) – reactions rxnspec_consensus_instances ( pd.DataFrame ) – reaction species Returns : reactions with trivial reactions dropped\\nreaction_species (pd.DataFrame): reaction species with trivial reaction species dropped Return type : reactions (pd.DataFrame)'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.network': {'module': 'napistu.network',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.html#module-napistu.network',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {'constants': {'url': 'napistu.network.constants.html#module-napistu.network.constants',\n",
       "    'description': 'Module to contain all constants used for representing and working with networks'},\n",
       "   'neighborhoods': {'url': 'napistu.network.neighborhoods.html#module-napistu.network.neighborhoods',\n",
       "    'description': ''},\n",
       "   'net_create': {'url': 'napistu.network.net_create.html#module-napistu.network.net_create',\n",
       "    'description': ''},\n",
       "   'net_propagation': {'url': 'napistu.network.net_propagation.html#module-napistu.network.net_propagation',\n",
       "    'description': ''},\n",
       "   'net_utils': {'url': 'napistu.network.net_utils.html#module-napistu.network.net_utils',\n",
       "    'description': ''},\n",
       "   'paths': {'url': 'napistu.network.paths.html#module-napistu.network.paths',\n",
       "    'description': ''},\n",
       "   'precompute': {'url': 'napistu.network.precompute.html#module-napistu.network.precompute',\n",
       "    'description': ''}}},\n",
       " 'napistu.network.constants': {'module': 'napistu.network.constants',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.constants.html#module-napistu.network.constants',\n",
       "  'functions': {},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.network.neighborhoods': {'module': 'napistu.network.neighborhoods',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.neighborhoods.html#module-napistu.network.neighborhoods',\n",
       "  'functions': {'_build_raw_neighborhood_df': {'name': '_build_raw_neighborhood_df',\n",
       "    'signature': 'napistu.network.neighborhoods._build_raw_neighborhood_df(cpr_graph:Graph,compartmentalized_species:list[str],network_type:str,order:int,precomputed_neighbors:DataFrame|None=None)→DataFrame',\n",
       "    'id': 'napistu.network.neighborhoods._build_raw_neighborhood_df',\n",
       "    'doc': ''},\n",
       "   '_calculate_path_attrs': {'name': '_calculate_path_attrs',\n",
       "    'signature': \"napistu.network.neighborhoods._calculate_path_attrs(neighborhood_paths:list[list],edges:DataFrame,vertices:list,weight_var:str='weights')→tuple[DataFrame,dict[Any,set]]\",\n",
       "    'id': 'napistu.network.neighborhoods._calculate_path_attrs',\n",
       "    'doc': 'Calculate Path Attributes Return the vertices and path weights (sum of edge weights) for a list of paths. Parameters : neighborhood_paths ( list ) – List of lists of edge indices edges ( pd.DataFrame ) – Edges with rows correponding to entries in neighborhood_paths inner lists vertices ( list ) – List of vertices correponding to the ordering of neighborhood_paths weights_var ( str ) – variable in edges to use for scoring path weights Returns : path_attributes_df ( pd.DataFrame ) – A table containing attributes summarizing the path to each neighbor neighborhood_path_entities ( dict ) – Dict mapping from each neighbor to the entities connecting it to the focal node'},\n",
       "   '_create_neighborhood_dict_entry_logging': {'name': '_create_neighborhood_dict_entry_logging',\n",
       "    'signature': 'napistu.network.neighborhoods._create_neighborhood_dict_entry_logging(sc_id:str,one_neighborhood_df:DataFrame,sbml_dfs:SBML_dfs)',\n",
       "    'id': 'napistu.network.neighborhoods._create_neighborhood_dict_entry_logging',\n",
       "    'doc': ''},\n",
       "   '_find_neighbors': {'name': '_find_neighbors',\n",
       "    'signature': 'napistu.network.neighborhoods._find_neighbors(cpr_graph:Graph,compartmentalized_species:list[str],relationship:str,order:int=3,precomputed_neighbors:DataFrame|None=None)→DataFrame',\n",
       "    'id': 'napistu.network.neighborhoods._find_neighbors',\n",
       "    'doc': 'Find Neighbors Identify the neighbors nearby each of the requested compartmentalized_species If ‘precomputed_neighbors’ are provided, neighbors will be summarized by reformatting\\nthis table. Otherwise, neighbors will be found on-the-fly using the igraph.neighborhood() method.'},\n",
       "   '_find_reactions_by_relationship': {'name': '_find_reactions_by_relationship',\n",
       "    'signature': 'napistu.network.neighborhoods._find_reactions_by_relationship(precomputed_neighbors,compartmentalized_species:list,sbml_dfs:SBML_dfs,relationship:str)→DataFrame|None',\n",
       "    'id': 'napistu.network.neighborhoods._find_reactions_by_relationship',\n",
       "    'doc': 'Find Reactions by Relationship Based on an ancestor-descendant edgelist of compartmentalized species find all reactions which involve 2+ members Since we primarily care about paths between species and reactions are more of a means-to-an-end of\\nconnecting pairs of species precomputed_distances are generated between just pairs of species\\nthis also makes the problem feasible since the number of species is upper bounded at <100K but\\nthe number of reactions is unbounded. Having a bound ensures that we can calculate\\nthe precomputed_distances efficiently using matrix operations whose memory footprint scales with O(N^2).'},\n",
       "   '_precompute_neighbors': {'name': '_precompute_neighbors',\n",
       "    'signature': \"napistu.network.neighborhoods._precompute_neighbors(compartmentalized_species:list[str],precomputed_distances:DataFrame,sbml_dfs:SBML_dfs,network_type:str='downstream',order:int=3,top_n:int=10)→DataFrame\",\n",
       "    'id': 'napistu.network.neighborhoods._precompute_neighbors',\n",
       "    'doc': 'Precompute Neighbors Identify compartmentalized_species’ most tightly connected neighbors using parameters\\nshared by the on-the-fly methods (order for identifying neighbors within N steps;\\ntop_n for identifying the most the lowest weight network paths between the focal node\\nand each possible neighbors). This precomputation will greatly speed up the neighborhood\\ngeneration for highly connected species or densely connected networks. In those situations\\nnaively creating a neighborhood in N steps could contain thousands of neighbors.'},\n",
       "   '_prune_vertex_set': {'name': '_prune_vertex_set',\n",
       "    'signature': 'napistu.network.neighborhoods._prune_vertex_set(one_neighborhood:dict,top_n:int)→DataFrame',\n",
       "    'id': 'napistu.network.neighborhoods._prune_vertex_set',\n",
       "    'doc': 'Prune Vertex Set Filter a neighborhood to the lowest weight neighbors connected to the focal node.\\nDuring this process upstream and downstream nodes are treated separately. Parameters : one_neighborhood ( dict ) – The neighborhood around a single compartmentalized species - one of the values in dict created by find_neighborhoods(). top_n ( int ) – How many neighboring molecular species should be retained?\\nIf the neighborhood includes both upstream and downstream connections\\n(i.e., hourglass), this filter will be applied to both sets separately. Returns : vertices – the vertices in one_neighborhood with high weight neighbors removed. Return type : pd.DataFrame'},\n",
       "   'add_vertices_uri_urls': {'name': 'add_vertices_uri_urls',\n",
       "    'signature': 'napistu.network.neighborhoods.add_vertices_uri_urls(vertices:DataFrame,sbml_dfs:SBML_dfs)→DataFrame',\n",
       "    'id': 'napistu.network.neighborhoods.add_vertices_uri_urls',\n",
       "    'doc': 'Add Vertices URI URLs Add a url variable to the neighborhood vertices pd.DataFrame Parameters : vertices ( pd.DataFrame ) – table of neighborhood vertices sbml_dfs ( sbml_dfs_core.SBML_dfs ) – consensus network model Returns : vertices – input table with a url field Return type : pd.DataFrame'},\n",
       "   'create_neighborhood_dict_entry': {'name': 'create_neighborhood_dict_entry',\n",
       "    'signature': 'napistu.network.neighborhoods.create_neighborhood_dict_entry(sc_id:str,neighborhood_df:DataFrame,sbml_dfs:SBML_dfs,cpr_graph:Graph,verbose:bool=False)→dict[str,Any]',\n",
       "    'id': 'napistu.network.neighborhoods.create_neighborhood_dict_entry',\n",
       "    'doc': 'Create Neighborhood Dict Entry Generate a summary of a compartmentalized species’ neighborhood Parameters : sc_id ( str ) – A compartmentalized species id neighborhood_df ( pd.DataFrame ) – A table of upstream and/or downstream neighbors of all compartmentalized species sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic molecular model cpr_graph ( igraph.Graph ) – A network connecting molecular species and reactions verbose ( bool ) – Extra reporting? Returns : graph: igraph.Graph subgraph of sc_id’s neighborhood, vertices: pd.DataFrame nodes in the neighborhood edges: pd.DataFrame edges in the neighborhood edge_sources: pd.DataFrame models that edges were derived from neighborhood_path_entities: dict upstream and downstream dicts representing entities in paths.\\nIf the keys are to be included in a neighborhood, the\\nvalues should be as well in order to maintain connection to the\\nfocal node. Return type : dict containing'},\n",
       "   'create_neighborhood_prefix': {'name': 'create_neighborhood_prefix',\n",
       "    'signature': 'napistu.network.neighborhoods.create_neighborhood_prefix(network_type:str,order:int,top_n:int)→str',\n",
       "    'id': 'napistu.network.neighborhoods.create_neighborhood_prefix',\n",
       "    'doc': ''},\n",
       "   'create_neighborhoods': {'name': 'create_neighborhoods',\n",
       "    'signature': 'napistu.network.neighborhoods.create_neighborhoods(s_ids:list[str],sbml_dfs:SBML_dfs,cpr_graph:Graph,network_type:str,order:int,top_n:int,verbose:bool=False)→tuple[DataFrame,dict]',\n",
       "    'id': 'napistu.network.neighborhoods.create_neighborhoods',\n",
       "    'doc': 'Create Neighborhoods Create neighborhoods for a set of species and return Parameters : s_ids ( list ( str ) ) – create a neighborhood around each species sbml_dfs ( sbml_dfs_core.SBML_dfs ) – network model cpr_graph ( igraph.Graph ) – network associated with sbml_dfs network_type ( str ) – downstream, upstream or hourglass (i.e., downstream and upstream) order ( 10 ) – maximum number of steps from the focal node top_n ( 30 ) – target number of upstream and downstream species to retain verbose ( bool ) – extra reporting Returns : all_neighborhoods_df ( pd.DataFrame ) – A table containing all species in each query s_ids neighborhood neighborhoods_dict ( dict ) – Outputs from find_and_prune_neighborhoods for each s_id'},\n",
       "   'find_and_prune_neighborhoods': {'name': 'find_and_prune_neighborhoods',\n",
       "    'signature': \"napistu.network.neighborhoods.find_and_prune_neighborhoods(sbml_dfs:SBML_dfs,cpr_graph:Graph,compartmentalized_species:str|list[str],precomputed_distances:DataFrame|None=None,network_type:str='downstream',order:int=3,verbose:bool=True,top_n:int=10)→dict[str,Any]\",\n",
       "    'id': 'napistu.network.neighborhoods.find_and_prune_neighborhoods',\n",
       "    'doc': 'Find and Prune Neighborhoods Wrapper which combines find_neighborhoods() and prune_neighborhoods() Parameters cpr_graph igraph.Graph A bipartite network connecting molecular species and reactions compartmentalized_species [str] or str Compartmentalized species IDs for neighborhood centers precomputed_distances pd.DataFrame or None If provided, an edgelist of origin->destination path weights and lengths network_type: str If the network is directed should neighbors be located “downstream”,\\nor “upstream” of each compartmentalized species. The “hourglass” option\\nlocates both upstream and downstream species. order: int Max steps away from center node verbose: bool Extra reporting top_n: int How many neighboring molecular species should be retained?\\nIf the neighborhood includes both upstream and downstream connections\\n(i.e., hourglass), this filter will be applied to both sets separately. Returns: \\uf0c1 A dict containing the neighborhood of each compartmentalized species.\\nEach entry in the dict is a dict of the subgraph, vertices, and edges.'},\n",
       "   'find_neighborhoods': {'name': 'find_neighborhoods',\n",
       "    'signature': \"napistu.network.neighborhoods.find_neighborhoods(sbml_dfs:SBML_dfs,cpr_graph:Graph,compartmentalized_species:list[str],network_type:str='downstream',order:int=3,verbose:bool=True,precomputed_neighbors:DataFrame|None=None)→dict\",\n",
       "    'id': 'napistu.network.neighborhoods.find_neighborhoods',\n",
       "    'doc': 'Find Neighborhood Create a network composed of all species and reactions within N steps of each of a set of compartmentalized species. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic molecular model cpr_graph ( igraph.Graph ) – A network connecting molecular species and reactions compartmentalized_species ( [ str ] ) – Compartmentalized species IDs for neighborhood centers network_type ( str ) – If the network is directed should neighbors be located “downstream”,\\nor “upstream” of each compartmentalized species. The “hourglass” option\\nlocates both upstream and downstream species. order ( int ) – Max steps away from center node verbose ( bool ) – Extra reporting precomputed_neighbors ( pd.DataFrame or None ) – If provided, a pre-filtered table of nodes nearby the compartmentalized species\\nwhich will be used to skip on-the-fly neighborhood generation. Returns ---------- species. ( A dict containing the neighborhood of each compartmentalized ) – Each entry in the dict is a dict of the subgraph, vertices, and edges.'},\n",
       "   'load_neighborhoods': {'name': 'load_neighborhoods',\n",
       "    'signature': 'napistu.network.neighborhoods.load_neighborhoods(s_ids:list[str],sbml_dfs:SBML_dfs,cpr_graph:Graph,output_dir:str,network_type:str,order:int,top_n:int,overwrite:bool=False,verbose:bool=False)→tuple[DataFrame,dict[str,Any]]',\n",
       "    'id': 'napistu.network.neighborhoods.load_neighborhoods',\n",
       "    'doc': 'Load Neighborhoods Load existing neighborhoods if they exist\\n(and overwrite = False) and otherwise construct neighborhoods using the provided settings Parameters : s_ids ( list ( str ) ) – create a neighborhood around each species sbml_dfs ( sbml_dfs_core.SBML_dfs ) – network model cpr_graph ( igraph.Graph ) – network associated with sbml_dfs output_dir ( str ) – path to existing output directory network_type ( str ) – downstream, upstream or hourglass (i.e., downstream and upstream) order ( 10 ) – maximum number of steps from the focal node top_n ( 30 ) – target number of upstream and downstream species to retain overwrite ( bool ) – ignore cached files and regenerate neighborhoods verbose ( bool ) – extra reporting Returns : all_neighborhoods_df ( pd.DataFrame ) – A table containing all species in each query s_ids neighborhood neighborhoods_dict ( dict ) – Outputs from find_and_prune_neighborhoods for each s_id'},\n",
       "   'load_neighborhoods_by_partition': {'name': 'load_neighborhoods_by_partition',\n",
       "    'signature': \"napistu.network.neighborhoods.load_neighborhoods_by_partition(selected_partition:int,neighborhood_outdir:str,graph_type:str='regulatory')→None\",\n",
       "    'id': 'napistu.network.neighborhoods.load_neighborhoods_by_partition',\n",
       "    'doc': 'Load Neighborhoods By Partition Call load_neighborhoods for a subset of species ids defined by a partition.\\nThis function is setup to be called in a slurm job. Params \\uf0c1 selected_partition: int A partition of sids to search neighborhood_outdir: str Output directory rtype : None, used for side-effects'},\n",
       "   'plot_neighborhood': {'name': 'plot_neighborhood',\n",
       "    'signature': \"napistu.network.neighborhoods.plot_neighborhood(neighborhood_graph:Graph,name_nodes:bool=False,plot_size:int=1000,network_layout:str='drl')→plot\",\n",
       "    'id': 'napistu.network.neighborhoods.plot_neighborhood',\n",
       "    'doc': 'Plot Neighborhood Parameters: \\uf0c1 neighborhood_graph: igraph.Graph An igraph network name_nodes: bool Should nodes be named plot_size: int Plot width/height in pixels network_layout: str Igraph network layout method Returns: \\uf0c1 An igraph plot'},\n",
       "   'prune_neighborhoods': {'name': 'prune_neighborhoods',\n",
       "    'signature': 'napistu.network.neighborhoods.prune_neighborhoods(neighborhoods:dict,top_n:int=100)→dict',\n",
       "    'id': 'napistu.network.neighborhoods.prune_neighborhoods',\n",
       "    'doc': 'Prune Neighborhoods Take a possibly very large neighborhood around a set of focal nodes\\nand prune to the most highly weighted nodes. Nodes weights are\\nconstructed as the sum of path weights from the focal node to each\\nneighbor so each pruned neighborhood will still be a single subnetwork. Parameters : neighborhoods ( dict ) – A dictionary of sc_id neighborhoods as produced by find_neighborhoods() top_n ( int ) – How many neighbors should be retained? If the neighborhood includes\\nboth upstream and downstream connections (i.e., hourglass), this filter\\nwill be applied to both sets separately Returns : neighborhoods – Same structure as neighborhoods input Return type : dict'},\n",
       "   'read_paritioned_neighborhoods': {'name': 'read_paritioned_neighborhoods',\n",
       "    'signature': 'napistu.network.neighborhoods.read_paritioned_neighborhoods(sbml_dfs:SBML_dfs,cpr_graph:Graph,partitions_path:str,n_partitions:int=200)→tuple[DataFrame,dict[str,Any]]',\n",
       "    'id': 'napistu.network.neighborhoods.read_paritioned_neighborhoods',\n",
       "    'doc': 'Read Partitioned Neighborhoods Import a set of neighborhoods produced by the find_neighborhoods_batch.sh slurm job Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs network model cpr_graph: igraph.Graph network associated with sbml_dfs partitions_path: str Path to a directory containing folders for each partition’s results n_partitions: int Number of partitions that exist returns : all_neighborhoods_df ( pd.DataFrame ) – A table containing all species in each query s_ids neighborhood neighborhoods_dict ( dict ) – Outputs from find_and_prune_neighborhoods for each s_id'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.network.net_create': {'module': 'napistu.network.net_create',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_create.html#module-napistu.network.net_create',\n",
       "  'functions': {'_add_edge_attr_to_vertex_graph': {'name': '_add_edge_attr_to_vertex_graph',\n",
       "    'signature': \"napistu.network.net_create._add_edge_attr_to_vertex_graph(cpr_graph:Graph,edge_attr_list:list,shared_node_key:str='r_id')→Graph\",\n",
       "    'id': 'napistu.network.net_create._add_edge_attr_to_vertex_graph',\n",
       "    'doc': 'Merge edge attribute(s) from edge_attr_list to vetices of an igraph Parameters : cpr_graph ( iGraph ) – A graph generated by create_cpr_graph() edge_attr_list ( list ) – A list containing attributes to pull out of edges, then to add to vertices shared_node_key ( str ) – key in edge that is shared with vertex, to map edge ids to corresponding vertex ids Returns ---------- network ( An Igraph )'},\n",
       "   '_add_graph_species_attribute': {'name': '_add_graph_species_attribute',\n",
       "    'signature': 'napistu.network.net_create._add_graph_species_attribute(cpr_graph:Graph,sbml_dfs:SBML_dfs,species_graph_attrs:dict,custom_transformations:dict|None=None)→Graph',\n",
       "    'id': 'napistu.network.net_create._add_graph_species_attribute',\n",
       "    'doc': 'Add meta-data from species_data to existing igraph’s vertices. This function augments the vertices of an igraph network with additional attributes\\nderived from the species-level data in the provided SBML_dfs object. The attributes\\nto add are specified in the species_graph_attrs dictionary, and can be transformed\\nusing either built-in or user-supplied transformation functions. Parameters : cpr_graph ( ig.Graph ) – The igraph network to augment. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object containing species data. species_graph_attrs ( dict ) – Dictionary specifying which attributes to pull from species_data and how to transform them.\\nThe structure should be {attribute_name: {“table”: …, “variable”: …, “trans”: …}}. custom_transformations ( dict , optional ) – Dictionary mapping transformation names to functions. If provided, these will be checked\\nbefore built-in transformations. Example: {“square”: lambda x: x**2} Returns : The input igraph network with additional vertex attributes added from species_data. Return type : ig.Graph'},\n",
       "   '_add_graph_weights_calibration': {'name': '_add_graph_weights_calibration',\n",
       "    'signature': 'napistu.network.net_create._add_graph_weights_calibration(cpr_graph:Graph,reaction_attrs:dict)→Graph',\n",
       "    'id': 'napistu.network.net_create._add_graph_weights_calibration',\n",
       "    'doc': 'Weight a graph using a calibrated strategy which aims to roughly align qualiatively similar weights from different sources.'},\n",
       "   '_add_graph_weights_mixed': {'name': '_add_graph_weights_mixed',\n",
       "    'signature': 'napistu.network.net_create._add_graph_weights_mixed(cpr_graph:Graph,reaction_attrs:dict)→Graph',\n",
       "    'id': 'napistu.network.net_create._add_graph_weights_mixed',\n",
       "    'doc': 'Weight a graph using a mixed approach combining source-specific weights and existing edge weights.'},\n",
       "   '_augment_network_edges': {'name': '_augment_network_edges',\n",
       "    'signature': 'napistu.network.net_create._augment_network_edges(network_edges:DataFrame,sbml_dfs:SBML_dfs,reaction_graph_attrs:dict={},custom_transformations:dict|None=None)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._augment_network_edges',\n",
       "    'doc': 'Add reversibility and other metadata from reactions. Parameters : network_edges ( pd.DataFrame ) – DataFrame of network edges. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object containing reaction data. reaction_graph_attrs ( dict ) – Dictionary of reaction attributes to add. custom_transformations ( dict , optional ) – Dictionary of custom transformation functions to use for attribute transformation.'},\n",
       "   '_augment_network_nodes': {'name': '_augment_network_nodes',\n",
       "    'signature': 'napistu.network.net_create._augment_network_nodes(network_nodes:DataFrame,sbml_dfs:SBML_dfs,species_graph_attrs:dict={},custom_transformations:dict|None=None)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._augment_network_nodes',\n",
       "    'doc': 'Add species-level attributes, expand network_nodes with s_id and c_id and then map to species-level attributes by s_id. This function merges species-level attributes from sbml_dfs into the provided network_nodes DataFrame,\\nusing the mapping in species_graph_attrs. Optionally, custom transformation functions can be provided\\nto transform the attributes as they are added. Parameters : network_nodes ( pd.DataFrame ) – DataFrame of network nodes. Must include columns ‘name’, ‘node_name’, and ‘node_type’. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object containing species data. species_graph_attrs ( dict ) – Dictionary specifying which attributes to pull from species_data and how to transform them.\\nThe structure should be {attribute_name: {“table”: …, “variable”: …, “trans”: …}}. custom_transformations ( dict , optional ) – Dictionary mapping transformation names to functions. If provided, these will be checked\\nbefore built-in transformations. Example: {“square”: lambda x: x**2} Returns : The input network_nodes DataFrame with additional columns for each extracted and transformed attribute. Return type : pd.DataFrame'},\n",
       "   '_create_cpr_graph_bipartite': {'name': '_create_cpr_graph_bipartite',\n",
       "    'signature': 'napistu.network.net_create._create_cpr_graph_bipartite(sbml_dfs:SBML_dfs)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._create_cpr_graph_bipartite',\n",
       "    'doc': 'Turn an sbml_dfs model into a bipartite graph linking molecules to reactions.'},\n",
       "   '_create_cpr_graph_tiered': {'name': '_create_cpr_graph_tiered',\n",
       "    'signature': 'napistu.network.net_create._create_cpr_graph_tiered(sbml_dfs:SBML_dfs,graph_type:str)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._create_cpr_graph_tiered',\n",
       "    'doc': 'Turn an sbml_dfs model into a tiered graph which links upstream entities to downstream ones.'},\n",
       "   '_create_graph_hierarchy_df': {'name': '_create_graph_hierarchy_df',\n",
       "    'signature': 'napistu.network.net_create._create_graph_hierarchy_df(graph_type:str)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._create_graph_hierarchy_df',\n",
       "    'doc': 'Create Graph Hierarchy DataFrame Format a graph hierarchy list of lists and a pd.DataFrame Parameters : graph_type ( str ) – The type of tiered graph to work with. Each type has its own specification in constants.py. Returns : A pandas DataFrame with sbo_name, tier, and sbo_term.'},\n",
       "   '_create_source_weights': {'name': '_create_source_weights',\n",
       "    'signature': \"napistu.network.net_create._create_source_weights(edges_df:DataFrame,source_wt_var:str='source_wt',source_vars_dict:dict={'string_wt':10},source_wt_default:int=1)→DataFrame\",\n",
       "    'id': 'napistu.network.net_create._create_source_weights',\n",
       "    'doc': '”\\nCreate Source Weights Create weights based on an edges source. This is a simple but crude way of allowing different\\ndata sources to have different support if we think that some are more trustworthly than others. Parameters : edges_df – pd.DataFrame\\nThe edges dataframe to add the source weights to. source_wt_var – str\\nThe name of the column to store the source weights. source_vars_dict – dict\\nDictionary with keys indicating edge attributes and values indicating the weight to assign\\nto that attribute. This value is generally the largest weight that can be assigned to an\\nedge so that the numeric weight is chosen over the default. source_wt_default – int\\nThe default weight to assign to an edge if no other weight attribute is found. Returns : pd.DataFrame The edges dataframe with the source weights added.'},\n",
       "   '_create_topology_weights': {'name': '_create_topology_weights',\n",
       "    'signature': 'napistu.network.net_create._create_topology_weights(cpr_graph:Graph,base_score:float=2,protein_multiplier:int=1,metabolite_multiplier:int=3,unknown_multiplier:int=10,scale_multiplier_by_meandegree:bool=True)→Graph',\n",
       "    'id': 'napistu.network.net_create._create_topology_weights',\n",
       "    'doc': 'Create Topology Weights Add weights to a network based on its topology. Edges downstream of nodes\\nwith many connections receive a higher weight suggesting that any one\\nof them is less likely to be regulatory. This is a simple and clearly\\nflawed heuristic which can be combined with more principled weighting\\nschemes. Parameters : cpr_graph ( ig.Graph ) – a graph containing connections between molecules, proteins, and reactions. base_score ( float ) – offset which will be added to all weights. protein_multiplier ( int ) – multiplier for non-metabolite species (lower weight paths will tend to be selected). metabolite_multiplier ( int ) – multiplier for metabolites [defined a species with a ChEBI ID). unknown_multiplier ( int ) – multiplier for species without any identifier. See sbml_dfs_core.species_type_types. scale_multiplier_by_meandegree ( bool ) – if True then multipliers will be rescaled by the average number of\\nconnections a node has (i.e., its degree) so that weights will be relatively similar regardless of network\\nsize and sparsity. Returns : graph with added topology weights Return type : cpr_graph (ig.Graph)'},\n",
       "   '_format_interactors_for_tiered_graph': {'name': '_format_interactors_for_tiered_graph',\n",
       "    'signature': 'napistu.network.net_create._format_interactors_for_tiered_graph(r_id:str,rxn_species:DataFrame,sbml_dfs:SBML_dfs)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._format_interactors_for_tiered_graph',\n",
       "    'doc': 'Format an undirected interactions for tiered graph so interactions are linked even though they would be on the same tier.'},\n",
       "   '_format_tier_combo': {'name': '_format_tier_combo',\n",
       "    'signature': 'napistu.network.net_create._format_tier_combo(upstream_tier:DataFrame,downstream_tier:DataFrame,past_reaction:bool)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._format_tier_combo',\n",
       "    'doc': 'Format Tier Combo Create a set of edges crossing two tiers of a tiered graph. This will involve an all x all combination of entries. Tiers form an ordering along the molecular entities\\nin a reaction plus a tier for the reaction itself. Attributes such as stoichiometry\\nand sbo_term will be passed from the tier which is furthest from the reaction tier\\nto ensure that each tier of molecular data applies its attributes to a single set of\\nedges while the “reaction” tier does not. Reaction entities have neither a\\nstoichiometery or sbo_term annotation. Parameters : upstream_tier ( pd.DataFrame ) – A table containing upstream entities in a reaction,\\ne.g., regulators. downstream_tier ( pd.DataFrame ) – A table containing downstream entities in a reaction,\\ne.g., catalysts. past_reaction ( bool ) – if True then attributes will be taken from downstream_tier and\\nif False they will come from upstream_tier. Returns : A table of edges containing (from, to, stoichiometry, sbo_term, r_id). The\\nnumber of edges is the product of the number of entities in the upstream tier\\ntimes the number in the downstream tier. Return type : formatted_tier_combo (pd.DataFrame)'},\n",
       "   '_format_tiered_reaction_species': {'name': '_format_tiered_reaction_species',\n",
       "    'signature': 'napistu.network.net_create._format_tiered_reaction_species(r_id:str,sorted_reaction_species:DataFrame,sbml_dfs:SBML_dfs,graph_hierarchy_df:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._format_tiered_reaction_species',\n",
       "    'doc': 'Format Tiered Reaction Species Refactor a reaction’s species into tiered edges between substrates, products, enzymes and allosteric regulators.'},\n",
       "   '_reverse_network_edges': {'name': '_reverse_network_edges',\n",
       "    'signature': 'napistu.network.net_create._reverse_network_edges(augmented_network_edges:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.network.net_create._reverse_network_edges',\n",
       "    'doc': 'Flip reversible reactions to derive the reverse reaction.'},\n",
       "   '_summarize_weight_calibration_plots': {'name': '_summarize_weight_calibration_plots',\n",
       "    'signature': 'napistu.network.net_create._summarize_weight_calibration_plots(calibrated_edges:DataFrame,score_calibration_df_calibrated:DataFrame)→None',\n",
       "    'id': 'napistu.network.net_create._summarize_weight_calibration_plots',\n",
       "    'doc': 'Create a couple of plots summarizing the relationships between different scoring measures.'},\n",
       "   '_summarize_weight_calibration_table': {'name': '_summarize_weight_calibration_table',\n",
       "    'signature': 'napistu.network.net_create._summarize_weight_calibration_table(calibrated_edges:DataFrame,score_calibration_df:DataFrame,score_calibration_df_calibrated:DataFrame)',\n",
       "    'id': 'napistu.network.net_create._summarize_weight_calibration_table',\n",
       "    'doc': 'Create a table comparing edge weights from multiple sources.'},\n",
       "   '_validate_entity_attrs': {'name': '_validate_entity_attrs',\n",
       "    'signature': 'napistu.network.net_create._validate_entity_attrs(entity_attrs:dict,validate_transformations:bool=True,custom_transformations:dict|None=None)→None',\n",
       "    'id': 'napistu.network.net_create._validate_entity_attrs',\n",
       "    'doc': 'Validate that graph attributes are a valid format.'},\n",
       "   '_wt_transformation_identity': {'name': '_wt_transformation_identity',\n",
       "    'signature': 'napistu.network.net_create._wt_transformation_identity(x)',\n",
       "    'id': 'napistu.network.net_create._wt_transformation_identity',\n",
       "    'doc': 'Identity'},\n",
       "   '_wt_transformation_string': {'name': '_wt_transformation_string',\n",
       "    'signature': 'napistu.network.net_create._wt_transformation_string(x)',\n",
       "    'id': 'napistu.network.net_create._wt_transformation_string',\n",
       "    'doc': 'Map STRING scores to a similar scale as topology weights.'},\n",
       "   '_wt_transformation_string_inv': {'name': '_wt_transformation_string_inv',\n",
       "    'signature': 'napistu.network.net_create._wt_transformation_string_inv(x)',\n",
       "    'id': 'napistu.network.net_create._wt_transformation_string_inv',\n",
       "    'doc': 'Map STRING scores so they work with source weights.'},\n",
       "   'add_graph_weights': {'name': 'add_graph_weights',\n",
       "    'signature': \"napistu.network.net_create.add_graph_weights(cpr_graph:Graph,reaction_attrs:dict,weighting_strategy:str='unweighted')→Graph\",\n",
       "    'id': 'napistu.network.net_create.add_graph_weights',\n",
       "    'doc': 'Add Graph Weights Apply a weighting strategy to generate edge weights on a graph. For directed graphs “upstream_weights” will\\nbe generated as well which should be used when searching for a node’s ancestors. Parameters : cpr_graph ( ig.Graph ) – a graphical network of molecules/reactions (nodes) and edges linking them. reaction_attrs ( dict ) – an optional dict weighting_strategy – a network weighting strategy with options:\\n- unweighted: all weights (and upstream_weights for directed graphs) are set to 1.\\n- topology: weight edges by the degree of the source nodes favoring nodes emerging from nodes with few connections. mixed: transform edges with a quantitative score based on reaction_attrs; and set edges without quantitative score as a source-specific weight. calibrated: transforme edges with a quantitative score based on reaction_attrs and combine them with topology scores to generate a consensus.'},\n",
       "   'apply_weight_transformations': {'name': 'apply_weight_transformations',\n",
       "    'signature': 'napistu.network.net_create.apply_weight_transformations(edges_df:DataFrame,reaction_attrs:dict,custom_transformations:dict=None)',\n",
       "    'id': 'napistu.network.net_create.apply_weight_transformations',\n",
       "    'doc': 'Apply Weight Transformations Parameters : edges_df ( pd.DataFrame ) – a table of edges and their attributes extracted\\nfrom a cpr_grpah. reaction_attrs ( dict ) – A dictionary of attributes identifying weighting attributes within\\nan sbml_df’s reaction_data, how they will be named in edges_df (the keys),\\nand how they should be transformed (the “trans” aliases”) custom_transformations ( dict , optional ) – A dictionary mapping transformation names to functions. If provided, these\\nwill be checked before built-in transformations. Returns : edges_df with weight variables transformed. Return type : transformed_edges_df (pd.DataFrame)'},\n",
       "   'create_cpr_graph': {'name': 'create_cpr_graph',\n",
       "    'signature': \"napistu.network.net_create.create_cpr_graph(sbml_dfs:SBML_dfs,reaction_graph_attrs:dict|None=None,directed:bool=True,edge_reversed:bool=False,graph_type:str='bipartite',verbose:bool=False,custom_transformations:dict|None=None)→Graph\",\n",
       "    'id': 'napistu.network.net_create.create_cpr_graph',\n",
       "    'doc': 'Create CPR Graph Create an igraph network from a mechanistic network using one of a set of graph_types. Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways reaction_graph_attrs ( dict ) – Dictionary containing attributes to pull out of reaction_data and\\na weighting scheme for the graph directed ( bool ) – Should a directed (True) or undirected graph be made (False) edge_reversed ( bool ) – Should the directions of edges be reversed or not (False) graph_type ( str ) – Type of graph to create, valid values are: bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products reguatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products surrogate: non-enzymatic modifiers -> substrates -> enzymes -> reaction -> products.\\nIn this representation enzymes are effective standing in for their reaction (eventhough the enzyme is\\nnot modified by a substrate per-se). verbose ( bool ) – Extra reporting custom_transformations ( dict , optional ) – Dictionary of custom transformation functions to use for attribute transformation. Returns ---------- network ( An Igraph )'},\n",
       "   'pluck_entity_data': {'name': 'pluck_entity_data',\n",
       "    'signature': 'napistu.network.net_create.pluck_entity_data(sbml_dfs:SBML_dfs,graph_attrs:dict[str,dict],data_type:str,custom_transformations:dict[str,callable]|None=None)→DataFrame|None',\n",
       "    'id': 'napistu.network.net_create.pluck_entity_data',\n",
       "    'doc': 'Pluck Entity Attributes Pull species or reaction attributes out of an sbml_dfs based on a set of tables and variables to look for. Parameters:\\nsbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model graph_attrs: dict A dictionary of species/reaction attributes to pull out. If the requested\\ndata_type (“species” or “reactions”) is not present as a key, or if the value\\nis an empty dict, this function will return None (no error). data_type: str “species” or “reactions” to pull out species_data or reactions_data custom_transformations: dict[str, callable], optional A dictionary mapping transformation names to functions. If provided, these\\nwill be checked before built-in transformations. Example: custom_transformations = {“square”: lambda x: x**2} Returns : A table where all extracted attributes are merged based on a common index or None\\nif no attributes were extracted. If the requested data_type is not present in\\ngraph_attrs, or if the attribute dict is empty, returns None. This is intended\\nto allow optional annotation blocks.'},\n",
       "   'process_cpr_graph': {'name': 'process_cpr_graph',\n",
       "    'signature': \"napistu.network.net_create.process_cpr_graph(sbml_dfs:SBML_dfs,reaction_graph_attrs:dict|None=None,directed:bool=True,edge_reversed:bool=False,graph_type:str='bipartite',weighting_strategy:str='unweighted',verbose:bool=False,custom_transformations:dict=None)→Graph\",\n",
       "    'id': 'napistu.network.net_create.process_cpr_graph',\n",
       "    'doc': 'Process Consensus Graph Setup an igraph network and then add weights and other maleable attributes. Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways reaction_graph_attrs ( dict ) – Dictionary containing attributes to pull out of reaction_data and\\na weighting scheme for the graph directed ( bool ) – Should a directed (True) or undirected graph be made (False) edge_reversed ( bool ) – Should directions of edges be reversed (False) graph_type ( str ) – Type of graph to create, valid values are:\\n- bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products\\n- reguatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products weighting_strategy ( str ) – a network weighting strategy with options:\\n- unweighted: all weights (and upstream_weights for directed graphs) are set to 1.\\n- topology: weight edges by the degree of the source nodes favoring nodes emerging from nodes with few connections. mixed: transform edges with a quantitative score based on reaction_attrs; and set edges without quantitative score as a source-specific weight. calibrated: transforme edges with a quantitative score based on reaction_attrs and combine them with topology scores to generate a consensus. verbose ( bool ) – Extra reporting custom_transformations ( dict , optional ) – Dictionary of custom transformation functions to use for attribute transformation. Returns : An Igraph network Return type : weighted_graph (ig.Graph)'},\n",
       "   'summarize_weight_calibration': {'name': 'summarize_weight_calibration',\n",
       "    'signature': 'napistu.network.net_create.summarize_weight_calibration(cpr_graph:Graph,reaction_attrs:dict)→None',\n",
       "    'id': 'napistu.network.net_create.summarize_weight_calibration',\n",
       "    'doc': 'Summarize Weight Calibration For a network with multiple sources for edge weights summarize the alignment of\\ndifferent weighting schemes and how they map onto our notion of “good” versus\\n“dubious” weights. Parameters : cpr_graph ( ig.Graph ) – A graph where edge weights have already been calibrated. reaction_attrs ( dict ) – a dictionary summarizing the types of weights that\\nexist and how they are transformed for calibration. Returns : None'}},\n",
       "  'classes': {'_EntityAttrValidator': {'name': '_EntityAttrValidator',\n",
       "    'signature': \"classnapistu.network.net_create._EntityAttrValidator(*,table:str,variable:str,trans:str|None='identity')\",\n",
       "    'id': 'napistu.network.net_create._EntityAttrValidator',\n",
       "    'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict]. table : str \\uf0c1 trans : str | None \\uf0c1 variable : str \\uf0c1',\n",
       "    'methods': {},\n",
       "    'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "      'signature': '_abc_impl=<_abc._abc_dataobject>',\n",
       "      'id': 'napistu.network.net_create._EntityAttrValidator._abc_impl',\n",
       "      'doc': ''},\n",
       "     'model_config': {'name': 'model_config',\n",
       "      'signature': 'model_config:ClassVar[ConfigDict]={}',\n",
       "      'id': 'napistu.network.net_create._EntityAttrValidator.model_config',\n",
       "      'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'},\n",
       "     'table': {'name': 'table',\n",
       "      'signature': 'table:str',\n",
       "      'id': 'napistu.network.net_create._EntityAttrValidator.table',\n",
       "      'doc': ''},\n",
       "     'trans': {'name': 'trans',\n",
       "      'signature': 'trans:str|None',\n",
       "      'id': 'napistu.network.net_create._EntityAttrValidator.trans',\n",
       "      'doc': ''},\n",
       "     'variable': {'name': 'variable',\n",
       "      'signature': 'variable:str',\n",
       "      'id': 'napistu.network.net_create._EntityAttrValidator.variable',\n",
       "      'doc': ''}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.network.net_propagation': {'module': 'napistu.network.net_propagation',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_propagation.html#module-napistu.network.net_propagation',\n",
       "  'functions': {'_ensure_nonnegative_vertex_attribute': {'name': '_ensure_nonnegative_vertex_attribute',\n",
       "    'signature': 'napistu.network.net_propagation._ensure_nonnegative_vertex_attribute(g:Graph,attribute:str)',\n",
       "    'id': 'napistu.network.net_propagation._ensure_nonnegative_vertex_attribute',\n",
       "    'doc': 'Utility to check that a vertex attribute is present, numeric, and non-negative.\\nRaises ValueError if checks fail.\\nMissing or None values are treated as 0.\\nRaises ValueError if attribute is missing for all vertices or all values are zero.'},\n",
       "   'personalized_pagerank_by_attribute': {'name': 'personalized_pagerank_by_attribute',\n",
       "    'signature': 'napistu.network.net_propagation.personalized_pagerank_by_attribute(g:Graph,attribute:str,damping:float=0.85,calculate_uniform_dist:bool=True,additional_propagation_args:dict|None=None)→DataFrame',\n",
       "    'id': 'napistu.network.net_propagation.personalized_pagerank_by_attribute',\n",
       "    'doc': \"Run personalized PageRank with reset probability proportional to a vertex attribute.\\nOptionally computes uniform PPR over nonzero attribute nodes. Parameters : g ( igraph.Graph ) – The input graph. attribute ( str ) – The vertex attribute to use for personalization. damping ( float , optional ) – Damping factor (default 0.85). calculate_uniform_dist ( bool , optional ) – If True, also compute uniform PPR over nonzero attribute nodes. additional_propagation_args ( dict , optional ) – Additional arguments to pass to igraph’s personalized_pagerank. Keys must match the method’s signature. Returns : DataFrame with columns [‘name’, ‘pagerank_by_attribute’, attribute] and optionally ‘pagerank_uniform’. Return type : pd.DataFrame Example >>> import igraph as ig >>> from scraps.utils import personalized_pagerank_by_attribute >>> g = ig . Graph . Full ( 3 ) >>> g . vs [ 'name' ] = [ 'A' , 'B' , 'C' ] >>> g . vs [ 'score' ] = [ 1 , 0 , 2 ] >>> df = personalized_pagerank_by_attribute ( g , 'score' ) >>> print ( df )\"}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.network.net_utils': {'module': 'napistu.network.net_utils',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_utils.html#module-napistu.network.net_utils',\n",
       "  'functions': {'_create_induced_subgraph': {'name': '_create_induced_subgraph',\n",
       "    'signature': 'napistu.network.net_utils._create_induced_subgraph(cpr_graph:Graph,vertices=None,n_vertices:int=5000)→Graph',\n",
       "    'id': 'napistu.network.net_utils._create_induced_subgraph',\n",
       "    'doc': 'Utility function for creating subgraphs including a set of vertices and their connections'},\n",
       "   '_create_network_save_string': {'name': '_create_network_save_string',\n",
       "    'signature': 'napistu.network.net_utils._create_network_save_string(model_prefix:str,outdir:str,directed:bool,graph_type:str)→str',\n",
       "    'id': 'napistu.network.net_utils._create_network_save_string',\n",
       "    'doc': ''},\n",
       "   '_get_top_n_component_stats': {'name': '_get_top_n_component_stats',\n",
       "    'signature': 'napistu.network.net_utils._get_top_n_component_stats(graph:Graph,components,component_sizes:Sequence[int],n:int=10,ascending:bool=False)→list[dict[str,Any]]',\n",
       "    'id': 'napistu.network.net_utils._get_top_n_component_stats',\n",
       "    'doc': 'Summarize the top N components’ network properties.'},\n",
       "   '_get_top_n_idx': {'name': '_get_top_n_idx',\n",
       "    'signature': 'napistu.network.net_utils._get_top_n_idx(arr:Sequence,n:int,ascending:bool=False)→Sequence[int]',\n",
       "    'id': 'napistu.network.net_utils._get_top_n_idx',\n",
       "    'doc': 'Returns the indices of the top n values in an array Parameters : arr ( Sequence ) – An array of values n ( int ) – The number of top values to return ascending ( bool , optional ) – Whether to return the top or bottom n values. Defaults to False. Returns : The indices of the top n values Return type : Sequence[int]'},\n",
       "   '_get_top_n_nodes': {'name': '_get_top_n_nodes',\n",
       "    'signature': 'napistu.network.net_utils._get_top_n_nodes(graph:Graph,vals:Sequence,val_name:str,n:int=10,ascending:bool=False)→list[dict[str,Any]]',\n",
       "    'id': 'napistu.network.net_utils._get_top_n_nodes',\n",
       "    'doc': 'Get the top N nodes by a node attribute.'},\n",
       "   '_get_top_n_objects': {'name': '_get_top_n_objects',\n",
       "    'signature': 'napistu.network.net_utils._get_top_n_objects(object_vals:Sequence,objects:Sequence,n:int=10,ascending:bool=False)→list',\n",
       "    'id': 'napistu.network.net_utils._get_top_n_objects',\n",
       "    'doc': 'Get the top N objects based on a ranking measure.'},\n",
       "   '_validate_assets_graph_dist': {'name': '_validate_assets_graph_dist',\n",
       "    'signature': 'napistu.network.net_utils._validate_assets_graph_dist(cpr_graph:Graph,precomputed_distances:DataFrame)→None',\n",
       "    'id': 'napistu.network.net_utils._validate_assets_graph_dist',\n",
       "    'doc': '“Check an cpr_graph and precomputed distances table for inconsistencies.'},\n",
       "   '_validate_assets_sbml_graph': {'name': '_validate_assets_sbml_graph',\n",
       "    'signature': 'napistu.network.net_utils._validate_assets_sbml_graph(sbml_dfs:SBML_dfs,cpr_graph:Graph)→None',\n",
       "    'id': 'napistu.network.net_utils._validate_assets_sbml_graph',\n",
       "    'doc': '“Check an sbml_dfs model and cpr_graph for inconsistencies.'},\n",
       "   '_validate_edge_attributes': {'name': '_validate_edge_attributes',\n",
       "    'signature': 'napistu.network.net_utils._validate_edge_attributes(graph:Graph,edge_attributes:list[str])→None',\n",
       "    'id': 'napistu.network.net_utils._validate_edge_attributes',\n",
       "    'doc': 'Check for the existence of one or more edge attributes.'},\n",
       "   '_validate_vertex_attributes': {'name': '_validate_vertex_attributes',\n",
       "    'signature': 'napistu.network.net_utils._validate_vertex_attributes(graph:Graph,vertex_attributes:list[str])→None',\n",
       "    'id': 'napistu.network.net_utils._validate_vertex_attributes',\n",
       "    'doc': 'Check for the existence of one or more vertex attributes.'},\n",
       "   'compartmentalize_species': {'name': 'compartmentalize_species',\n",
       "    'signature': 'napistu.network.net_utils.compartmentalize_species(sbml_dfs:SBML_dfs,species:str|list[str])→DataFrame',\n",
       "    'id': 'napistu.network.net_utils.compartmentalize_species',\n",
       "    'doc': 'Compartmentalize Species Returns the compartmentalized species IDs (sc_ids) corresponding to a list of species (s_ids) Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways species ( list ) – Species IDs Return type : pd.DataFrame containings the s_id and sc_id pairs'},\n",
       "   'compartmentalize_species_pairs': {'name': 'compartmentalize_species_pairs',\n",
       "    'signature': 'napistu.network.net_utils.compartmentalize_species_pairs(sbml_dfs:SBML_dfs,origin_species:str|list[str],dest_species:str|list[str])→DataFrame',\n",
       "    'id': 'napistu.network.net_utils.compartmentalize_species_pairs',\n",
       "    'doc': 'Compartmentalize Shortest Paths For a set of origin and destination species pairs, consider each species in every compartment it operates in, seperately. Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways origin_species ( list ) – Species IDs as starting points dest_species ( list ) – Species IDs as ending points Return type : pd.DataFrame containing pairs of origin and destination compartmentalized species'},\n",
       "   'cpr_graph_to_pandas_dfs': {'name': 'cpr_graph_to_pandas_dfs',\n",
       "    'signature': 'napistu.network.net_utils.cpr_graph_to_pandas_dfs(cpr_graph:Graph)',\n",
       "    'id': 'napistu.network.net_utils.cpr_graph_to_pandas_dfs',\n",
       "    'doc': 'CPR Graph to Pandas DataFrames Take an igraph representation of a network and turn it into vertices and edges tables. Parameters : cpr_graph ( ig.Graph ) – an igraph network Returns : A table with one row per vertex.\\nedges (pd.DataFrame): A table with one row per edge. Return type : vertices (pd.DataFrame)'},\n",
       "   'export_networks': {'name': 'export_networks',\n",
       "    'signature': \"napistu.network.net_utils.export_networks(sbml_dfs:SBML_dfs,model_prefix:str,outdir:str,directeds:list[bool]=[True,False],graph_types:list[str]=['bipartite','regulatory'])→None\",\n",
       "    'id': 'napistu.network.net_utils.export_networks',\n",
       "    'doc': 'Exports Networks Create one or more network from a pathway model and pickle the results Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A pathway model model_prefix ( str ) – Label to prepend to all exported files outdir ( str ) – Path to an existing directory where results should be saved directeds ( [ bool ] ) – List of directed types to export: a directed (True) or undirected graph be made (False) graph_types ( [ str ] ) – Types of graphs to construct, valid values are: bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products regulatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products Returns ---------- None'},\n",
       "   'filter_to_largest_subgraph': {'name': 'filter_to_largest_subgraph',\n",
       "    'signature': 'napistu.network.net_utils.filter_to_largest_subgraph(cpr_graph:Graph)→Graph',\n",
       "    'id': 'napistu.network.net_utils.filter_to_largest_subgraph',\n",
       "    'doc': 'Filter a graph to its largest weakly connected component.'},\n",
       "   'get_graph_summary': {'name': 'get_graph_summary',\n",
       "    'signature': 'napistu.network.net_utils.get_graph_summary(graph:Graph)→dict[str,Any]',\n",
       "    'id': 'napistu.network.net_utils.get_graph_summary',\n",
       "    'doc': 'Calculates common summary statistics for a network Parameters : graph ( ig.Graph ) – An igraph Returns : A dictionary of summary statistics with values n_edges [int]: number of edges\\nn_vertices [int]: number of vertices\\nn_components [int]: number of weakly connected components (i.e. without considering edge directionality) stats_component_sizes [dict[str, float]]: summary statistics for the component sizes\\ntop10_large_components [list[dict[str, Any]]]: the top 10 largest components with 10 example vertices\\ntop10_smallest_components [list[dict[str, Any]]]: the top 10 smallest components with 10 example vertices\\naverage_path_length [float]: the average shortest path length between all vertices\\ntop10_betweenness [list[dict[str, Any]]]: the top 10 vertices by betweenness centrality. Roughly: measures how many shortest paths go through a vertices top10_harmonic_centrality [list[dict[str, Any]]]: the top 10 vertices by harmonic centrality: Roughly: mean inverse distance to all other vertices Return type : dict'},\n",
       "   'get_minimal_sources_edges': {'name': 'get_minimal_sources_edges',\n",
       "    'signature': 'napistu.network.net_utils.get_minimal_sources_edges(vertices:DataFrame,sbml_dfs:SBML_dfs)→DataFrame|None',\n",
       "    'id': 'napistu.network.net_utils.get_minimal_sources_edges',\n",
       "    'doc': 'Assign edges to a set of sources.'},\n",
       "   'read_graph_attrs_spec': {'name': 'read_graph_attrs_spec',\n",
       "    'signature': 'napistu.network.net_utils.read_graph_attrs_spec(graph_attrs_spec_uri:str)→dict',\n",
       "    'id': 'napistu.network.net_utils.read_graph_attrs_spec',\n",
       "    'doc': 'Read a YAML file containing the specification for adding reaction- and/or species-attributes to a cpr_graph.'},\n",
       "   'read_network_pkl': {'name': 'read_network_pkl',\n",
       "    'signature': 'napistu.network.net_utils.read_network_pkl(model_prefix:str,network_dir:str,graph_type:str,directed:bool=True)→Graph',\n",
       "    'id': 'napistu.network.net_utils.read_network_pkl',\n",
       "    'doc': 'Read Network Pickle Read a saved network representation. Params \\uf0c1 model_prefix: str Type of model to import network_dir: str Path to a directory containing all saved networks. directed bool Should a directed (True) or undirected graph be loaded (False) graph_type [str] Type of graphs to read, valid values are: bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products reguatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products returns : network_graph – An igraph network of the pathway rtype : igraph.Graph'},\n",
       "   'safe_fill': {'name': 'safe_fill',\n",
       "    'signature': 'napistu.network.net_utils.safe_fill(x,fill_width=15)',\n",
       "    'id': 'napistu.network.net_utils.safe_fill',\n",
       "    'doc': ''},\n",
       "   'validate_assets': {'name': 'validate_assets',\n",
       "    'signature': 'napistu.network.net_utils.validate_assets(sbml_dfs:SBML_dfs,cpr_graph:Graph,precomputed_distances:DataFrame,identifiers_df:DataFrame)→None',\n",
       "    'id': 'napistu.network.net_utils.validate_assets',\n",
       "    'doc': 'Validate Assets Perform a few quick checks of inputs to catch inconsistencies. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A pathway representation. cpr_graph ( igraph.Graph ) – A network-based representation of “sbml_dfs”. precomputed_distances ( pd.DataFrame ) – Precomputed distances between vertices in “cpr_graph”. identifiers_df ( pd.DataFrame ) – A table of systematic identifiers for compartmentalized species in “sbml_dfs”. Returns : None'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.network.paths': {'module': 'napistu.network.paths',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.paths.html#module-napistu.network.paths',\n",
       "  'functions': {'_calculate_net_polarity': {'name': '_calculate_net_polarity',\n",
       "    'signature': 'napistu.network.paths._calculate_net_polarity(link_polarity_series:Series)→str',\n",
       "    'id': 'napistu.network.paths._calculate_net_polarity',\n",
       "    'doc': 'Determine whether a path implies activation, inhbition, or an ambiguous regulatory relationship.'},\n",
       "   '_filter_paths_by_precomputed_distances': {'name': '_filter_paths_by_precomputed_distances',\n",
       "    'signature': 'napistu.network.paths._filter_paths_by_precomputed_distances(all_species_pairs:DataFrame,precomputed_distances:DataFrame|None=None)→DataFrame',\n",
       "    'id': 'napistu.network.paths._filter_paths_by_precomputed_distances',\n",
       "    'doc': 'Filter source -> destination pairs based on precomputed distances if they were provided.'},\n",
       "   '_label_path_reactions': {'name': '_label_path_reactions',\n",
       "    'signature': 'napistu.network.paths._label_path_reactions(sbml_dfs:SBML_dfs,paths_df:DataFrame)',\n",
       "    'id': 'napistu.network.paths._label_path_reactions',\n",
       "    'doc': 'Create labels for reactions in a shortest path.'},\n",
       "   '_patch': {'name': '_patch',\n",
       "    'signature': 'napistu.network.paths._patch(x:Any)',\n",
       "    'id': 'napistu.network.paths._patch',\n",
       "    'doc': ''},\n",
       "   '_terminal_net_polarity': {'name': '_terminal_net_polarity',\n",
       "    'signature': 'napistu.network.paths._terminal_net_polarity(link_polarity_series:Series)→str',\n",
       "    'id': 'napistu.network.paths._terminal_net_polarity',\n",
       "    'doc': 'Figure out the net polarity for the vertex at the end of a path.'},\n",
       "   'find_all_shortest_reaction_paths': {'name': 'find_all_shortest_reaction_paths',\n",
       "    'signature': \"napistu.network.paths.find_all_shortest_reaction_paths(cpr_graph:Graph,sbml_dfs:SBML_dfs,target_species_paths:DataFrame,weight_var:str='weights',precomputed_distances:DataFrame|None=None)\",\n",
       "    'id': 'napistu.network.paths.find_all_shortest_reaction_paths',\n",
       "    'doc': 'Shortest Reaction Paths Find all shortest paths between a source and destination entity Parameters : cpr_graph ( igraph.Graph ) – A bipartite network connecting molecular species and reactions sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways target_species_paths ( pd.DataFrame ) – Pairs of source and destination compartmentalized species; produced by compartmentalize_species_pairs() weight_var ( str ) – An edge attribute to use when forming a weighted shortest path precomputed_distances ( pd.DataFrame | None ) – A table containing precalculated path summaries between pairs of compartmentalized species Returns ---------- all_shortest_reaction_paths_df ( pd.DataFrame ) – Nodes in all shortest paths all_shortest_reaction_path_edges_df ( pd.DataFrame ) – Edges in all shortest paths edge_sources ( pd.DataFrame ) – Sources of edge identifying the models where they originated paths_graph ( igraph.Graph ) – Network formed by all shortest paths'},\n",
       "   'find_shortest_reaction_paths': {'name': 'find_shortest_reaction_paths',\n",
       "    'signature': 'napistu.network.paths.find_shortest_reaction_paths(cpr_graph:Graph,sbml_dfs:SBML_dfs,origin:str,dest:str|list,weight_var:str)→tuple[DataFrame,DataFrame]|None',\n",
       "    'id': 'napistu.network.paths.find_shortest_reaction_paths',\n",
       "    'doc': 'Shortest Reaction Paths Find all shortest paths between an origin and destination entity Parameters : cpr_graph ( igraph.Graph ) – A bipartite network connecting molecular species and reactions sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A model formed by aggregating pathways origin ( str ) – A node to start at dest ( str | list ) – Node(s) to reach weight_var ( str ) – An edge attribute to use when forming a weighted shortest path Returns ---------- pd.DataFrames ( Node paths and edges )'},\n",
       "   'plot_shortest_paths': {'name': 'plot_shortest_paths',\n",
       "    'signature': 'napistu.network.paths.plot_shortest_paths(paths_graph:Graph)→plot',\n",
       "    'id': 'napistu.network.paths.plot_shortest_paths',\n",
       "    'doc': 'Plot a shortest paths graph.'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.network.precompute': {'module': 'napistu.network.precompute',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.precompute.html#module-napistu.network.precompute',\n",
       "  'functions': {'_calculate_distances_subset': {'name': '_calculate_distances_subset',\n",
       "    'signature': \"napistu.network.precompute._calculate_distances_subset(cpr_graph:Graph,vs_to_partition:DataFrame,one_partition:DataFrame,weights_vars:list[str]=['weights','upstream_weights'])→DataFrame\",\n",
       "    'id': 'napistu.network.precompute._calculate_distances_subset',\n",
       "    'doc': 'Calculate distances from a subset of vertices to all vertices.'},\n",
       "   '_filter_precomputed_distances': {'name': '_filter_precomputed_distances',\n",
       "    'signature': \"napistu.network.precompute._filter_precomputed_distances(precomputed_distances:DataFrame,max_steps:float|int=inf,max_score_q:float=1,path_weights_vars:list[str]=['path_weights','path_upstream_weights'])→DataFrame\",\n",
       "    'id': 'napistu.network.precompute._filter_precomputed_distances',\n",
       "    'doc': 'Filter precomputed distances by maximum steps and/or to low scores by quantile.'},\n",
       "   'precompute_distances': {'name': 'precompute_distances',\n",
       "    'signature': \"napistu.network.precompute.precompute_distances(cpr_graph:Graph,max_steps:int=-1,max_score_q:float=1.0,partition_size:int=5000,weights_vars:list[str]=['weights','upstream_weights'])→DataFrame\",\n",
       "    'id': 'napistu.network.precompute.precompute_distances',\n",
       "    'doc': 'Pre-Compute Distances Parameters : cpr_graph ( ig.Graph ) – An igraph network model max_steps ( int ) – The maximum number of steps between pairs of species to save a distance max_score_q ( float ) – Retain up to the “max_score_q” quantiles of all scores (small scores are better) partition_size ( int ) – The number of species to process together when computing distances. Decreasing this\\nvalue will lower the overall memory footprint of distance calculation. weights_vars ( list ) – One or more variables defining edge weights to use when calculating weighted\\nshortest paths. Shortest paths will be separately calculated with each type of\\nweights and used to construct path weights named according to ‘path_{weight_var}’ Returns ---------- containing ( A pd.DataFrame ) sc_id_origin ( - ) sc_id_dest ( - ) path_length ( - ) path_weight* ( - ) – * One variable will exist for each weight specified in ‘weights_vars’'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.rpy2': {'module': 'napistu.rpy2',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.html#module-napistu.rpy2',\n",
       "  'functions': {'_r_homer_warning': {'name': '_r_homer_warning',\n",
       "    'signature': 'napistu.rpy2._r_homer_warning()→None',\n",
       "    'id': 'napistu.rpy2._r_homer_warning',\n",
       "    'doc': ''},\n",
       "   'report_r_exceptions': {'name': 'report_r_exceptions',\n",
       "    'signature': 'napistu.rpy2.report_r_exceptions(function)',\n",
       "    'id': 'napistu.rpy2.report_r_exceptions',\n",
       "    'doc': ''},\n",
       "   'rsession_info': {'name': 'rsession_info',\n",
       "    'signature': 'napistu.rpy2.rsession_info()→None',\n",
       "    'id': 'napistu.rpy2.rsession_info',\n",
       "    'doc': ''},\n",
       "   'warn_if_no_rpy2': {'name': 'warn_if_no_rpy2',\n",
       "    'signature': 'napistu.rpy2.warn_if_no_rpy2(func)',\n",
       "    'id': 'napistu.rpy2.warn_if_no_rpy2',\n",
       "    'doc': ''}},\n",
       "  'classes': {},\n",
       "  'submodules': {'callr': {'url': 'napistu.rpy2.callr.html#module-napistu.rpy2.callr',\n",
       "    'description': ''},\n",
       "   'constants': {'url': 'napistu.rpy2.constants.html#module-napistu.rpy2.constants',\n",
       "    'description': 'Module for Rpy2 module-specific constants'},\n",
       "   'netcontextr': {'url': 'napistu.rpy2.netcontextr.html#module-napistu.rpy2.netcontextr',\n",
       "    'description': \"Module containing functions to interoperate with rcpr's netcontextr functions\"},\n",
       "   'rids': {'url': 'napistu.rpy2.rids.html#module-napistu.rpy2.rids',\n",
       "    'description': ''}}},\n",
       " 'napistu.rpy2.callr': {'module': 'napistu.rpy2.callr',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.callr.html#module-napistu.rpy2.callr',\n",
       "  'functions': {'_get_py2rpy_pandas_conv': {'name': '_get_py2rpy_pandas_conv',\n",
       "    'signature': 'napistu.rpy2.callr._get_py2rpy_pandas_conv()',\n",
       "    'id': 'napistu.rpy2.callr._get_py2rpy_pandas_conv',\n",
       "    'doc': 'Get the py2rpy arrow converter for pandas This is a high-performance converter using\\nthe rpy2-arrow functionality: https://rpy2.github.io/rpy2-arrow/version/main/html/index.html Returns : The converter function Return type : Callable'},\n",
       "   'bioconductor_org_r_function': {'name': 'bioconductor_org_r_function',\n",
       "    'signature': 'napistu.rpy2.callr.bioconductor_org_r_function(object_type:str,species:str,r_paths:list[str]|None=None)',\n",
       "    'id': 'napistu.rpy2.callr.bioconductor_org_r_function',\n",
       "    'doc': 'Bioconuctor Organism R Function Calls “bioconductor_org_function” from the R cpr package to pull a mapping object\\nout of a species specific library. Parameters:\\nobject_type (str): Type of function to call species (str): Species name r_paths: list(str): Paths to add to .libPaths() in R. Alternatively consider setting the R_HOME env variable. Returns:\\npd.DataFrame or a function for non-tabular results'},\n",
       "   'get_rbase': {'name': 'get_rbase',\n",
       "    'signature': 'napistu.rpy2.callr.get_rbase(r_paths:list[str]|None=None)→InstalledSTPackage|InstalledPackage',\n",
       "    'id': 'napistu.rpy2.callr.get_rbase',\n",
       "    'doc': 'Get the base R package Parameters : r_paths ( list [ str ] , optional ) – Optional additional\\nr_paths. Defaults to None. Returns : _description_ Return type : _type_'},\n",
       "   'get_rcpr': {'name': 'get_rcpr',\n",
       "    'signature': 'napistu.rpy2.callr.get_rcpr(r_paths:list[str]|None=None)',\n",
       "    'id': 'napistu.rpy2.callr.get_rcpr',\n",
       "    'doc': 'Get rcpr Gets the rcpr R package Parameters : r_paths ( list [ str ] ) – Paths to add to .libPaths() in R Returns : rcpr R package'},\n",
       "   'pandas_to_r_dataframe': {'name': 'pandas_to_r_dataframe',\n",
       "    'signature': 'napistu.rpy2.callr.pandas_to_r_dataframe(df:pd.DataFrame)→rpy2.robjects.DataFrame',\n",
       "    'id': 'napistu.rpy2.callr.pandas_to_r_dataframe',\n",
       "    'doc': 'Convert a pandas dataframe to an R dataframe This uses the rpy2-arrow functionality\\nto increase the performance of conversion orders of magnitude. Parameters : df ( pd.DataFrame ) – Pandas dataframe Returns : R dataframe Return type : rpy2.robjects.DataFrame'},\n",
       "   'r_dataframe_to_pandas': {'name': 'r_dataframe_to_pandas',\n",
       "    'signature': 'napistu.rpy2.callr.r_dataframe_to_pandas(rdf:rpy2.robjects.DataFrame)→pd.DataFrame',\n",
       "    'id': 'napistu.rpy2.callr.r_dataframe_to_pandas',\n",
       "    'doc': 'Convert an R dataframe to a pandas dataframe Parameters : rdf ( rpy2.robjects.DataFrame ) – R dataframe Returns : Pandas dataframe Return type : pd.DataFrame'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.rpy2.constants': {'module': 'napistu.rpy2.constants',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.constants.html#module-napistu.rpy2.constants',\n",
       "  'functions': {'_map_sbo_identifiers': {'name': '_map_sbo_identifiers',\n",
       "    'signature': 'napistu.rpy2.constants._map_sbo_identifiers()→dict[str,str]',\n",
       "    'id': 'napistu.rpy2.constants._map_sbo_identifiers',\n",
       "    'doc': 'Map sbo identifiers to netcontextr identifiers'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.rpy2.netcontextr': {'module': 'napistu.rpy2.netcontextr',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.netcontextr.html#module-napistu.rpy2.netcontextr',\n",
       "  'functions': {'_get_reactions': {'name': '_get_reactions',\n",
       "    'signature': \"napistu.rpy2.netcontextr._get_reactions(sbml_dfs:SBML_dfs,identifier_ontology:str='ensembl_gene')→DataFrame\",\n",
       "    'id': 'napistu.rpy2.netcontextr._get_reactions',\n",
       "    'doc': 'Gets the reactions from the sbml_dfs'},\n",
       "   '_get_rids_from_rcpr_reactions': {'name': '_get_rids_from_rcpr_reactions',\n",
       "    'signature': 'napistu.rpy2.netcontextr._get_rids_from_rcpr_reactions(rcpr_reactions:ListVector)→set[str]',\n",
       "    'id': 'napistu.rpy2.netcontextr._get_rids_from_rcpr_reactions',\n",
       "    'doc': 'Gets the r_ids from the rcpr reactions'},\n",
       "   '_none2null': {'name': '_none2null',\n",
       "    'signature': 'napistu.rpy2.netcontextr._none2null(none_obj)',\n",
       "    'id': 'napistu.rpy2.netcontextr._none2null',\n",
       "    'doc': ''},\n",
       "   'annotate_genes': {'name': 'annotate_genes',\n",
       "    'signature': 'napistu.rpy2.netcontextr.annotate_genes(rcpr,rcpr_graph:ListVector,data,field_name:str,**kwargs)→ListVector',\n",
       "    'id': 'napistu.rpy2.netcontextr.annotate_genes',\n",
       "    'doc': 'Annotates the genes in the graph with the given gene data See the rcpr documentation about the exact format\\nrequired. Parameters : ( ) ( rcpr ) – The rpy2 rcpr object rcpr_graph ( ListVector ) – The graph to annotate data ( complicated ) – ” field_name ( str ) – The name of the column in the gene data to annotate with Returns : The annotated graph Return type : ListVector'},\n",
       "   'apply_context_to_sbml_dfs': {'name': 'apply_context_to_sbml_dfs',\n",
       "    'signature': 'napistu.rpy2.netcontextr.apply_context_to_sbml_dfs(sbml_dfs:sbml_dfs_core.SBML_dfs,rcpr_graph:ListVector,inplace=True,remove_species=False)→sbml_dfs_core.SBML_dfs',\n",
       "    'id': 'napistu.rpy2.netcontextr.apply_context_to_sbml_dfs',\n",
       "    'doc': 'Applies the context to the SBML dfs This is currently an in-place modification of\\nthe sbml_dfs object. Parameters : sbml_dfs ( SbmlDfs ) – The SBML dfs to apply the context to rcpr_graph ( ListVector ) – The graph to apply the context from inplace ( bool , optional ) – Whether to modify the sbml_dfs in-place\\nwhen applying the context. Defaults to True. “False” not yet implemented. remove_species ( bool , optional ) – Whether to remove\\n(compartmentalized) species that are no longer in the reactions.\\nDefaults to False. Returns : The SBML dfs with the context applied Return type : SbmlDfs'},\n",
       "   'apply_reactions_context_to_sbml_dfs': {'name': 'apply_reactions_context_to_sbml_dfs',\n",
       "    'signature': 'napistu.rpy2.netcontextr.apply_reactions_context_to_sbml_dfs(sbml_dfs:sbml_dfs_core.SBML_dfs,rcpr_reactions:ListVector,considered_reactions:Iterable[str]|None=None,inplace=True,remove_species=False)→sbml_dfs_core.SBML_dfs',\n",
       "    'id': 'napistu.rpy2.netcontextr.apply_reactions_context_to_sbml_dfs',\n",
       "    'doc': 'Applies the context to the SBML dfs This is currently an in-place modification of\\nthe sbml_dfs object. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML dfs to apply the context to rcpr_reactions ( ListVector ) – The contextualized considered_reactions ( Iterable [ str ] , optional ) – The reactions that were\\nconsidered for contextualisation. If None, all reactions that are\\nin the sbml_dfs are considered and filtered out if they are not part of\\nthe rcpr_reactions. If provided, only reactions considered and not part\\nof the rcpr_reactions are removed. Defaults to None. inplace ( bool , optional ) – Whether to apply the context inplace.\\nOnly True currently implemented. remove_species ( bool , optional ) – Whether to remove\\n(compartmentalized) species that are no longer in the reactions.\\nDefaults to False. Returns : The SBML dfs with the context applied Return type : SbmlDfs'},\n",
       "   'load_and_clean_gtex_data': {'name': 'load_and_clean_gtex_data',\n",
       "    'signature': 'napistu.rpy2.netcontextr.load_and_clean_gtex_data(rcpr_rpy2,uri_gtex:str,by_tissue_zfpkm:bool=False)',\n",
       "    'id': 'napistu.rpy2.netcontextr.load_and_clean_gtex_data',\n",
       "    'doc': 'Load and cleans GTEx data using rcpr Parameters : ( ) ( rcpr_rpy2 ) – The rpy2 rcpr object uri_gtex ( str ) – The uri of the GTEx data by_tissue_zfpkm ( bool , optional ) – Whether to return the data normalized\\nby tissue using zfpkm. Defaults to False. Returns : The cleaned GTEx data Return type : rpy2 object'},\n",
       "   'load_and_clean_hpa_data': {'name': 'load_and_clean_hpa_data',\n",
       "    'signature': 'napistu.rpy2.netcontextr.load_and_clean_hpa_data(rcpr,uri_hpa:str)',\n",
       "    'id': 'napistu.rpy2.netcontextr.load_and_clean_hpa_data',\n",
       "    'doc': 'Load and cleans HPA data using rcpr Parameters : ( ) ( rcpr ) – The rpy2 rcpr object uri_hpa ( str ) – The uri of the HPA data Returns : The cleaned HPA data Return type : rpy2 object'},\n",
       "   'sbml_dfs_to_rcpr_reactions': {'name': 'sbml_dfs_to_rcpr_reactions',\n",
       "    'signature': \"napistu.rpy2.netcontextr.sbml_dfs_to_rcpr_reactions(sbml_dfs:sbml_dfs_core.SBML_dfs,identifier_ontology:str='ensembl_gene')→ListVector\",\n",
       "    'id': 'napistu.rpy2.netcontextr.sbml_dfs_to_rcpr_reactions',\n",
       "    'doc': 'Converts an sbml_dfs to a rcpr reaction graph This utility converts the sbml_dfs to the format validated by\\nby rcpr::validate_netcontextr_reactions . It converts the smbl_dfs into a reaction graph by:\\n- Building the reactions dataframe: Using the species identifiers to map reaction_species to genes using the identifier_ontology .\\nNote that one species may be split into multiple genes and multiple species may be combined into a single gene . Converting sbo_terms to roles. renaming r_id to reaction_id Building genes dataframe by taking all unique genes from the reactions Parameters : sbml_dfs ( SBML_dfs ) – an sbml_dfs. identifier_ontology ( str , optional ) – The ontology to use for the\\nidentifiers. Defaults to ensembl_gene (default in rcpr) Returns : genes : a dataframe with column gene reactions : a dataframe with columns “gene”, “reaction_id”, “role”, “rsc_id” representing the reaction data split up into individual reactions. Return type : This is a list of dataframes that validate with validate_netcontextr_reactions'},\n",
       "   'sbml_dfs_to_rcpr_string_graph': {'name': 'sbml_dfs_to_rcpr_string_graph',\n",
       "    'signature': \"napistu.rpy2.netcontextr.sbml_dfs_to_rcpr_string_graph(sbml_dfs:sbml_dfs_core.SBML_dfs,reaction_data:str='string',identifier_ontology:str='ensembl_gene',rescale_data:Callable[[pd.DataFrame],pd.DataFrame]|None=<function<lambda>>)→ListVector\",\n",
       "    'id': 'napistu.rpy2.netcontextr.sbml_dfs_to_rcpr_string_graph',\n",
       "    'doc': 'Converts an sbml_dfs to a rcpr string graph This utility converts the sbml_dfs to the format returned\\nby rcpr::createStringGraph . Parameters : sbml_dfs ( SBML_dfs ) – the sbml_dfs from string.\\nIt is assumed that this sbml_dfs has only reactions with exactly\\ntwo reactands and a 1:1 mapping between s_id and sc_id. reaction_data ( str , optional ) – The reaction data that contains\\nthe string scores. Defaults to ‘string’. identifier_ontology ( str , optional ) – The ontology to use for the\\nprotein identifiers. Defaults to ensembl_gene (default in rcpr) rescale_data ( Callable [ pd.DataFrame ] , optional ) – A function to rescale\\nthe data. Defaults to lambda x: x/1000 (default in rcpr) Returns : genes : a dataframe with column gene and the extra column s_id , sc_id interactions : a dataframe with columns protein1 , protein2 and the scores from string\\nand the extra column r_id The extra columns s_id and r_id are used to map the genes and reactions\\nto the sbml_dfs. This is useful for mapping back rcpr results to the\\nsbml_dfs. Return type : This is a list of dataframes almost the same as rcpr::createStringGraph'},\n",
       "   'trim_network_by_gene_attribute': {'name': 'trim_network_by_gene_attribute',\n",
       "    'signature': 'napistu.rpy2.netcontextr.trim_network_by_gene_attribute(rcpr,rcpr_graph:ListVector,field_name:str,field_value:Any=None,**kwargs)→ListVector',\n",
       "    'id': 'napistu.rpy2.netcontextr.trim_network_by_gene_attribute',\n",
       "    'doc': 'Trims the network by a gene attribute See the R function rcpr::trim_network_by_gene_attribute for\\nmore details. Parameters : ( ) ( rcpr ) – The rpy2 rcpr object rcpr_graph ( ListVector ) – The graph to trim field_name ( str ) – The name of the column in the gene data to trim by field_value ( Any ) – One or more values to trim by Returns : The trimmed graph Return type : ListVector'},\n",
       "   'trim_reactions_by_gene_attribute': {'name': 'trim_reactions_by_gene_attribute',\n",
       "    'signature': 'napistu.rpy2.netcontextr.trim_reactions_by_gene_attribute(rcpr,rcpr_reactions:ListVector,field_name:str,field_value:Any=None,**kwargs)→ListVector',\n",
       "    'id': 'napistu.rpy2.netcontextr.trim_reactions_by_gene_attribute',\n",
       "    'doc': 'Trims rcpr reactions by a gene attribute See the R function rcpr::trim_reactions_by_gene_attribute for\\nmore details. Parameters : ( ) ( rcpr ) – The rpy2 rcpr object rcpr_reactions ( ListVector ) – The graph to trim field_name ( str ) – The name of the column in the gene data to trim by field_value ( Any ) – One or more values to trim by Returns : The trimmed graph Return type : ListVector'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.rpy2.rids': {'module': 'napistu.rpy2.rids',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.rids.html#module-napistu.rpy2.rids',\n",
       "  'functions': {'_check_species_identifiers_entrez_gene_ontology': {'name': '_check_species_identifiers_entrez_gene_ontology',\n",
       "    'signature': 'napistu.rpy2.rids._check_species_identifiers_entrez_gene_ontology(entity_identifiers_df:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.rpy2.rids._check_species_identifiers_entrez_gene_ontology',\n",
       "    'doc': 'Check whether species ontologies contain ncbigene or ncbi_gene\\nIf so, replaced them to ncbi_entrez_gene.\\nReturn: entity_identifiers_df with proper gene ontology types.'},\n",
       "   '_expand_identifiers_new_entries': {'name': '_expand_identifiers_new_entries',\n",
       "    'signature': 'napistu.rpy2.rids._expand_identifiers_new_entries(sysid:str,expanded_identifiers_df:DataFrame)→Identifiers',\n",
       "    'id': 'napistu.rpy2.rids._expand_identifiers_new_entries',\n",
       "    'doc': 'Expand Identifiers to include Bioconductor annotations'},\n",
       "   'connect_dogmatic_mappings': {'name': 'connect_dogmatic_mappings',\n",
       "    'signature': 'napistu.rpy2.rids.connect_dogmatic_mappings(species:str,r_paths:str|None=None)→dict',\n",
       "    'id': 'napistu.rpy2.rids.connect_dogmatic_mappings',\n",
       "    'doc': 'Connect Dogmatic Mappings Merge all ontologies into greedy clusters based on shared associations to entrez ids Parameters : species ( str ) – An organismal species (e.g., Homo sapiens) r_paths ( str or None ) – Optional, p]ath to an R packages directory Returns : s_name_series: a series where the index is distinct molecular species and the values are names. cluster_consensus_identifiers_df: a pd.DataFrame where the index is distinct molecular species\\nand values are identifiers objects. Return type : dict with'},\n",
       "   'create_bioconductor_mapping_tables': {'name': 'create_bioconductor_mapping_tables',\n",
       "    'signature': 'napistu.rpy2.rids.create_bioconductor_mapping_tables(mappings:set[str],species:str,r_paths:str|None=None)→dict[str,DataFrame]',\n",
       "    'id': 'napistu.rpy2.rids.create_bioconductor_mapping_tables',\n",
       "    'doc': 'Create Bioconductor Mapping Tables Creating a dictionary of mappings between entrez and other ontologies. Parameters : mappings ( set ) – A set of ontologies to work with. The valid ontologies are:\\n“ensembl_gene”, “ensembl_transcript”, and “uniprot”. species ( str ) – The organismal species that we are working with (e.g., Homo sapiens). r_paths ( str , optional ) – Optional path to a library of R packages. Returns : A table of entrez ids, and tables mapping from each ontology in “mappings” to entrez. Return type : mappings_dict (dict)'},\n",
       "   'create_dogmatic_sbml_dfs': {'name': 'create_dogmatic_sbml_dfs',\n",
       "    'signature': 'napistu.rpy2.rids.create_dogmatic_sbml_dfs(species:str,r_paths:str|None=None)→SBML_dfs',\n",
       "    'id': 'napistu.rpy2.rids.create_dogmatic_sbml_dfs',\n",
       "    'doc': 'Create Dogmatic SMBL_DFs Create an SBML_dfs model which is pretty much just proteins and no\\nreactions, as well as annotations linking proteins to genes, and\\ncreating nice labels for genes/proteins. Parameters : species ( str ) – An organismal species (e.g., Homo sapiens) r_paths ( str or None ) – Optional, p]ath to an R packages directory Returns : dogmatic_sbml_dfs (sbml.SBML_dfs) A pathway model which (pretty much) just contains proteins and\\ndiverse identifiers'},\n",
       "   'expand_identifiers': {'name': 'expand_identifiers',\n",
       "    'signature': 'napistu.rpy2.rids.expand_identifiers(sbml_dfs:SBML_dfs,id_type:str,species:str,expanded_ontologies:list[str],r_paths:str|None=None)→Series',\n",
       "    'id': 'napistu.rpy2.rids.expand_identifiers',\n",
       "    'doc': 'Expand Identifiers Update a table’s identifiers to include additional related ontologies Ontologies are pulled from the bioconductor “org” packages. This is effective, but inelegant. Parameters : sbml_dfs ( SBML_dfs ) – A relational pathway model built around reactions interconverting compartmentalized species. id_type ( str ) – Identifiers to expand: species, compartments, or reactions species ( str ) – Species name expanded_ontologies ( list ) – Ontologies to add or complete r_paths ( str ) – Path to an R packages directory Return type : a pd.Series with identifiers as the index and updated Identifiers objects as values'},\n",
       "   'merge_bioconductor_mappings': {'name': 'merge_bioconductor_mappings',\n",
       "    'signature': 'napistu.rpy2.rids.merge_bioconductor_mappings(mappings_dict:dict,mapping_ontologies:set[str])→DataFrame',\n",
       "    'id': 'napistu.rpy2.rids.merge_bioconductor_mappings',\n",
       "    'doc': 'Combine multiple ontologies by recursively joining on Entrez Gene'},\n",
       "   'stack_bioconductor_mappings': {'name': 'stack_bioconductor_mappings',\n",
       "    'signature': 'napistu.rpy2.rids.stack_bioconductor_mappings(mappings_dict:dict[str,DataFrame],mapping_ontologies:set[str])→DataFrame',\n",
       "    'id': 'napistu.rpy2.rids.stack_bioconductor_mappings',\n",
       "    'doc': 'Stack Bioconductor Mappings Convert a dict of mappings between entrez identifiers and other identifiers to a single table. Parameters : mappings_dict ( dict ) – A dictionary containing mappings between entrez and other ontologies. mapping_ontologies ( set ) – A set of mappings to combine. Returns : A table containing entrez_gene_id, ontology, and identifier. Return type : mappings_df (pd.DataFrame)'},\n",
       "   'update_expanded_identifiers': {'name': 'update_expanded_identifiers',\n",
       "    'signature': 'napistu.rpy2.rids.update_expanded_identifiers(model:SBML_dfs,id_type:str,expanded_ids:Series)→SBML_dfs',\n",
       "    'id': 'napistu.rpy2.rids.update_expanded_identifiers',\n",
       "    'doc': 'Update the expanded identifiers for a model. Parameters : model ( sbml_dfs_core.SBML_dfs ) – _description_ id_type ( str ) – _description_ expanded_ids ( str ) – _description_'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.sbml_dfs_core': {'module': 'napistu.sbml_dfs_core',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_core.html#module-napistu.sbml_dfs_core',\n",
       "  'functions': {'_sbml_dfs_from_edgelist_check_cspecies_merge': {'name': '_sbml_dfs_from_edgelist_check_cspecies_merge',\n",
       "    'signature': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_check_cspecies_merge(merged_species:DataFrame,original_species:DataFrame)→None',\n",
       "    'id': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_check_cspecies_merge',\n",
       "    'doc': 'Check for a mismatch between the provided species data and species implied by the edgelist.'},\n",
       "   '_sbml_dfs_from_edgelist_validate_inputs': {'name': '_sbml_dfs_from_edgelist_validate_inputs',\n",
       "    'signature': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_validate_inputs(interaction_edgelist:DataFrame,species_df:DataFrame,compartments_df:DataFrame)→None',\n",
       "    'id': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_validate_inputs',\n",
       "    'doc': 'Check that the inputs for creating an SBML_dfs from an edgelist are appropriate.'},\n",
       "   '_stub_compartments': {'name': '_stub_compartments',\n",
       "    'signature': \"napistu.sbml_dfs_core._stub_compartments(stubbed_compartment:str='CELLULAR_COMPONENT')→DataFrame\",\n",
       "    'id': 'napistu.sbml_dfs_core._stub_compartments',\n",
       "    'doc': 'Stub Compartments Create a compartments table with only a single compartment Args:\\nstubbed_compartment (str): the name of a compartment which should match the keys in constants.COMPARTMENTS and constants.COMPARTMENTS_GO_TERMS Returns:\\ncompartments_df (pd.DataFrame): compartments dataframe'},\n",
       "   '_validate_matching_data': {'name': '_validate_matching_data',\n",
       "    'signature': 'napistu.sbml_dfs_core._validate_matching_data(data_table:DataFrame,ref_table:DataFrame)',\n",
       "    'id': 'napistu.sbml_dfs_core._validate_matching_data',\n",
       "    'doc': 'Validates a table against a reference This check if the table has the same index, no duplicates in the index\\nand that all values in the index are in the reference table. Parameters : data_table ( pd.DataFrame ) – a table with data that should\\nmatch the reference ref_table ( pd.DataFrame ) – a reference table Raises : ValueError – not same index name ValueError – index contains duplicates ValueError – index not subset of index of reactions table'},\n",
       "   'add_stoi_to_species_name': {'name': 'add_stoi_to_species_name',\n",
       "    'signature': 'napistu.sbml_dfs_core.add_stoi_to_species_name(stoi:float|int,name:str)→str',\n",
       "    'id': 'napistu.sbml_dfs_core.add_stoi_to_species_name',\n",
       "    'doc': 'Add Stoi To Species Name Add # of molecules to a species name Parameters: \\uf0c1 stoi: float or int Number of molecules name: str Name of species Returns: \\uf0c1 name: str Name containing number of species'},\n",
       "   'construct_formula_string': {'name': 'construct_formula_string',\n",
       "    'signature': 'napistu.sbml_dfs_core.construct_formula_string(reaction_species_df:DataFrame,reactions_df:DataFrame,name_var:str)→str',\n",
       "    'id': 'napistu.sbml_dfs_core.construct_formula_string',\n",
       "    'doc': 'Construct Formula String Convert a table of reaction species into a formula string Parameters: \\uf0c1 reaction_species_df: pd.DataFrame Table containing a reactions’ species reactions_df: pd.DataFrame smbl.reactions name_var: str Name used to label species Returns: \\uf0c1 formula_str: str String representation of a reactions substrates, products and\\nmodifiers'},\n",
       "   'export_sbml_dfs': {'name': 'export_sbml_dfs',\n",
       "    'signature': 'napistu.sbml_dfs_core.export_sbml_dfs(model_prefix:str,sbml_dfs:SBML_dfs,outdir:str,overwrite:bool=False,dogmatic:bool=True)→None',\n",
       "    'id': 'napistu.sbml_dfs_core.export_sbml_dfs',\n",
       "    'doc': 'Export SBML_dfs Export summaries of species identifiers and each table underlying\\nan SBML_dfs pathway model Params \\uf0c1 model_prefix: str Label to prepend to all exported files sbml_dfs: sbml.SBML_dfs A pathway model outdir: str Path to an existing directory where results should be saved overwrite: bool Should the directory be overwritten if it already exists? dogmatic: bool If True then treat genes, transcript, and proteins as separate species. If False\\nthen treat them interchangeably. rtype : None'},\n",
       "   'filter_to_characteristic_species_ids': {'name': 'filter_to_characteristic_species_ids',\n",
       "    'signature': \"napistu.sbml_dfs_core.filter_to_characteristic_species_ids(species_ids:DataFrame,max_complex_size:int=4,max_promiscuity:int=20,defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→DataFrame\",\n",
       "    'id': 'napistu.sbml_dfs_core.filter_to_characteristic_species_ids',\n",
       "    'doc': 'Filter to Characteristic Species IDs Remove identifiers corresponding to one component within a large protein\\ncomplexes and non-characteristic annotations such as pubmed references and\\nhomologues. Parameters : species_ids ( pd.DataFrame ) – A table of identifiers produced by sdbml_dfs.get_identifiers(“species”) max_complex_size ( int ) – The largest size of a complex, where BQB_HAS_PART terms will be retained.\\nIn most cases, complexes are handled with specific formation and\\ndissolutation reactions,but these identifiers will be pulled in when\\nsearching by identifiers or searching the identifiers associated with a\\nspecies against an external resource such as Open Targets. max_promiscuity ( int ) – Maximum number of species where a single molecule can act as a\\nBQB_HAS_PART component associated with a single identifier (and common ontology). ( list [ str ] ) ( defining_biological_qualifiers ) – BQB codes which define distinct entities. Narrowly this would be BQB_IS, while more\\npermissive settings would include homologs, different forms of the same gene. Returns -------- species_id ( pd.DataFrame ) – Input species filtered to characteristic identifiers'},\n",
       "   'find_underspecified_reactions': {'name': 'find_underspecified_reactions',\n",
       "    'signature': 'napistu.sbml_dfs_core.find_underspecified_reactions(sbml_dfs:SBML_dfs,sc_ids:Iterable[str])→set[str]',\n",
       "    'id': 'napistu.sbml_dfs_core.find_underspecified_reactions',\n",
       "    'doc': 'Find Underspecified reactions Identity reactions which should be removed if a set of molecular species are removed\\nfrom the system. Params:\\nsbml_dfs (SBML_dfs): A pathway representation sc_ids (list[str]) A list of compartmentalized species ids (sc_ids) which will be removed. Returns:\\nunderspecified_reactions (set[str]): A list of reactions which should be removed because they will not occur once\\n“sc_ids” are removed.'},\n",
       "   'infer_sbo_terms': {'name': 'infer_sbo_terms',\n",
       "    'signature': 'napistu.sbml_dfs_core.infer_sbo_terms(sbml_dfs:SBML_dfs)→SBML_dfs',\n",
       "    'id': 'napistu.sbml_dfs_core.infer_sbo_terms',\n",
       "    'doc': 'Infer SBO Terms Define SBO terms based on stoichiometry for reaction_species with missing terms Parameters: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model Returns: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model (with missing/invalid reaction species sbo_terms resolved)'},\n",
       "   'infer_uncompartmentalized_species_location': {'name': 'infer_uncompartmentalized_species_location',\n",
       "    'signature': 'napistu.sbml_dfs_core.infer_uncompartmentalized_species_location(sbml_dfs:SBML_dfs)→SBML_dfs',\n",
       "    'id': 'napistu.sbml_dfs_core.infer_uncompartmentalized_species_location',\n",
       "    'doc': 'Infer Uncompartmentalized Species Location If the compartment of a subset of compartmentalized species\\nwas not specified, infer an appropriate compartment from\\nother members of reactions they particpate in Parameters: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model Returns: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model (with filled in species compartments)'},\n",
       "   'name_compartmentalized_species': {'name': 'name_compartmentalized_species',\n",
       "    'signature': 'napistu.sbml_dfs_core.name_compartmentalized_species(sbml_dfs)',\n",
       "    'id': 'napistu.sbml_dfs_core.name_compartmentalized_species',\n",
       "    'doc': 'Name Compartmentalized Species Rename compartmentalized species if they have the same\\nname as their species Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways Returns ---------- sbml_dfs'},\n",
       "   'reaction_summaries': {'name': 'reaction_summaries',\n",
       "    'signature': 'napistu.sbml_dfs_core.reaction_summaries(sbml_dfs:SBML_dfs,r_ids=None)→Series',\n",
       "    'id': 'napistu.sbml_dfs_core.reaction_summaries',\n",
       "    'doc': 'Reaction Summary Return human-readable formulas for reactions. Parameters: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational mechanistic model r_ids: [str], str or None Reaction IDs or None for all reactions Returns: \\uf0c1 formula_strs: pd.Series'},\n",
       "   'reaction_summary': {'name': 'reaction_summary',\n",
       "    'signature': 'napistu.sbml_dfs_core.reaction_summary(r_id:str,sbml_dfs:SBML_dfs)→DataFrame',\n",
       "    'id': 'napistu.sbml_dfs_core.reaction_summary',\n",
       "    'doc': 'Reaction Summary Return a reaction’s name and a human-readable formula. Parameters:\\nr_id: str A reaction ID sbml_dfs: SBML_dfs Returns:\\none row pd.DataFrame'},\n",
       "   'sbml_dfs_from_edgelist': {'name': 'sbml_dfs_from_edgelist',\n",
       "    'signature': \"napistu.sbml_dfs_core.sbml_dfs_from_edgelist(interaction_edgelist:DataFrame,species_df:DataFrame,compartments_df:DataFrame,interaction_source:Source,upstream_stoichiometry:int=0,downstream_stoichiometry:int=1,downstream_sbo_name:str='product',keep_species_data:bool|str=False,keep_reactions_data:bool|str=False)→SBML_dfs\",\n",
       "    'id': 'napistu.sbml_dfs_core.sbml_dfs_from_edgelist',\n",
       "    'doc': 'Create SBML_dfs from Edgelist Combine a set of interactions into an sbml.SBML_dfs mechanistic model Parameters:\\ninteraction_edgelist (pd.DataFrame): A table containing interactions: upstream_name (str): matching “s_name” from “species_df” downstream_name (str): matching “s_name” from “species_df” upstream_compartment (str): compartment of “upstream_name” with names matching “c_name” from “compartments_df” downstream_compartment (str): compartment of “downstream_name” with names matching “c_name” from “compartments_df” r_name (str): a name for the interaction sbo_term (str): sbo term defining the type of molecular interaction (see MINI_SBO_FROM_NAME) r_Identifiers (identifiers.Identifiers): identifiers supporting the interaction (e.g., pubmed ids) r_isreversible (bool): Is this reaction reversible? If True, the reaction is reversible\\nBy default, the interactions of TRRUST networks are irreversible, and reversible for STRING networks species_df (pd.DataFrame): A table defining unique molecular species participating in “interaction_edgelist”:\\n- s_name (str): name of molecular species\\n- s_Identifiers (identifiers.Identifiers): identifiers defining the species compartments_df (pd.DataFrame): A table defining compartments where interactions are occurring “interaction_edgelist”:\\n- c_name (str): name of compartment\\n- c_Identifiers (identifiers.Identifiers): identifiers defining the compartment (see\\nbigg.annotate_recon() for a set of names > go categories) interaction_source (source.Source): A source object which will tie model entities to the interaction source upstream_stoichiometry (int): stoichiometry of upstream species in reaction downstream_stoichiometry (int): stoichiometry of downstream species in reaction downstream_sbo_name (str): sbo term defining the type of molecular interaction for the downstream reactand\\n(see MINI_SBO_FROM_NAME) keep_species_data (bool | str): Should species data be kept in the model? If True, all species data will be kept\\nand saved as “species_data” in the SBML_dfs. The label will be ‘source’\\nIf False, no species data will be kept.\\nIf a string: label for the species data to be kept. keep_reactions_data (bool | str): Should reaction data be kept in the model? If True, all reaction data will be kept and saved\\nas “reactions_data” in the SBML_dfs. The label will be ‘source’.\\nIf False, no reaction data will be kept.\\nIf a string: label for the reaction data to be kept. Returns:\\nsbml.SBML_dfs'},\n",
       "   'species_status': {'name': 'species_status',\n",
       "    'signature': 'napistu.sbml_dfs_core.species_status(s_id:str,sbml_dfs:SBML_dfs)→DataFrame',\n",
       "    'id': 'napistu.sbml_dfs_core.species_status',\n",
       "    'doc': 'Species Status Return all of the reaction’s a species particpates in. Parameters:\\ns_id: str A species ID sbml_dfs: SBML_dfs Returns:\\npd.DataFrame, one row reaction'},\n",
       "   'species_type_types': {'name': 'species_type_types',\n",
       "    'signature': 'napistu.sbml_dfs_core.species_type_types(x)',\n",
       "    'id': 'napistu.sbml_dfs_core.species_type_types',\n",
       "    'doc': 'Assign a high-level molecule type to a molecular species'},\n",
       "   'stub_ids': {'name': 'stub_ids',\n",
       "    'signature': 'napistu.sbml_dfs_core.stub_ids(ids)',\n",
       "    'id': 'napistu.sbml_dfs_core.stub_ids',\n",
       "    'doc': ''}},\n",
       "  'classes': {'SBML_dfs': {'name': 'SBML_dfs',\n",
       "    'signature': 'classnapistu.sbml_dfs_core.SBML_dfs(sbml_model:SBML|MutableMapping[str,DataFrame|dict[str,DataFrame]],validate:bool=True,resolve:bool=True)',\n",
       "    'id': 'napistu.sbml_dfs_core.SBML_dfs',\n",
       "    'doc': 'Bases: object System Biology Markup Language Model Data Frames. compartments \\uf0c1 sub-cellular compartments in the model Type : pd.DataFrame species \\uf0c1 molecular species in the model Type : pd.DataFrame species_data \\uf0c1 DataFrames with additional data and index = species_id Type : Dict[str, pd.DataFrame]: Additional data for species. reactions \\uf0c1 reactions in the model Type : pd.DataFrame reactions_data \\uf0c1 DataFrames with additional data and index = reaction_id Type : Dict[str, pd.DataFrame]: Additional data for reactions. reaction_species \\uf0c1 One entry per species participating in a reaction Type : pd.DataFrame schema \\uf0c1 dictionary reprenting the structure of the other attributes and meaning of their variables Type : dict get_table ( entity_type , required_attributes ) \\uf0c1 Get a table from the SBML_dfs object and optionally validate that it contains a set of required attributes search_by_ids ( ids , entity_type , identifiers_df , ontologies ) \\uf0c1 Pull out identifiers and entities matching a set of query ids which optionally match a set of ontologies search_by_name ( name , entity_type , partial_match ) \\uf0c1 Pull out a set of entities by name or partial string match [default] get_cspecies_features ( ) \\uf0c1 Returns additional attributes of compartmentalized species get_species_features ( ) \\uf0c1 Returns additional attributes of species get_identifiers ( id_type ) \\uf0c1 Returns a DataFrame containing identifiers from the id_type table get_uri_urls ( entity_type , entity_ids = None ) \\uf0c1 Returns a Series containing reference urls for each entity validate ( ) \\uf0c1 Validate that the sbml_dfs follows the schema and identify clear pathologies validate_and_rec ( ) \\uf0c1 Validate the sbml_dfs and attempt to automatically resolve common issues __init__ ( sbml_model : SBML | MutableMapping [ str , DataFrame | dict [ str , DataFrame ] ] , validate : bool = True , resolve : bool = True ) → None \\uf0c1 Creates a pathway Parameters : sbml_model ( cpr.SBML or a dict containing tables following the sbml_dfs schema ) – A SBML model produced by cpr.SBML(). ( bool ) ( resolve ) ( bool ) Return type : None. _attempt_resolve ( e ) \\uf0c1 _get_unused_cspecies ( ) → set [ str ] \\uf0c1 Returns a set of compartmentalized species\\nthat are not part of any reactions _get_unused_species ( ) → set [ str ] \\uf0c1 Returns a list of species that are not part of any reactions _remove_compartmentalized_species ( sc_ids : Iterable [ str ] ) \\uf0c1 Removes compartmentalized species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. Parameters : sc_ids ( Iterable [ str ] ) – the compartmentalized species to remove _remove_species ( s_ids : Iterable [ str ] ) \\uf0c1 Removes species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. This removes the species and corresponding compartmentalized species and\\nreactions_species. Parameters : s_ids ( Iterable [ str ] ) – the species to remove _remove_unused_cspecies ( ) \\uf0c1 Removes compartmentalized species that are no\\nlonger part of any reactions _remove_unused_species ( ) \\uf0c1 Removes species that are no longer part of any\\ncompartmentalized species _validate_reaction_species ( ) \\uf0c1 _validate_reactions_data ( reactions_data_table : DataFrame ) \\uf0c1 Validates reactions data attribute Parameters : reactions_data_table ( pd.DataFrame ) – a reactions data table Raises : ValueError – r_id not index name ValueError – r_id index contains duplicates ValueError – r_id not in reactions table _validate_species_data ( species_data_table : DataFrame ) \\uf0c1 Validates species data attribute Parameters : species_data_table ( pd.DataFrame ) – a species data table Raises : ValueError – s_id not index name ValueError – s_id index contains duplicates ValueError – s_id not in species table add_reactions_data ( label : str , data : DataFrame ) \\uf0c1 Adds additional reaction_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with reactions add_species_data ( label : str , data : DataFrame ) \\uf0c1 Adds additional species_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with species get_cspecies_features ( ) → DataFrame \\uf0c1 get_identifiers ( id_type ) → DataFrame \\uf0c1 get_network_summary ( ) → Mapping [ str , Any ] \\uf0c1 Return diagnostic statistics about the network Returns : A dictionary of diagnostic statistics with entries: n_species_types [int]: Number of species types\\ndict_n_species_per_type [dict[str, int]]: Number of species per species type n_species [int]: Number of species\\nn_cspecies [int]: Number of compartmentalized species\\nn_reaction_species [int]: Number of reaction species\\nn_reactions [int]: Number of reactions\\nn_compartments [int]: Number of compartments\\ndict_n_species_per_compartment [dict[str, int]]: Number of species per compartment stats_species_per_reaction [dict[str, float]]: Statistics on the number of reactands per reaction top10_species_per_reaction [list[dict[str, Any]]]: Top 10 reactions with highest number of reactands stats_degree [dict[str, float]]: Statistics on the degree of a species (number of reactions it is involved in) top10_degree [list[dict[str, Any]]]: Top 10 species with highest degree stats_identifiers_per_species [dict[str, float]]: Statistics on the number of identifiers per species top10_identifiers_per_species [list[dict[str, Any]]]: Top 10 species with highest number of identifiers Return type : Mapping[str, Any] get_species_features ( ) → DataFrame \\uf0c1 get_table ( entity_type : str , required_attributes : None | set [ str ] = None ) → DataFrame \\uf0c1 Get Table Get a table from the SBML_dfs object and optionally validate that it contains a set of required attributes. get_uri_urls ( entity_type : str , entity_ids : Iterable [ str ] | None = None , required_ontology : str | None = None ) → Series \\uf0c1 remove_compartmentalized_species ( sc_ids : Iterable [ str ] ) \\uf0c1 Starting with a set of compartmentalized species determine which reactions should be removed\\nbased on there removal. Then remove these reactions, compartmentalized species, and species. remove_reactions ( r_ids : Iterable [ str ] , remove_species : bool = False ) \\uf0c1 Removes reactions from the model Parameters : r_ids ( List [ str ] ) – the reactions to remove remove_species ( bool , optional ) – whether to remove species that are no longer\\npart of any reactions. Defaults to False. search_by_ids ( ids : list [ str ] , entity_type : str , identifiers_df : DataFrame , ontologies : None | set [ str ] = None ) → tuple [ DataFrame , DataFrame ] \\uf0c1 search_by_name ( name : str , entity_type : str , partial_match : bool = True ) → DataFrame \\uf0c1 validate ( ) \\uf0c1 Validates the object for obvious errors validate_and_resolve ( ) \\uf0c1 Call validate and try to iteratively resolve common validation errors _optional_entities : set [ str ] \\uf0c1 _required_entities : set [ str ] \\uf0c1 compartments : DataFrame \\uf0c1 reaction_species : DataFrame \\uf0c1 reactions : DataFrame \\uf0c1 reactions_data : dict [ str , DataFrame ] \\uf0c1 schema : dict \\uf0c1 species : DataFrame \\uf0c1 species_data : dict [ str , DataFrame ] \\uf0c1',\n",
       "    'methods': {'get_table': {'name': 'get_table',\n",
       "      'signature': 'get_table(entity_type:str,required_attributes:None|set[str]=None)→DataFrame',\n",
       "      'id': 'id3',\n",
       "      'doc': 'Get Table Get a table from the SBML_dfs object and optionally validate that it contains a set of required attributes.'},\n",
       "     'search_by_ids': {'name': 'search_by_ids',\n",
       "      'signature': 'search_by_ids(ids:list[str],entity_type:str,identifiers_df:DataFrame,ontologies:None|set[str]=None)→tuple[DataFrame,DataFrame]',\n",
       "      'id': 'id5',\n",
       "      'doc': ''},\n",
       "     'search_by_name': {'name': 'search_by_name',\n",
       "      'signature': 'search_by_name(name:str,entity_type:str,partial_match:bool=True)→DataFrame',\n",
       "      'id': 'id6',\n",
       "      'doc': ''},\n",
       "     'get_cspecies_features': {'name': 'get_cspecies_features',\n",
       "      'signature': 'get_cspecies_features()→DataFrame',\n",
       "      'id': 'id0',\n",
       "      'doc': ''},\n",
       "     'get_species_features': {'name': 'get_species_features',\n",
       "      'signature': 'get_species_features()→DataFrame',\n",
       "      'id': 'id2',\n",
       "      'doc': ''},\n",
       "     'get_identifiers': {'name': 'get_identifiers',\n",
       "      'signature': 'get_identifiers(id_type)→DataFrame',\n",
       "      'id': 'id1',\n",
       "      'doc': ''},\n",
       "     'get_uri_urls': {'name': 'get_uri_urls',\n",
       "      'signature': 'get_uri_urls(entity_type:str,entity_ids:Iterable[str]|None=None,required_ontology:str|None=None)→Series',\n",
       "      'id': 'id4',\n",
       "      'doc': ''},\n",
       "     'validate': {'name': 'validate',\n",
       "      'signature': 'validate()',\n",
       "      'id': 'id7',\n",
       "      'doc': 'Validates the object for obvious errors'},\n",
       "     'validate_and_rec': {'name': 'validate_and_rec',\n",
       "      'signature': 'validate_and_rec()',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.validate_and_rec',\n",
       "      'doc': 'Validate the sbml_dfs and attempt to automatically resolve common issues'},\n",
       "     '__init__': {'name': '__init__',\n",
       "      'signature': '__init__(sbml_model:SBML|MutableMapping[str,DataFrame|dict[str,DataFrame]],validate:bool=True,resolve:bool=True)→None',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.__init__',\n",
       "      'doc': 'Creates a pathway Parameters : sbml_model ( cpr.SBML or a dict containing tables following the sbml_dfs schema ) – A SBML model produced by cpr.SBML(). ( bool ) ( resolve ) ( bool ) Return type : None.'},\n",
       "     '_attempt_resolve': {'name': '_attempt_resolve',\n",
       "      'signature': '_attempt_resolve(e)',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._attempt_resolve',\n",
       "      'doc': ''},\n",
       "     '_get_unused_cspecies': {'name': '_get_unused_cspecies',\n",
       "      'signature': '_get_unused_cspecies()→set[str]',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._get_unused_cspecies',\n",
       "      'doc': 'Returns a set of compartmentalized species\\nthat are not part of any reactions'},\n",
       "     '_get_unused_species': {'name': '_get_unused_species',\n",
       "      'signature': '_get_unused_species()→set[str]',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._get_unused_species',\n",
       "      'doc': 'Returns a list of species that are not part of any reactions'},\n",
       "     '_remove_compartmentalized_species': {'name': '_remove_compartmentalized_species',\n",
       "      'signature': '_remove_compartmentalized_species(sc_ids:Iterable[str])',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_compartmentalized_species',\n",
       "      'doc': 'Removes compartmentalized species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. Parameters : sc_ids ( Iterable [ str ] ) – the compartmentalized species to remove'},\n",
       "     '_remove_species': {'name': '_remove_species',\n",
       "      'signature': '_remove_species(s_ids:Iterable[str])',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_species',\n",
       "      'doc': 'Removes species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. This removes the species and corresponding compartmentalized species and\\nreactions_species. Parameters : s_ids ( Iterable [ str ] ) – the species to remove'},\n",
       "     '_remove_unused_cspecies': {'name': '_remove_unused_cspecies',\n",
       "      'signature': '_remove_unused_cspecies()',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_unused_cspecies',\n",
       "      'doc': 'Removes compartmentalized species that are no\\nlonger part of any reactions'},\n",
       "     '_remove_unused_species': {'name': '_remove_unused_species',\n",
       "      'signature': '_remove_unused_species()',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_unused_species',\n",
       "      'doc': 'Removes species that are no longer part of any\\ncompartmentalized species'},\n",
       "     '_validate_reaction_species': {'name': '_validate_reaction_species',\n",
       "      'signature': '_validate_reaction_species()',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._validate_reaction_species',\n",
       "      'doc': ''},\n",
       "     '_validate_reactions_data': {'name': '_validate_reactions_data',\n",
       "      'signature': '_validate_reactions_data(reactions_data_table:DataFrame)',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._validate_reactions_data',\n",
       "      'doc': 'Validates reactions data attribute Parameters : reactions_data_table ( pd.DataFrame ) – a reactions data table Raises : ValueError – r_id not index name ValueError – r_id index contains duplicates ValueError – r_id not in reactions table'},\n",
       "     '_validate_species_data': {'name': '_validate_species_data',\n",
       "      'signature': '_validate_species_data(species_data_table:DataFrame)',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._validate_species_data',\n",
       "      'doc': 'Validates species data attribute Parameters : species_data_table ( pd.DataFrame ) – a species data table Raises : ValueError – s_id not index name ValueError – s_id index contains duplicates ValueError – s_id not in species table'},\n",
       "     'add_reactions_data': {'name': 'add_reactions_data',\n",
       "      'signature': 'add_reactions_data(label:str,data:DataFrame)',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.add_reactions_data',\n",
       "      'doc': 'Adds additional reaction_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with reactions'},\n",
       "     'add_species_data': {'name': 'add_species_data',\n",
       "      'signature': 'add_species_data(label:str,data:DataFrame)',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.add_species_data',\n",
       "      'doc': 'Adds additional species_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with species'},\n",
       "     'get_network_summary': {'name': 'get_network_summary',\n",
       "      'signature': 'get_network_summary()→Mapping[str,Any]',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.get_network_summary',\n",
       "      'doc': 'Return diagnostic statistics about the network Returns : A dictionary of diagnostic statistics with entries: n_species_types [int]: Number of species types\\ndict_n_species_per_type [dict[str, int]]: Number of species per species type n_species [int]: Number of species\\nn_cspecies [int]: Number of compartmentalized species\\nn_reaction_species [int]: Number of reaction species\\nn_reactions [int]: Number of reactions\\nn_compartments [int]: Number of compartments\\ndict_n_species_per_compartment [dict[str, int]]: Number of species per compartment stats_species_per_reaction [dict[str, float]]: Statistics on the number of reactands per reaction top10_species_per_reaction [list[dict[str, Any]]]: Top 10 reactions with highest number of reactands stats_degree [dict[str, float]]: Statistics on the degree of a species (number of reactions it is involved in) top10_degree [list[dict[str, Any]]]: Top 10 species with highest degree stats_identifiers_per_species [dict[str, float]]: Statistics on the number of identifiers per species top10_identifiers_per_species [list[dict[str, Any]]]: Top 10 species with highest number of identifiers Return type : Mapping[str, Any]'},\n",
       "     'remove_compartmentalized_species': {'name': 'remove_compartmentalized_species',\n",
       "      'signature': 'remove_compartmentalized_species(sc_ids:Iterable[str])',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.remove_compartmentalized_species',\n",
       "      'doc': 'Starting with a set of compartmentalized species determine which reactions should be removed\\nbased on there removal. Then remove these reactions, compartmentalized species, and species.'},\n",
       "     'remove_reactions': {'name': 'remove_reactions',\n",
       "      'signature': 'remove_reactions(r_ids:Iterable[str],remove_species:bool=False)',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.remove_reactions',\n",
       "      'doc': 'Removes reactions from the model Parameters : r_ids ( List [ str ] ) – the reactions to remove remove_species ( bool , optional ) – whether to remove species that are no longer\\npart of any reactions. Defaults to False.'},\n",
       "     'validate_and_resolve': {'name': 'validate_and_resolve',\n",
       "      'signature': 'validate_and_resolve()',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs.validate_and_resolve',\n",
       "      'doc': 'Call validate and try to iteratively resolve common validation errors'}},\n",
       "    'attributes': {'compartments': {'name': 'compartments',\n",
       "      'signature': 'compartments:DataFrame',\n",
       "      'id': 'id8',\n",
       "      'doc': ''},\n",
       "     'species': {'name': 'species',\n",
       "      'signature': 'species:DataFrame',\n",
       "      'id': 'id13',\n",
       "      'doc': ''},\n",
       "     'species_data': {'name': 'species_data',\n",
       "      'signature': 'species_data:dict[str,DataFrame]',\n",
       "      'id': 'id14',\n",
       "      'doc': ''},\n",
       "     'reactions': {'name': 'reactions',\n",
       "      'signature': 'reactions:DataFrame',\n",
       "      'id': 'id10',\n",
       "      'doc': ''},\n",
       "     'reactions_data': {'name': 'reactions_data',\n",
       "      'signature': 'reactions_data:dict[str,DataFrame]',\n",
       "      'id': 'id11',\n",
       "      'doc': ''},\n",
       "     'reaction_species': {'name': 'reaction_species',\n",
       "      'signature': 'reaction_species:DataFrame',\n",
       "      'id': 'id9',\n",
       "      'doc': ''},\n",
       "     'schema': {'name': 'schema',\n",
       "      'signature': 'schema:dict',\n",
       "      'id': 'id12',\n",
       "      'doc': ''},\n",
       "     '_optional_entities': {'name': '_optional_entities',\n",
       "      'signature': '_optional_entities:set[str]',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._optional_entities',\n",
       "      'doc': ''},\n",
       "     '_required_entities': {'name': '_required_entities',\n",
       "      'signature': '_required_entities:set[str]',\n",
       "      'id': 'napistu.sbml_dfs_core.SBML_dfs._required_entities',\n",
       "      'doc': ''}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.sbml_dfs_utils': {'module': 'napistu.sbml_dfs_utils',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_utils.html#module-napistu.sbml_dfs_utils',\n",
       "  'functions': {'_dogmatic_to_defining_bqbs': {'name': '_dogmatic_to_defining_bqbs',\n",
       "    'signature': 'napistu.sbml_dfs_utils._dogmatic_to_defining_bqbs(dogmatic:bool=False)→str',\n",
       "    'id': 'napistu.sbml_dfs_utils._dogmatic_to_defining_bqbs',\n",
       "    'doc': ''},\n",
       "   '_stub_ids': {'name': '_stub_ids',\n",
       "    'signature': 'napistu.sbml_dfs_utils._stub_ids(ids)',\n",
       "    'id': 'napistu.sbml_dfs_utils._stub_ids',\n",
       "    'doc': 'Stub with a blank ID if an ids list is blank; otherwise create an Identifiers object from the provided ids'},\n",
       "   'adapt_pw_index': {'name': 'adapt_pw_index',\n",
       "    'signature': 'napistu.sbml_dfs_utils.adapt_pw_index(source:str|PWIndex,species:str|Iterable[str]|None,outdir:str|None=None)→PWIndex',\n",
       "    'id': 'napistu.sbml_dfs_utils.adapt_pw_index',\n",
       "    'doc': 'Adapts a pw_index Helpful to filter for species before reconstructing. Parameters : source ( str | PWIndex ) – uri for pw_index.csv file or PWIndex object species ( str ) outdir ( str | None , optional ) – Optional directory to write pw_index to.\\nDefaults to None. Returns : Filtered pw index Return type : indices.PWIndex'},\n",
       "   'check_entity_data_index_matching': {'name': 'check_entity_data_index_matching',\n",
       "    'signature': 'napistu.sbml_dfs_utils.check_entity_data_index_matching(sbml_dfs,table)',\n",
       "    'id': 'napistu.sbml_dfs_utils.check_entity_data_index_matching',\n",
       "    'doc': 'Update the input smbl_dfs’s entity_data (dict) index\\nwith match_entitydata_index_to_entity,\\nso that index for dataframe(s) in entity_data (dict) matches the sbml_dfs’\\ncorresponding entity, and then passes sbml_dfs.validate()\\nArgs sbml_dfs (cpr.SBML_dfs): a cpr.SBML_dfs\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns sbml_dfs (cpr.SBML_dfs):\\nsbml_dfs whose entity_data is checked to have the same index\\nas the corresponding entity.'},\n",
       "   'get_characteristic_species_ids': {'name': 'get_characteristic_species_ids',\n",
       "    'signature': 'napistu.sbml_dfs_utils.get_characteristic_species_ids(sbml_dfs:SBML_dfs,dogmatic:bool=True)→DataFrame',\n",
       "    'id': 'napistu.sbml_dfs_utils.get_characteristic_species_ids',\n",
       "    'doc': 'Get Characteristic Species IDs List the systematic identifiers which are characteristic of molecular species, e.g., excluding subcomponents, and optionally, treating proteins, transcripts, and genes equiavlently. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object. dogmatic ( bool , default=True ) – Whether to use the dogmatic flag to determine which BQB attributes are valid. Returns : A DataFrame containing the systematic identifiers which are characteristic of molecular species. Return type : pd.DataFrame'},\n",
       "   'get_current_max_id': {'name': 'get_current_max_id',\n",
       "    'signature': 'napistu.sbml_dfs_utils.get_current_max_id(sbml_dfs_table:DataFrame)→int',\n",
       "    'id': 'napistu.sbml_dfs_utils.get_current_max_id',\n",
       "    'doc': 'Get Current Max ID Look at a table from an SBML_dfs object and find the largest primary key following\\nthe default naming convention for a the table. Params:\\nsbml_dfs_table (pd.DataFrame): A table derived from an SBML_dfs object. Returns:\\ncurrent_max_id (int): The largest id which is already defined in the table using its expected naming\\nconvention. If no IDs following this convention are present then the default\\nwill be -1. In this way new IDs will be added starting with 0.'},\n",
       "   'id_formatter': {'name': 'id_formatter',\n",
       "    'signature': 'napistu.sbml_dfs_utils.id_formatter(id_values:Iterable[Any],id_type:str,id_len:int=8)→list[str]',\n",
       "    'id': 'napistu.sbml_dfs_utils.id_formatter',\n",
       "    'doc': ''},\n",
       "   'id_formatter_inv': {'name': 'id_formatter_inv',\n",
       "    'signature': 'napistu.sbml_dfs_utils.id_formatter_inv(ids:list[str])→list[int]',\n",
       "    'id': 'napistu.sbml_dfs_utils.id_formatter_inv',\n",
       "    'doc': 'ID Formatter Inverter Convert from internal IDs back to integer IDs'},\n",
       "   'match_entitydata_index_to_entity': {'name': 'match_entitydata_index_to_entity',\n",
       "    'signature': 'napistu.sbml_dfs_utils.match_entitydata_index_to_entity(entity_data_dict:dict,an_entity_data_type:str,consensus_entity_df:DataFrame,entity_schema:dict,table:str)→DataFrame',\n",
       "    'id': 'napistu.sbml_dfs_utils.match_entitydata_index_to_entity',\n",
       "    'doc': 'Match the index of entity_data_dict[an_entity_data_type] with the index of corresponding entity.\\nUpdate entity_data_dict[an_entity_data_type]’s index to the same as consensus_entity_df’s index\\nReport cases where entity_data has indices not in corresponding entity’s index.\\nArgs entity_data_dict (dict): dictionary containing all model’s “an_entity_data_type” dictionaries\\nan_entity_data_type (str): data_type from species/reactions_data in entity_data_dict\\nconsensus_entity_df (pd.DataFrame): the dataframe of the corresponding entity\\nentity_schema (dict): schema for “table”\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns : entity_data_df (pd.DataFrame) table for entity_data_dict[an_entity_data_type]'},\n",
       "   'unnest_identifiers': {'name': 'unnest_identifiers',\n",
       "    'signature': 'napistu.sbml_dfs_utils.unnest_identifiers(id_table:DataFrame,id_var:str)→DataFrame',\n",
       "    'id': 'napistu.sbml_dfs_utils.unnest_identifiers',\n",
       "    'doc': 'Unnest Identifiers Take a pd.DataFrame containing an array of Identifiers and\\nreturn one-row per identifier. Parameters:\\nid_table: pd.DataFrame a table containing an array of Identifiers id_var: str variable containing Identifiers Returns:\\npd.Dataframe containing the index of id_table but expanded\\nto include one row per identifier'}},\n",
       "  'classes': {},\n",
       "  'submodules': {}},\n",
       " 'napistu.source': {'module': 'napistu.source',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.source.html#module-napistu.source',\n",
       "  'functions': {'_collapse_by_membership_string': {'name': '_collapse_by_membership_string',\n",
       "    'signature': 'napistu.source._collapse_by_membership_string(membership_string:str,membership_categories:DataFrame,table_schema:dict)→DataFrame',\n",
       "    'id': 'napistu.source._collapse_by_membership_string',\n",
       "    'doc': 'Assign each member of a membership-string to a set of pathways.'},\n",
       "   '_collapse_source_df': {'name': '_collapse_source_df',\n",
       "    'signature': 'napistu.source._collapse_source_df(source_df:DataFrame)→Series',\n",
       "    'id': 'napistu.source._collapse_source_df',\n",
       "    'doc': 'Collapse a source_df table into a single entry.'},\n",
       "   '_deduplicate_source_df': {'name': '_deduplicate_source_df',\n",
       "    'signature': 'napistu.source._deduplicate_source_df(source_df:DataFrame,table_schema:dict)→DataFrame',\n",
       "    'id': 'napistu.source._deduplicate_source_df',\n",
       "    'doc': 'Combine entries in a source table when multiple models have the same members.'},\n",
       "   '_safe_source_merge': {'name': '_safe_source_merge',\n",
       "    'signature': 'napistu.source._safe_source_merge(member_Sources:Source|list)→Source',\n",
       "    'id': 'napistu.source._safe_source_merge',\n",
       "    'doc': 'Combine either a Source or pd.Series of Sources into a single Source object.'},\n",
       "   'create_source_table': {'name': 'create_source_table',\n",
       "    'signature': 'napistu.source.create_source_table(lookup_table:Series,table_schema:dict,pw_index:PWIndex|None)→DataFrame',\n",
       "    'id': 'napistu.source.create_source_table',\n",
       "    'doc': 'Create Source Table Create a table with one row per “new_id” and a Source object created from the union of “old_id” Source objects'},\n",
       "   'greedy_set_coverge_of_sources': {'name': 'greedy_set_coverge_of_sources',\n",
       "    'signature': 'napistu.source.greedy_set_coverge_of_sources(source_df:DataFrame,table_schema:dict)→DataFrame',\n",
       "    'id': 'napistu.source.greedy_set_coverge_of_sources',\n",
       "    'doc': 'Greedy Set Coverage of Sources Apply the greedy set coverge algorithm to find the minimal set of sources which cover all entries Parameters:\\nsource_df: pd.DataFrame pd.Dataframe containing the index of source_table but expanded to\\ninclude one row per source. As produced by source.unnest_sources() Returns:\\nminimial_sources: [str] A list of pathway_ids of the minimal source set'},\n",
       "   'merge_sources': {'name': 'merge_sources',\n",
       "    'signature': 'napistu.source.merge_sources(source_list:list|Series)→Source',\n",
       "    'id': 'napistu.source.merge_sources',\n",
       "    'doc': 'Merge Sources Merge a list of Source objects into a single Source object'},\n",
       "   'unnest_sources': {'name': 'unnest_sources',\n",
       "    'signature': 'napistu.source.unnest_sources(source_table:DataFrame,source_var:str,verbose:bool=False)→DataFrame',\n",
       "    'id': 'napistu.source.unnest_sources',\n",
       "    'doc': 'Unnest Sources Take a pd.DataFrame containing an array of Sources and\\nreturn one-row per source. Parameters:\\nsource_table: pd.DataFrame a table containing an array of Sources source_var: str variable containing Sources Returns:\\npd.Dataframe containing the index of source_table but expanded\\nto include one row per source'}},\n",
       "  'classes': {'Source': {'name': 'Source',\n",
       "    'signature': 'classnapistu.source.Source(source_df:DataFrame|None=None,init:bool=False,pw_index:PWIndex|None=None)',\n",
       "    'id': 'napistu.source.Source',\n",
       "    'doc': 'Bases: object An Entity’s Source source \\uf0c1 A dataframe containing the model source and other optional variables Type : pd.DataFrame __init__ ( source_df : DataFrame | None = None , init : bool = False , pw_index : PWIndex | None = None ) → None \\uf0c1 Tracks the model(s) an entity (i.e., a compartment, species, reaction) came from. By convention sources exist only for the models that an entity came from rather\\nthan the current model they are part of. For example, when combining Reactome models\\ninto a consensus, a molecule which existed in multiple models would have a source entry\\nfor each, but it would not have a source entry for the consensus model itself. Parameters : source_df ( pd.DataFrame ) – A dataframe containing the model source and other optional variables init ( bool ) – Creates an empty source object. This is typically used when creating an SBML_dfs\\nobject from a single source. pw_index ( indices.PWIndex ) Return type : None.',\n",
       "    'methods': {'__init__': {'name': '__init__',\n",
       "      'signature': '__init__(source_df:DataFrame|None=None,init:bool=False,pw_index:PWIndex|None=None)→None',\n",
       "      'id': 'napistu.source.Source.__init__',\n",
       "      'doc': 'Tracks the model(s) an entity (i.e., a compartment, species, reaction) came from. By convention sources exist only for the models that an entity came from rather\\nthan the current model they are part of. For example, when combining Reactome models\\ninto a consensus, a molecule which existed in multiple models would have a source entry\\nfor each, but it would not have a source entry for the consensus model itself. Parameters : source_df ( pd.DataFrame ) – A dataframe containing the model source and other optional variables init ( bool ) – Creates an empty source object. This is typically used when creating an SBML_dfs\\nobject from a single source. pw_index ( indices.PWIndex ) Return type : None.'}},\n",
       "    'attributes': {'source': {'name': 'source',\n",
       "      'signature': 'source',\n",
       "      'id': 'napistu.source.Source.source',\n",
       "      'doc': 'A dataframe containing the model source and other optional variables Type : pd.DataFrame'}}}},\n",
       "  'submodules': {}},\n",
       " 'napistu.utils': {'module': 'napistu.utils',\n",
       "  'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.utils.html#module-napistu.utils',\n",
       "  'functions': {'_add_nameness_score': {'name': '_add_nameness_score',\n",
       "    'signature': 'napistu.utils._add_nameness_score(df,name_var)',\n",
       "    'id': 'napistu.utils._add_nameness_score',\n",
       "    'doc': 'Add a nameness_score variable which reflects how name-like each entry is.'},\n",
       "   '_add_nameness_score_wrapper': {'name': '_add_nameness_score_wrapper',\n",
       "    'signature': 'napistu.utils._add_nameness_score_wrapper(df,name_var,table_schema)',\n",
       "    'id': 'napistu.utils._add_nameness_score_wrapper',\n",
       "    'doc': 'Call _add_nameness_score with default value.'},\n",
       "   'check_unique_index': {'name': 'check_unique_index',\n",
       "    'signature': \"napistu.utils.check_unique_index(df,label='')\",\n",
       "    'id': 'napistu.utils.check_unique_index',\n",
       "    'doc': 'Validate that each index value only maps to a single row.'},\n",
       "   'click_str_to_list': {'name': 'click_str_to_list',\n",
       "    'signature': 'napistu.utils.click_str_to_list(string:str)→list[str]',\n",
       "    'id': 'napistu.utils.click_str_to_list',\n",
       "    'doc': 'Convert a string-based representation of a list inputted from the CLI into a list of strings.'},\n",
       "   'copy_uri': {'name': 'copy_uri',\n",
       "    'signature': 'napistu.utils.copy_uri(input_uri:str,output_uri:str,is_file=True)',\n",
       "    'id': 'napistu.utils.copy_uri',\n",
       "    'doc': 'Copy a file or folder from one uri to another Parameters : input_uri ( str ) – input file uri (gcs, http, …) output_uri ( str ) – path to output file (gcs, local) is_file ( bool , optional ) – Is this a file or folder?. Defaults to True.'},\n",
       "   'download_and_extract': {'name': 'download_and_extract',\n",
       "    'signature': \"napistu.utils.download_and_extract(url:str,output_dir_path:str='.',download_method:str='wget',overwrite:bool=False)→None\",\n",
       "    'id': 'napistu.utils.download_and_extract',\n",
       "    'doc': 'Download and Unpack Download an archive and then extract to a new folder Parameters : url ( str ) – Url of archive. output_dir_path ( str ) – Path to output directory. overwrite ( bool ) – Overwrite an existing output directory. Returns : None'},\n",
       "   'download_ftp': {'name': 'download_ftp',\n",
       "    'signature': 'napistu.utils.download_ftp(url,path)',\n",
       "    'id': 'napistu.utils.download_ftp',\n",
       "    'doc': ''},\n",
       "   'download_wget': {'name': 'download_wget',\n",
       "    'signature': 'napistu.utils.download_wget(url:str,path,target_filename:str=None,verify:bool=True)→None',\n",
       "    'id': 'napistu.utils.download_wget',\n",
       "    'doc': 'Downloades file / archive with wget Parameters : url ( str ) – url path ( FilePath | WriteBuffer ) – file path or buffer target_filename ( str ) – specific file to extract from ZIP if URL is a ZIP file verify ( bool ) – verify argument to pass to requests.get Returns : None'},\n",
       "   'drop_extra_cols': {'name': 'drop_extra_cols',\n",
       "    'signature': 'napistu.utils.drop_extra_cols(df_in:DataFrame,df_out:DataFrame,always_include:List[str]|None=None)→DataFrame',\n",
       "    'id': 'napistu.utils.drop_extra_cols',\n",
       "    'doc': \"Remove columns in df_out that are not in df_in, except those specified in always_include. Parameters : df_in ( pd.DataFrame ) – Reference DataFrame whose columns determine what to keep df_out ( pd.DataFrame ) – DataFrame to filter columns from always_include ( Optional [ List [ str ] ] , optional ) – List of column names to always include in output, even if not in df_in Returns : DataFrame with columns filtered to match df_in plus any always_include columns.\\nColumn order follows df_in, with always_include columns appended at the end. Return type : pd.DataFrame Examples >>> df_in = pd . DataFrame ({ 'a' : [ 1 ], 'b' : [ 2 ]}) >>> df_out = pd . DataFrame ({ 'a' : [ 3 ], 'c' : [ 4 ], 'd' : [ 5 ]}) >>> _drop_extra_cols ( df_in , df_out ) # Returns DataFrame with just column 'a' >>> _drop_extra_cols ( df_in , df_out , always_include = [ 'd' ]) # Returns DataFrame with columns ['a', 'd']\"},\n",
       "   'ensure_pd_df': {'name': 'ensure_pd_df',\n",
       "    'signature': 'napistu.utils.ensure_pd_df(pd_df_or_series:DataFrame|Series)→DataFrame',\n",
       "    'id': 'napistu.utils.ensure_pd_df',\n",
       "    'doc': 'Ensure Pandas DataFrame Convert a pd.Series to a DataFrame if needed. Parameters : pd_df_or_series ( pd.Series | pd.DataFrame ) – a pandas df or series Returns : pd_df converted to a pd.DataFrame if needed'},\n",
       "   'extract': {'name': 'extract',\n",
       "    'signature': 'napistu.utils.extract(file:str)',\n",
       "    'id': 'napistu.utils.extract',\n",
       "    'doc': 'Download and Unpack Untar, unzip and ungzip Parameters : file ( str ) – Path to compressed file Returns : None'},\n",
       "   'extract_regex_match': {'name': 'extract_regex_match',\n",
       "    'signature': 'napistu.utils.extract_regex_match(regex:str,query:str)→str',\n",
       "    'id': 'napistu.utils.extract_regex_match',\n",
       "    'doc': 'Parameters : regex ( str ) – regular expression to search query ( str ) – string to search against Returns : a character string match Return type : match (str)'},\n",
       "   'extract_regex_search': {'name': 'extract_regex_search',\n",
       "    'signature': 'napistu.utils.extract_regex_search(regex:str,query:str,index_value:int=0)→str',\n",
       "    'id': 'napistu.utils.extract_regex_search',\n",
       "    'doc': 'Match an identifier substring and otherwise throw an error Parameters : regex ( str ) – regular expression to search query ( str ) – string to search against index_value ( int ) – entry in index to return Returns : a character string match Return type : match (str)'},\n",
       "   'find_weakly_connected_subgraphs': {'name': 'find_weakly_connected_subgraphs',\n",
       "    'signature': 'napistu.utils.find_weakly_connected_subgraphs(edgelist:DataFrame)→DataFrame',\n",
       "    'id': 'napistu.utils.find_weakly_connected_subgraphs',\n",
       "    'doc': 'Find all cliques of loosly connected components.'},\n",
       "   'format_identifiers_as_edgelist': {'name': 'format_identifiers_as_edgelist',\n",
       "    'signature': 'napistu.utils.format_identifiers_as_edgelist(df:DataFrame,defining_vars:list[str])→DataFrame',\n",
       "    'id': 'napistu.utils.format_identifiers_as_edgelist',\n",
       "    'doc': 'Format Identifiers as Edgelist Collapse a multiindex to an index (if needed), and similarly collapse multiple variables to a single entry.\\nThis indexed pd.Sereies of index - ids can be treated as an edgelist for greedy clustering. Parameters : df ( pd.DataFrame ) – Any pd.DataFrame defining_vars ( list ( str ) ) – A set of attributes which define a distinct entry in df Returns : A pd.DataFrame with an “ind” and “id” variable added indicating rolled up\\nvalues of the index and defining_vars Return type : df (pd.DataFrame)'},\n",
       "   'get_extn_from_url': {'name': 'get_extn_from_url',\n",
       "    'signature': 'napistu.utils.get_extn_from_url(url:str)→str',\n",
       "    'id': 'napistu.utils.get_extn_from_url',\n",
       "    'doc': 'Retrieves file extension from an URL Parameters : url ( str ) – url Raises : ValueError – Raised when no extension identified Returns : the identified extension Return type : str Examples:\\n>>> get_extn_from_url(’ https://test/test.gz ’)\\n‘.gz’\\n>>> get_extn_from_url(’ https://test/test.tar.gz ’)\\n‘.tar.gz’\\n>>> get_extn_from_url(’ https://test/test.tar.gz/bla ’)\\nTraceback (most recent call last):\\n…\\nValueError: File extension not identifiable: https://test/test.tar.gz/bla'},\n",
       "   'get_source_base_and_path': {'name': 'get_source_base_and_path',\n",
       "    'signature': 'napistu.utils.get_source_base_and_path(uri:str)→tuple[str,str]',\n",
       "    'id': 'napistu.utils.get_source_base_and_path',\n",
       "    'doc': 'Get the base of a bucket or folder and the path to the file Parameters : uri ( str ) – uri Returns : base: the base folder of the bucket Return type : tuple[str, str] Example:\\n>>> get_source_base_and_path(“gs://bucket/folder/file”)\\n(‘gs://bucket’, ‘folder/file’)\\n>>> get_source_base_and_path(“/bucket/folder/file”)\\n(‘/bucket/folder’, ‘file’)'},\n",
       "   'get_target_base_and_path': {'name': 'get_target_base_and_path',\n",
       "    'signature': 'napistu.utils.get_target_base_and_path(uri)',\n",
       "    'id': 'napistu.utils.get_target_base_and_path',\n",
       "    'doc': 'Get the base of a bucket + directory and the file Parameters : uri ( str ) – uri Returns : base: the base folder + path of the bucket file: the file Return type : tuple[str, str] Example:\\n>>> get_target_base_and_path(“gs://bucket/folder/file”)\\n(‘gs://bucket/folder’, ‘file’)\\n>>> get_target_base_and_path(“bucket/folder/file”)\\n(‘bucket/folder’, ‘file’)\\n>>> get_target_base_and_path(“/bucket/folder/file”)\\n(‘/bucket/folder’, ‘file’)'},\n",
       "   'gunzip': {'name': 'gunzip',\n",
       "    'signature': 'napistu.utils.gunzip(gzipped_path:str,outpath:str|None=None)→None',\n",
       "    'id': 'napistu.utils.gunzip',\n",
       "    'doc': 'Gunzip a file to an output path.'},\n",
       "   'initialize_dir': {'name': 'initialize_dir',\n",
       "    'signature': 'napistu.utils.initialize_dir(output_dir_path:str,overwrite:bool)',\n",
       "    'id': 'napistu.utils.initialize_dir',\n",
       "    'doc': 'Initializes a filesystem directory Parameters : output_dir_path ( str ) – path to new directory overwrite ( bool ) – overwrite? if true, directory will be\\ndeleted and recreated Raises : FileExistsError –'},\n",
       "   'load_json': {'name': 'load_json',\n",
       "    'signature': 'napistu.utils.load_json(uri:str)→Any',\n",
       "    'id': 'napistu.utils.load_json',\n",
       "    'doc': 'Read json from uri Parameters : uri ( str ) – path to json file'},\n",
       "   'load_pickle': {'name': 'load_pickle',\n",
       "    'signature': 'napistu.utils.load_pickle(path:str)',\n",
       "    'id': 'napistu.utils.load_pickle',\n",
       "    'doc': 'Loads pickle object to path Parameters : path ( str ) – path to pickle Returns : Object Return type : Any'},\n",
       "   'path_exists': {'name': 'path_exists',\n",
       "    'signature': 'napistu.utils.path_exists(path:str)→bool',\n",
       "    'id': 'napistu.utils.path_exists',\n",
       "    'doc': 'Checks if path or uri exists Parameters : path ( str ) – path/uri Returns : exists? Return type : bool'},\n",
       "   'pickle_cache': {'name': 'pickle_cache',\n",
       "    'signature': 'napistu.utils.pickle_cache(path:str,overwrite:bool=False)',\n",
       "    'id': 'napistu.utils.pickle_cache',\n",
       "    'doc': 'A decorator to cache a function call result to pickle Attention: this does not care about the function arguments\\nAll function calls will be served by the same pickle file. Parameters : path ( str ) – path to the cache pickle file overwrite ( bool ) – should an existing cache be overwritten even\\nif it exists? Returns : A function whos output will be cached to pickle.'},\n",
       "   'read_pickle': {'name': 'read_pickle',\n",
       "    'signature': 'napistu.utils.read_pickle(path:str)',\n",
       "    'id': 'napistu.utils.read_pickle',\n",
       "    'doc': 'Loads pickle object to path Parameters : path ( str ) – path to pickle Returns : Object Return type : Any'},\n",
       "   'requests_retry_session': {'name': 'requests_retry_session',\n",
       "    'signature': 'napistu.utils.requests_retry_session(retries=5,backoff_factor=0.3,status_forcelist=(500,502,503,504),session:Session|None=None,**kwargs)→Session',\n",
       "    'id': 'napistu.utils.requests_retry_session',\n",
       "    'doc': 'Requests session with retry logic This should help to combat flaky apis, eg Brenda.\\nFrom: https://stackoverflow.com/a/58687549 Parameters : retries ( int , optional ) – Number of retries. Defaults to 5. backoff_factor ( float , optional ) – backoff. Defaults to 0.3. status_forcelist ( tuple , optional ) – errors to retry. Defaults to (500, 502, 503, 504). session ( Optional [ requests.Session ] , optional ) – existing session. Defaults to None. Returns : new requests session Return type : requests.Session'},\n",
       "   'safe_series_tolist': {'name': 'safe_series_tolist',\n",
       "    'signature': 'napistu.utils.safe_series_tolist(x)',\n",
       "    'id': 'napistu.utils.safe_series_tolist',\n",
       "    'doc': 'Convert either a list or str to a list.'},\n",
       "   'save_json': {'name': 'save_json',\n",
       "    'signature': 'napistu.utils.save_json(uri:str,object:Any)→None',\n",
       "    'id': 'napistu.utils.save_json',\n",
       "    'doc': 'Write object to json file at uri Parameters : object ( Any ) – object to write uri ( str ) – path to json file'},\n",
       "   'save_pickle': {'name': 'save_pickle',\n",
       "    'signature': 'napistu.utils.save_pickle(path:str,dat:object)',\n",
       "    'id': 'napistu.utils.save_pickle',\n",
       "    'doc': 'Saves object to path as pickle Parameters : path ( str ) – target path dat ( object ) – object'},\n",
       "   'score_nameness': {'name': 'score_nameness',\n",
       "    'signature': 'napistu.utils.score_nameness(string:str)',\n",
       "    'id': 'napistu.utils.score_nameness',\n",
       "    'doc': 'Score Nameness This utility assigns a numeric score to a string reflecting how likely it is to be\\na human readable name. This will help to prioritize readable entries when we are\\ntrying to pick out a single name to display from a set of values which may also\\ninclude entries like systematic ids. Parameters : string ( str ) – An alphanumeric string Returns : An integer score indicating how name-like the string is (low is more name-like) Return type : score (int)'},\n",
       "   'style_df': {'name': 'style_df',\n",
       "    'signature': \"napistu.utils.style_df(df:pd.DataFrame,headers:str|list[str]|None='keys',hide_index:bool=False)→pd.io.formats.style.Styler\",\n",
       "    'id': 'napistu.utils.style_df',\n",
       "    'doc': 'Style DataFrame Provide some simple options for styling a pd.DataFrame Parameters : df – pd.DataFrame\\nA table to style headers – “keys” to use the current column names None to suppress column names list[str] to overwrite and show column names hide_index – bool\\nShould rows be displayed? Returns : pd.io.formats.style.Styler df with styles updated Return type : styled_df'},\n",
       "   'write_file_contents_to_path': {'name': 'write_file_contents_to_path',\n",
       "    'signature': 'napistu.utils.write_file_contents_to_path(path:str,contents)→None',\n",
       "    'id': 'napistu.utils.write_file_contents_to_path',\n",
       "    'doc': 'Helper function to write file contents to the path. Parameters : path ( str ) – destination contents ( Any ) – file contents Returns : None'},\n",
       "   'write_pickle': {'name': 'write_pickle',\n",
       "    'signature': 'napistu.utils.write_pickle(path:str,dat:object)',\n",
       "    'id': 'napistu.utils.write_pickle',\n",
       "    'doc': 'Saves object to path as pickle Parameters : path ( str ) – target path dat ( object ) – object'}},\n",
       "  'classes': {'match_pd_vars': {'name': 'match_pd_vars',\n",
       "    'signature': 'classnapistu.utils.match_pd_vars(df:DataFrame|Series,req_vars:set,allow_series:bool=True)',\n",
       "    'id': 'napistu.utils.match_pd_vars',\n",
       "    'doc': 'Bases: object Match Pandas Variables. req_vars \\uf0c1 A set of variables which should exist in df missing_vars \\uf0c1 Required variables which are not present in df extra_vars \\uf0c1 Non-required variables which are present in df are_present \\uf0c1 Returns True if req_vars are present and False otherwise assert_present ( ) \\uf0c1 Raise an exception of req_vars are absent __init__ ( df : DataFrame | Series , req_vars : set , allow_series : bool = True ) → None \\uf0c1 Connects to an SBML file Parameters : df – A pd.DataFrame or pd.Series req_vars – A set of variables which should exist in df allow_series – Can a pd.Series be provided as df? Return type : None. assert_present ( ) → None \\uf0c1 Raise an error if required variables are missing',\n",
       "    'methods': {'assert_present': {'name': 'assert_present',\n",
       "      'signature': 'assert_present()→None',\n",
       "      'id': 'id0',\n",
       "      'doc': 'Raise an error if required variables are missing'},\n",
       "     '__init__': {'name': '__init__',\n",
       "      'signature': '__init__(df:DataFrame|Series,req_vars:set,allow_series:bool=True)→None',\n",
       "      'id': 'napistu.utils.match_pd_vars.__init__',\n",
       "      'doc': 'Connects to an SBML file Parameters : df – A pd.DataFrame or pd.Series req_vars – A set of variables which should exist in df allow_series – Can a pd.Series be provided as df? Return type : None.'}},\n",
       "    'attributes': {'req_vars': {'name': 'req_vars',\n",
       "      'signature': 'req_vars',\n",
       "      'id': 'napistu.utils.match_pd_vars.req_vars',\n",
       "      'doc': 'A set of variables which should exist in df'},\n",
       "     'missing_vars': {'name': 'missing_vars',\n",
       "      'signature': 'missing_vars',\n",
       "      'id': 'napistu.utils.match_pd_vars.missing_vars',\n",
       "      'doc': 'Required variables which are not present in df'},\n",
       "     'extra_vars': {'name': 'extra_vars',\n",
       "      'signature': 'extra_vars',\n",
       "      'id': 'napistu.utils.match_pd_vars.extra_vars',\n",
       "      'doc': 'Non-required variables which are present in df'},\n",
       "     'are_present': {'name': 'are_present',\n",
       "      'signature': 'are_present',\n",
       "      'id': 'napistu.utils.match_pd_vars.are_present',\n",
       "      'doc': 'Returns True if req_vars are present and False otherwise'}}}},\n",
       "  'submodules': {}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read-the-docs module and function defs\n",
    "rtd_docs = await run_async(read_read_the_docs(package_toc_url = NAPISTU_PY_READTHEDOCS_API))\n",
    "rtd_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using token from environment variable GITHUB_TOKEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.github.com/repos/napistu/napistu.wiki/contents/ \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Client error '404 Not Found' for url 'https://api.github.com/repos/napistu/napistu.wiki/contents/'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# github wiki\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnapistu\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PACKAGE_DEFS\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m wiki_pages = \u001b[38;5;28;01mawait\u001b[39;00m run_async(documentation_utils.list_wiki_pages(repo = PACKAGE_DEFS.GITHUB_PROJECT_REPO))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mrun_async\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_async\u001b[39m(coro):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GITHUB/napistu/tutorials/.venv/lib/python3.11/site-packages/napistu/mcp/documentation_utils.py:44\u001b[39m, in \u001b[36mlist_wiki_pages\u001b[39m\u001b[34m(repo, owner, github_api)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m httpx.AsyncClient(headers=_get_github_headers()) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[32m     43\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m client.get(url)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [item[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m resp.json() \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m].endswith(\u001b[33m\"\u001b[39m\u001b[33m.md\u001b[39m\u001b[33m\"\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GITHUB/napistu/tutorials/.venv/lib/python3.11/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    827\u001b[39m error_type = error_types.get(status_class, \u001b[33m\"\u001b[39m\u001b[33mInvalid status code\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'https://api.github.com/repos/napistu/napistu.wiki/contents/'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404"
     ]
    }
   ],
   "source": [
    "# github wiki\n",
    "\n",
    "from napistu.constants import PACKAGE_DEFS\n",
    "\n",
    "wiki_pages = await run_async(documentation_utils.list_wiki_pages(repo = PACKAGE_DEFS.GITHUB_PROJECT_REPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using token from environment variable GITHUB_TOKEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.github.com/repos/napistu/napistu/issues?state=all \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using token from environment variable GITHUB_TOKEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.github.com/repos/napistu/napistu/pulls?state=all \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# github issues and PRs\n",
    "\n",
    "GITHUB_ISSUES_INDEXED = \"all\"\n",
    "GITHUB_PRS_INDEXED = \"all\"\n",
    "\n",
    "# load issues (already includes the body)\n",
    "issue_list = await run_async(documentation_utils.list_issues(PACKAGE_DEFS.GITHUB_PROJECT_REPO, state = GITHUB_ISSUES_INDEXED))\n",
    "\n",
    "# load PRs\n",
    "prs_list = await run_async(documentation_utils.list_pull_requests(PACKAGE_DEFS.GITHUB_PROJECT_REPO, state = GITHUB_PRS_INDEXED))\n",
    "\n",
    "# there is probably no reason to use this since this info is captured in the lists\n",
    "# prs_list = await run_async(get_issue(PACKAGE_DEFS.GITHUB_PROJECT_REPO, number = 11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorials\n",
    "\n",
    "from napistu.mcp.constants import TUTORIAL_URLS\n",
    "from napistu.mcp.tutorials_utils import get_tutorial_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adding_data_to_graphs': '---\\ntitle: Tutorial - Adding Data to Graphs\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\nThis notebook describes how we can add species- or reaction-level data to pathway representation (`SBML_dfs`), and also how we can propagate these attributes to the vertices and edges in a `cpr_graph`.\\n\\n## Adding data to pathways\\n\\nSpecies- and reaction-level data is associated with the `species_data` or `reactions_data` attribute of an `SBML_dfs` object. Each of these fields can include multiple sources of entity data organized as a dictionary where keys are an information source label, and values are a `pd.DataFrame`. Each DataFrame is indexed by species or reaction ids (s_ids and _r_ids) corresponding to the indecies of the `species` and `reactions` tables.\\n\\nThe main approaches for this are either:\\n1. Adding information during network creation. This is generally how reaction-centric information such as the STRING weights will be passed. \\n2. Directly add species or reaction data joining data based on systematic identifiers stored in `s_Identifiers` or `r_Identifiers` attributes.\\n\\n## Passing information to graphs\\n\\nTo apply network-based methods we generally want to map results onto either vertex or edge attributes. For edges this can involve passing information which can be used for weighting connections (to favor certain sources or weight based on quantitative evidence scores.) For vertices, adding attributes supports either visualization or inference approaches such as network propagation.\\n\\nWe propagate this information by using an `entity_weights` dictionary which specifies both the values we should pluck out of entity data table (as a dictionary key plus a pd.DataFrame column) but also how we can combine these values. This would allow us to combine species_data which may be from different sets of biomolecules (such as proteomics and metabolomics), or to weight edges derived from multiple sources which may be weighted in different ways (or possess no evidence scores at all).\\n\\n# Demos\\n\\n## Adding Data to Pathways\\n\\n### During construction\\n\\nYou can create `SBML_dfs` objects in multiple ways:\\n1. translating results from an .sbml file\\n2. direct creation from a list of component pd.DataFrames (species, compartmentalized_species, compartments, reactions, and reaction_species)\\n3. using the edgelist format to specify pairwise relationships with minimal annotations\\n\\nOf these, the edgelist format supports directly passing edge attributes into `reactions_data`. Basically, when defining edges all of the columns which are not required variables will be added to reactions_data.\\n\\nSome example functions which pass attributes during creation are yeast.convert_idea_kinetics_to_sbml_dfs() and string.convert_string_to_sbml_dfs(). As a quick demo:\\n\\n---\\n\\n```python\\nimport logging\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nimport tutorial_utils\\nconfig = tutorial_utils.CprConfig(\"config.yaml\", \"downloading_pathway_data\")\\n```\\n\\n---\\n\\n```python\\nimport pandas as pd\\n\\nfrom napistu import sbml_dfs_core\\nfrom napistu import source\\nfrom napistu import identifiers\\nfrom napistu import utils\\n\\n# setup compartments (just treat this as uncompartmentalized for now)\\ncompartments_df = sbml_dfs_core._stub_compartments()\\n\\n# Per convention unaggregated models receive an empty source\\ninteraction_source = source.Source(init=True)\\n```\\n\\n---\\n\\n```python\\ndef _get_example_edgelist_inputs():\\n    interaction_edgelist = pd.DataFrame(\\n        [\\n            {\\n                \"upstream_name\": \"A\",\\n                \"downstream_name\": \"B\",\\n                \"upstream_compartment\": \"cellular_component\",\\n                \"downstream_compartment\": \"cellular_component\",\\n                \"r_name\": \"A -> B\",\\n                \"sbo_term\": \"SBO:0000020\",\\n                \"r_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ncbi.nlm.nih.gov/pubmed/10604467\",\\n                            \"BQB_IS_DESCRIBED_BY\",\\n                        )\\n                    ]\\n                ),\\n                \"r_isreversible\": False,\\n                \"rxn_attr_1\": \"foo\",\\n                \"rxn_attr_2\": 1,\\n            },\\n            {\\n                \"upstream_name\": \"A\",\\n                \"downstream_name\": \"C\",\\n                \"upstream_compartment\": \"cellular_component\",\\n                \"downstream_compartment\": \"cellular_component\",\\n                \"r_name\": \"A -> C\",\\n                \"sbo_term\": \"SBO:0000459\",\\n                \"r_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ncbi.nlm.nih.gov/pubmed/10604467\",\\n                            \"BQB_IS_DESCRIBED_BY\",\\n                        )\\n                    ]\\n                ),\\n                \"r_isreversible\": False,\\n                \"rxn_attr_1\": \"bar\",\\n                \"rxn_attr_2\": 2,\\n            },\\n        ],\\n        index=[0, 1],\\n    )\\n\\n    species_df = pd.DataFrame(\\n        [\\n            {\\n                \"s_name\": \"A\",\\n                \"s_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ensembl.org/Homo_sapiens/geneview?gene=ENSG00000153094\",\\n                            \"BQB_IS\",\\n                        )\\n                    ]\\n                ),\\n                \"spec_attr\": 2,\\n            },\\n            {\\n                \"s_name\": \"B\",\\n                \"s_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"https://purl.uniprot.org/uniprot/Q557I5\", \"BQB_IS\"\\n                        )\\n                    ]\\n                ),\\n                \"spec_attr\": 5,\\n            },\\n            {\\n                \"s_name\": \"C\",\\n                \"s_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ebi.ac.uk/chebi/searchId.do?chebiId=CHEBI:37136\",\\n                            \"BQB_IS\",\\n                        )\\n                    ]\\n                ),\\n                \"spec_attr\": 1,\\n            },\\n        ],\\n        index=[0, 1, 2],\\n    )\\n\\n    compartments_df = sbml_dfs_core._stub_compartments()\\n\\n    interaction_source = source.Source(init=True)\\n\\n    return (interaction_edgelist, species_df, compartments_df, interaction_source)\\n\\n\\n(\\n    interaction_edgelist,\\n    species_df,\\n    compartments_df,\\n    interaction_source,\\n) = _get_example_edgelist_inputs()\\n\\nsbml_dfs = sbml_dfs_core.sbml_dfs_from_edgelist(\\n    interaction_edgelist,\\n    species_df,\\n    compartments_df,\\n    interaction_source,\\n    keep_species_data=\"data\",\\n    keep_reactions_data=\"data\",\\n)\\n```\\n\\n---\\n\\n#### Mounted species data \\n\\n---\\n\\n```python\\nutils.style_df(sbml_dfs.reactions_data[\"data\"])\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c4ba10>\\n```\\n\\n---\\n\\n#### Mounted reaction data\\n\\n---\\n\\n```python\\nutils.style_df(sbml_dfs.species_data[\"data\"])\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c34b10>\\n```\\n\\n---\\n\\n## Adding entity data to an existing `SBML_dfs` object\\n\\nTo add reaction- or species-level data to an existing `SBML_dfs` object we can create an appropriate pd.DataFrame and directly add it to the object. As with all `species_data` or `reactions_data` entries this table must be indexed by the models species or reaction ids. Because of this, the challenge in merging results determining which species in our model match entries in the to-be-added entity data. To provide some guidance on this we will consider a couple of cases: matching by names, and matching by standard identifiers.\\n\\n### Matching by names\\n\\nMatching by names or symbols is generally not a good idea because there is a many-to-many relationship between many genes and symbols. Still, lots of people do use symbols, and this is a simple case which shows how easy it is to add entity data once we\\'ve matched it to existing pathway species or reactions.\\n\\n\\n---\\n\\n```python\\nnew_species_data = sbml_dfs.species[0:2].assign(new_data=2)[[\"new_data\"]]\\n\\nnew_reactions_data = pd.DataFrame(\\n    [\\n        {\"r_id\": sbml_dfs.reactions.index[0], \"new_data\": 2},\\n        {\"r_id\": sbml_dfs.reactions.index[1], \"new_data\": 3},\\n    ]\\n).set_index(\"r_id\")\\n\\nsbml_dfs.add_species_data(\"new_data\", new_species_data)\\nsbml_dfs.add_reactions_data(\"new_data\", new_reactions_data)\\n\\nutils.style_df(sbml_dfs.species_data[\"new_data\"])\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c26bd0>\\n```\\n\\n---\\n\\n### Matching by identifiers\\n\\nGenerally we will be trying to add molecular data to a network which is associated with one or more systematic ontologies. A nice way to do this is using `mechanism_matching.features_to_pathway_species()`. This function will compare a table containing all species or reactions identifiers in the pathway model to a set of query features to create a lookup table of query identifiers to pathway ids.\\n\\n---\\n\\n```python\\nfrom napistu import mechanism_matching\\n\\n# export identifiers from pathway\\nspecies_identifiers = sbml_dfs.get_identifiers(\"species\")\\n\\nfeature_annotations = pd.DataFrame(\\n    [\\n        {\"identifier\": \"ENSG00000153094\", \"expression\": 1000},\\n        {\"identifier\": \"ENSG0000000000\", \"expression\": 50},\\n    ],\\n    index=[0, 1],\\n)\\n\\nupdated_species_data = mechanism_matching.features_to_pathway_species(\\n    feature_annotations,\\n    species_identifiers,\\n    ontologies={\"ensembl_gene\"},\\n    feature_id_var=\"identifier\",\\n)[[\"s_id\", \"expression\"]].set_index(\"s_id\")\\n\\nsbml_dfs.add_species_data(\"newest_data\", updated_species_data)\\n```\\n\\n---\\n\\n#### Mounted species data\\n\\n---\\n\\n```python\\nsbml_dfs.species_data\\n```\\n\\nOutput:\\n```\\n{\\'data\\':            spec_attr\\n s_id                \\n S00000000          2\\n S00000001          5\\n S00000002          1,\\n \\'new_data\\':            new_data\\n s_id               \\n S00000000         2\\n S00000001         2,\\n \\'newest_data\\':            expression\\n s_id                 \\n S00000000        1000}\\n```\\n\\n---\\n\\n#### Mounted reaction data\\n\\n---\\n\\n```python\\nsbml_dfs.reactions_data\\n```\\n\\nOutput:\\n```\\n{\\'data\\':           rxn_attr_1  rxn_attr_2\\n r_id                            \\n R00000000        foo           1\\n R00000001        bar           2,\\n \\'new_data\\':            new_data\\n r_id               \\n R00000000         2\\n R00000001         3}\\n```\\n\\n---\\n\\n## Passing Information to Graphs \\n\\nNow that we have our data of interest tied to the appropriate species and reactions in our pathway we can carry this information forward as we translate the pathway representation into a graph of vertices connected by edges.\\n\\nThis process is controlled by the settings in the `reaction_graph_attrs` dictionary which specifies the variables which should pulled out of `species_data` or `reactions_data` and can also be used to specify how the graph should be weighted. A real-world example of this can be found in [calcification_causality.ipynb](https://github.com/calico/discovery/blob/main/projects/calcification/calcification_causality/calcification_causality.ipynb).\\n\\n\\n---\\n\\n```python\\nfrom napistu.network import net_create\\n\\nreaction_graph_attrs = {\\n    \"reactions\": {\\n        \"reaction_wts\": {\"table\": \"data\", \"variable\": \"rxn_attr_1\", \"trans\": \"identity\"}\\n    },\\n    \"species\": {\\n        \"species_var1\": {\\n            \"table\": \"data\",\\n            \"variable\": \"spec_attr\",\\n            \"trans\": \"string_inv\",\\n        },\\n        \"species_var2\": {\\n            \"table\": \"newest_data\",\\n            \"variable\": \"expression\",\\n            \"trans\": \"identity\",\\n        },\\n    },\\n}\\n\\ngraph_w_annotations = net_create.create_cpr_graph(\\n    sbml_dfs,\\n    reaction_graph_attrs,\\n    directed=True,\\n    graph_type=\"regulatory\"\\n)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.network.net_create:Organizing all network nodes (compartmentalized species and reactions)\\nINFO:napistu.network.net_create:Formatting edges as a regulatory graph\\nINFO:napistu.network.net_create:Formatting 4 reactions species as tiered edges.\\nINFO:napistu.network.net_create:Adding additional attributes to edges, e.g., # of children and parents.\\nINFO:napistu.network.net_create:Done preparing regulatory graph\\nINFO:napistu.network.net_create:Adding reversibility and other meta-data from reactions_data\\nINFO:napistu.network.net_create:Creating reverse reactions for reversible reactions on a directed graph\\nINFO:napistu.network.net_create:Formatting cpr_graph output\\n\\n```\\n\\n---\\n\\n### Graph vertices (with data)\\n\\n---\\n\\n```python\\nutils.style_df(graph_w_annotations.get_vertex_dataframe())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173d59810>\\n```\\n\\n---\\n\\n### Graph edges (with data)\\n\\n---\\n\\n```python\\nutils.style_df(graph_w_annotations.get_edge_dataframe())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c48210>\\n```\\n\\n---\\n',\n",
       " 'downloading_pathway_data': '---\\ntitle: Tutorial - Downloading and Formatting Pathway Data\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\nThis notebook provides examples for downloading pathway information from a variety of data sources and formatting the results as `sbml_dfs` objects. Since it is often not possible to download just a subset of a data source for demonstration purposes, this notebook will download and cache raw and intermediate representations of each data source.\\n\\n---\\n\\n```python\\n#| label: config\\nimport logging\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nimport tutorial_utils\\nconfig = tutorial_utils.CprConfig(\"config.yaml\", \"downloading_pathway_data\")\\n```\\n\\n---\\n\\n```python\\n#| label: environment\\nimport os\\nimport pickle\\n\\nfrom napistu import utils\\nfrom napistu.ingestion import bigg\\nfrom napistu.ingestion import psi_mi\\nfrom napistu.ingestion import reactome\\nfrom napistu.ingestion import string\\nfrom napistu.ingestion import trrust\\n\\ndef _log(text: str):\\n\\n    banner_str = \"====================================\\\\n\"\\n    logger.info(f\"\\\\n{banner_str}{text}\\\\n{banner_str}\")\\n\\ndef _log_skipped(uri: str):\\n    \"\"\" Log that a step was skipped. \"\"\"\\n    logger.info(f\"{uri} exists or overwrite = False\")\\n```\\n\\nOutput:\\n```\\nINFO:rpy2.situation:cffi mode is CFFI_MODE.ANY\\nDEBUG:rpy2.situation:Looking for R home with: R RHOME\\nINFO:rpy2.situation:R home found: /Library/Frameworks/R.framework/Resources\\nDEBUG:rpy2.situation:Looking for LD_LIBRARY_PATH with: /Library/Frameworks/R.framework/Resources/bin/Rscript -e cat(Sys.getenv(\"LD_LIBRARY_PATH\"))\\nINFO:rpy2.situation:R library path: :/opt/homebrew/lib\\nINFO:rpy2.situation:LD_LIBRARY_PATH: :/opt/homebrew/lib\\nDEBUG:rpy2.rinterface_lib.ffi_proxy:cffi mode is InterfaceType.API\\nINFO:rpy2.rinterface_lib.embedded:Default options to initialize R: rpy2, --quiet, --no-save\\nDEBUG:rpy2.rinterface_lib.embedded:Calling R setup_Rmainloop.\\nDEBUG:rpy2.rinterface_lib.embedded:Setting functions for R callbacks.\\nINFO:rpy2.rinterface_lib.embedded:R is already initialized. No need to initialize.\\n\\n```\\n\\n---\\n\\n```python\\n#| label: globals\\nOVERWRITE = config.overwrite\\nSPECIES = config.species\\nFN_BIGG_SBML_DIR = config.artifacts[\"bigg_sbml_dir\"]\\nFN_BIGG_SBML_DFS = config.artifacts[\"bigg_sbml_dfs\"]\\nFN_INTACT_DIR = config.artifacts[\"intact_dir\"]\\nFN_INTACT_SBML_DFS = config.artifacts[\"intact_sbml_dfs\"]\\nFN_REACTOME_SBML_DIR = config.artifacts[\"reactome_sbml_dir\"]\\nFN_REACTOME_SBML_DFS = config.artifacts[\"reactome_sbml_dfs\"]\\nFN_STRING_ALIASES = config.artifacts[\"string_aliases\"]\\nFN_STRING_INTERACTIONS = config.artifacts[\"string_interactions\"]\\nFN_STRING_SBML_DFS = config.artifacts[\"string_sbml_dfs\"]\\nFN_TRRUST_RAW = config.artifacts[\"trrust_raw\"]\\nFN_TRRUST_SBML_DFS = config.artifacts[\"trrust_sbml_dfs\"]\\n```\\n\\n---\\n\\n# Species Agnostic Sources\\n\\nThese sources include pathway information which can be broadly applied to a range of species. \\n\\n## STRING\\n\\n---\\n\\n```python\\n#| label: string\\n\\nif not utils.path_exists(FN_STRING_INTERACTIONS) or OVERWRITE:\\n    _log(f\"Downloading STRING interactions to {FN_STRING_INTERACTIONS}\")\\n    string.download_string(FN_STRING_INTERACTIONS, species = SPECIES)\\nelse:\\n    _log_skipped(FN_STRING_INTERACTIONS)\\n\\nif not utils.path_exists(FN_STRING_ALIASES) or OVERWRITE:\\n    _log(f\"Downloading STRING aliases (systematic identifiers) to {FN_STRING_ALIASES}\")\\n    string.download_string_aliases(FN_STRING_ALIASES, species = SPECIES)\\nelse:\\n    _log_skipped(FN_STRING_ALIASES)\\n\\nif not utils.path_exists(FN_STRING_SBML_DFS) or OVERWRITE:\\n    _log(f\"Combining interactions and aliases to create the STRING sbml_dfs at {FN_STRING_SBML_DFS}\")\\n\\n    sbml_dfs = string.convert_string_to_sbml_dfs(\\n        FN_STRING_INTERACTIONS,\\n        FN_STRING_ALIASES\\n    )\\n    sbml_dfs.validate()\\n\\n    utils.save_pickle(FN_STRING_SBML_DFS, sbml_dfs)\\n\\nelse:\\n    _log_skipped(FN_STRING_SBML_DFS)\\n```\\n\\nOutput:\\n```\\nINFO:root:napistu_data/string_interactions.txt exists or overwrite = False\\nINFO:root:napistu_data/string_aliases.txt exists or overwrite = False\\nINFO:root:napistu_data/string_sbml_dfs.pickle exists or overwrite = False\\n\\n```\\n\\n---\\n\\n# Species-Biased Sources\\n\\nThese sources inform multiple species but their focal point is a single species. Here which has additional types of data \\n\\n## Reactome\\n\\n---\\n\\n```python\\n#| label: reactome\\n\\nif not os.path.isdir(FN_REACTOME_SBML_DIR) or OVERWRITE:\\n    _log(f\"Download the Reactome pan-species tar-ball and unpack to a directory of .sbml files at {FN_REACTOME_SBML_DIR}\")\\n    reactome.reactome_sbml_download(FN_REACTOME_SBML_DIR, overwrite=OVERWRITE)\\nelse:\\n    _log_skipped(FN_REACTOME_SBML_DIR)\\n\\nif not utils.path_exists(FN_REACTOME_SBML_DFS) or OVERWRITE:\\n    _log(f\"Merging Reactome .sbml files into an sbml_dfs model at {FN_REACTOME_SBML_DFS}\")\\n\\n    pw_index_uri = os.path.join(FN_REACTOME_SBML_DIR, \"pw_index.tsv\")\\n    sbml_dfs = reactome.construct_reactome_consensus(\\n        pw_index_uri, species=SPECIES, strict=False\\n    )\\n    sbml_dfs.validate()\\n\\n    utils.save_pickle(FN_REACTOME_SBML_DFS, sbml_dfs)\\nelse:\\n    _log_skipped(FN_REACTOME_SBML_DFS)\\n```\\n\\nOutput:\\n```\\nINFO:root:napistu_data/reactome_sbmls exists or overwrite = False\\nINFO:root:napistu_data/reactome_sbml_dfs.pickle exists or overwrite = False\\n\\n```\\n\\n---\\n\\n## BiGG (metabolic models)\\n\\n---\\n\\n```python\\n#| label: bigg\\n\\nif not os.path.isdir(FN_BIGG_SBML_DIR) or OVERWRITE:\\n    _log(f\"Download multiple BiGG metabolic models to {FN_BIGG_SBML_DIR}\")\\n    bigg.bigg_sbml_download(FN_BIGG_SBML_DIR, overwrite = OVERWRITE)\\nelse:\\n    _log_skipped(FN_BIGG_SBML_DIR)\\n\\nif not utils.path_exists(FN_BIGG_SBML_DFS) or OVERWRITE:\\n    _log(f\"Formatting a BiGG .sbml model as a sbml_dfs model at {FN_BIGG_SBML_DFS}\")\\n\\n    pw_index_uri = os.path.join(FN_BIGG_SBML_DIR, \"pw_index.tsv\")\\n    sbml_dfs = bigg.construct_bigg_consensus(pw_index_uri, species=SPECIES)\\n    sbml_dfs.validate()\\n\\n    utils.save_pickle(FN_BIGG_SBML_DFS, sbml_dfs)\\nelse:\\n    _log_skipped(FN_BIGG_SBML_DFS)\\n```\\n\\nOutput:\\n```\\nINFO:root:napistu_data/bigg_sbmls exists or overwrite = False\\nINFO:root:\\n====================================\\nFormatting a BiGG .sbml model as a sbml_dfs model at napistu_data/bigg_sbml_dfs.pickle\\n====================================\\n\\n  0%|          | 0/1 [00:00<?, ?it/s]INFO:napistu.consensus:processing recon3D\\nWARNING:napistu.ingestion.sbml:Compartment c has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment l has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment m has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment r has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment e has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment x has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment n has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment g has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.ingestion.sbml:Compartment i has empty CVterms, mapping its c_Identifiers from the Compartment dict\\nWARNING:napistu.consensus:19 entries didn\\'t possess identifiers and thus cannot be merged\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\nDEBUG:napistu.utils:label is not defined in table_schema; adding a constant (1)\\nWARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\\nWARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\\nWARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\\nWARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\\nWARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\\nWARNING:napistu.ingestion.sbml:gene annotations nested deeper than 4 levels, ignoring\\nWARNING:napistu.sbml_dfs_core:compartmentalized_species included missing c_id values\\nWARNING:napistu.sbml_dfs_core:Attempting to resolve with infer_uncompartmentalized_species_location()\\nINFO:napistu.sbml_dfs_core:2213 species\\' compartmentalization inferred\\nWARNING:napistu.sbml_dfs_core:35 species compartmentalization could not be inferred from other reaction particpants. Their compartmentalization will be set to the default of c\\nWARNING:napistu.sbml_dfs_core:1 sbo_terms were not defined  (N=54877)\\nWARNING:napistu.sbml_dfs_core:Attempting to resolve with infer_sbo_terms()\\nINFO:napistu.sbml_dfs_core:Updating 54877 reaction_species\\' sbo_term\\n100%|██████████| 1/1 [00:11<00:00, 11.25s/it]\\nINFO:napistu.sbml_dfs_core:All compartmentalized species have compartments, returning input sbml_dfs\\n\\n```\\n\\n---\\n\\n# Species-Specific Sources\\n\\n## TRRUST\\n\\n---\\n\\n```python\\n#| label: trrust \\n\\nif not utils.path_exists(FN_TRRUST_RAW) or OVERWRITE:\\n    _log(f\"Downloading TRRUST to {FN_TRRUST_RAW}\")\\n    trrust.download_trrust(FN_TRRUST_RAW)\\nelse:\\n    _log_skipped(FN_TRRUST_RAW)\\n\\nif not utils.path_exists(FN_TRRUST_SBML_DFS) or OVERWRITE:\\n    _log(f\"Processing TRRUST as sbml_dfs at {FN_TRRUST_SBML_DFS}\")\\n    sbml_dfs = trrust.convert_trrust_to_sbml_dfs(FN_TRRUST_RAW)\\n    sbml_dfs.validate()\\n\\n    utils.save_pickle(FN_TRRUST_SBML_DFS, sbml_dfs)\\nelse:\\n    _log_skipped(FN_TRRUST_SBML_DFS)\\n```\\n\\nOutput:\\n```\\nINFO:root:napistu_data/trrust.csv exists or overwrite = False\\nINFO:root:\\n====================================\\nProcessing TRRUST as sbml_dfs at napistu_data/trrust_sbml_dfs.pickle\\n====================================\\n\\n\\n```\\n```\\n1724219e is not a valid pubmed id, it did not match the regex: ^[0-9]+$ returning None\\n\\n```\\n\\n---\\n\\n## IDEA\\n\\n---\\n',\n",
       " 'formatting_sbml_dfs_as_cpr_graphs': '---\\ntitle: Tutorial - Formatting an sbml_dfs as a cpr_graph\"\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\n`sbml_dfs` objects are stand-alone representations of pathways but they need to be formatted as a `cpr_graph` object if we want to use them as a network. Doing this will allow us to translate a range of biological questions into network operations - see **suggesting_mechanisms_with_networks.qmd**.\\n\\nHere, we will go through the process of translating pathways into graphs and how to precompute distances between molecular species (to speed up search). Its at this stage that we can also add high-dimensional data to our graph but that is discussed as a separate vignette - **adding_data_to_graphs.qmd**.\\n\\n---\\n\\n```python\\n#| label: config\\n\\nimport logging\\n\\nimport seaborn as sns\\n\\nfrom napistu import utils \\nfrom napistu.network import net_create\\nfrom napistu.network import precompute\\n\\nimport tutorial_utils\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nconfig = tutorial_utils.NapistuConfig(\"config.yaml\", \"formatting_sbml_dfs_as_cpr_graphs\")\\n```\\n\\n---\\n\\n## Load an `sbml_dfs` pathway representation\\n\\nA `sbml_dfs`, further described in the `understanding_sbml_dfs.qmd` vignette, is a stand-alone representation of a pathway. Here, we load a pickled `sbml_dfs` object that we will use to create a `cpr_graph`. The model here was created from a few metabolic pathways from Reactome merged into a consensus model.\\n\\n---\\n\\n```python\\n#| label: load_data\\n\\nsbml_dfs_path = config.load_asset(\"test_pathway\", \"sbml_dfs\")\\nsbml_dfs = utils.load_pickle(sbml_dfs_path)\\n```\\n\\n---\\n\\n## Create a Network\\n\\nCPR\\'s strategy for translating an `sbml_dfs` object into a graph is thoroughly described in the  [CPR Wiki - CPR Graphs](https://github.com/calico/Open-CPR/wiki/CPR-Graphs). Briefly, we can create a graph using a single function `process_cpr_graph` which creates and weights the network or we can divide these calls up by `igraph_network` and `add_graph_weights`.\\n\\nHere, we will create a network using the `regulatory` graph specification which places an appropriate hierarchy over molecules participating in the same reaction so for instance an enzyme will be upstream of its substrate (since the enzyme regulates the substrate not the other way around). We\\'ll also create a directed graph since the `sbml_dfs` pertains to a metabolic pathway where directionality can be appropriately inferred from reaction stoichiometry.\\n\\n---\\n\\n```python\\n#| label: sbml_dfs_to_cpr\\ncpr_graph = net_create.process_cpr_graph(\\n  sbml_dfs,\\n  graph_type = \"regulatory\",\\n  directed = True\\n)\\n```\\n\\nOutput:\\n```\\nINFO:root:Constructing network\\nINFO:napistu.network.net_create:Organizing all network nodes (compartmentalized species and reactions)\\nINFO:napistu.network.net_create:Formatting edges as a regulatory graph\\nINFO:napistu.network.net_create:Formatting 339 reactions species as tiered edges.\\nINFO:napistu.network.net_create:Adding additional attributes to edges, e.g., # of children and parents.\\nINFO:napistu.network.net_create:Done preparing regulatory graph\\nINFO:napistu.network.net_create:Adding reversibility and other meta-data from reactions_data\\nINFO:napistu.network.net_create:No reactions annotations provided in \"graph_attrs\"; returning None\\nINFO:napistu.network.net_create:Creating reverse reactions for reversible reactions on a directed graph\\nWARNING:napistu.network.net_create:2 edges were dropped due to duplicated origin -> target relationiships, use verbose for more information\\nINFO:napistu.network.net_create:Formatting cpr_graph output\\nINFO:root:Adding edge weights with an unweighted strategy\\n\\n```\\n\\n---\\n\\n## Inspecting the Network\\n\\nThe `cpr_graph` is really just an `igraph` `Graph` object with some specific vertex and edge attributes. Let\\'s take a look at the vertices and edges. To make this easier we\\'ll do this in a tabular format.\\n\\n---\\n\\n```python\\n#| label: graph_to_dfs\\n\\nfrom napistu.network import net_utils\\nvertices, edges = net_utils.cpr_graph_to_pandas_dfs(cpr_graph)\\n```\\n\\n---\\n\\n### Vertices: Genes, Metabolites, Reactions, ...\\n\\n---\\n\\n```python\\n#| label: vertices\\nutils.style_df(vertices.head())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x17c63d550>\\n```\\n\\n---\\n\\n### Edges: Linking Pairs of Vertices\\n\\n---\\n\\n```python\\n#| label: edges\\nutils.style_df(vertices.head())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x17c5e66d0>\\n```\\n\\n---\\n\\n### Network Visualization\\n\\nThe network visualization methods in CPR are better built-out on the R side. But for quick-and-dirty network visualization we can use the standard igraph visualization functions and some plotting wrappers within CPR.\\n\\n---\\n\\n```python\\nfrom napistu.network import neighborhoods\\n\\nneighborhoods.plot_neighborhood(\\n    net_utils.filter_to_largest_subgraph(cpr_graph),\\n    name_nodes = True,\\n    plot_size = 2000,\\n    network_layout = \"kk\" \\n)\\n```\\n\\nOutput:\\n```\\nWARNING:napistu.network.neighborhoods:net_polarity was not defined as an edge attribute so edges will not be colored\\n\\n```\\n```\\n<igraph.drawing.cairo.plot.CairoPlot at 0x17c63d5d0>\\n```\\n\\n---\\n\\n## Precompute Distances\\n\\nSome network operations can be sped up by precomputing distances between nodes. This is particularly useful for shortest path algorithms. Here we precompute the shortest path distances and weighted shortest paths (if weights are present) between all pairs of nodes in the graph.\\n\\n---\\n\\n```python\\n#| label: precomputed_distances\\ndistances = precompute.precompute_distances(cpr_graph)\\n\\nutils.style_df(distances.head(5))\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x3043063d0>\\n```\\n\\n---\\n\\nAs a quick look into this output we can create a table of the # of steps to progress from source to destination vertices.\\n\\n---\\n\\n```python\\n#| label: plot_precomputed_distance\\n\\ndf = distances.pivot(index=\\'sc_id_origin\\', columns=\\'sc_id_dest\\', values=\\'path_length\\')\\nsns.heatmap(df, annot=False)\\n```\\n\\nOutput:\\n```\\n<Axes: xlabel=\\'sc_id_dest\\', ylabel=\\'sc_id_origin\\'>\\n```\\n```\\n<Figure size 640x480 with 2 Axes>\\n```\\n\\n---\\n',\n",
       " 'merging_models_into_a_consensus': '---\\ntitle: \"Tutorial - Merging Networks into a Consensus\"\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\nThis notebook will show you how to use the `consensus` module to merge multiple pathway models into a single consensus. A description of the logic and algorithms underpinning the consensus model can be found in the [CPR Wiki](https://github.com/calico/Open-CPR/wiki/Consensus).\\n\\nFirst, we\\'ll merge a few different Reactome .sbml files into a consensus which are conveniently located the CPR packages test data.\\n\\n---\\n\\n```python\\n#| label: config\\nimport logging\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nimport tutorial_utils\\nconfig = tutorial_utils.NapistuConfig(\"config.yaml\", \"merging_models_into_a_consensus\")\\n\\ntest_data = tutorial_utils.locate_test_data()\\n```\\n\\n---\\n\\n```python\\nimport os\\n\\nfrom napistu import consensus\\nfrom napistu import indices\\n```\\n\\n---\\n\\n```python\\npw_index = indices.PWIndex(os.path.join(test_data, \"pw_index.tsv\"))\\nsbml_dfs_dict = consensus.construct_sbml_dfs_dict(pw_index)\\n\\nconsensus_model = consensus.construct_consensus_model(sbml_dfs_dict, pw_index)\\n```\\n\\nOutput:\\n```\\n  0%|          | 0/5 [00:00<?, ?it/s]INFO:napistu.consensus:processing Erythrocytes take up carbon dioxide and release oxygen\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\nINFO:napistu.consensus:processing Bicarbonate transporters\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\nINFO:napistu.consensus:processing Erythrocytes take up oxygen and release carbon dioxide\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\n 60%|██████    | 3/5 [00:00<00:00, 25.74it/s]INFO:napistu.consensus:processing Reversible hydration of carbon dioxide\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\nINFO:napistu.consensus:processing Aryl hydrocarbon receptor signalling\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\n100%|██████████| 5/5 [00:00<00:00, 28.70it/s]\\nINFO:napistu.consensus:Reporting possible issues in component models\\nINFO:napistu.sbml_dfs_utils:Running in dogmatic mode - differences genes, transcripts, and proteins will try to be maintained as separate species.\\nINFO:napistu.consensus:Defining compartments based on unique ids\\nINFO:napistu.utils:creating an edgelist linking index levels model, c_id, entry and linking it to levels defined by ontology, identifier\\nINFO:napistu.consensus:Creating source table\\nINFO:napistu.consensus:Aggregating old sources\\nINFO:napistu.consensus:Returning new source table\\nINFO:napistu.consensus:>>>> 13 c_id entries merged into 3\\nINFO:napistu.consensus:Testing for identical formulas of to-be-merged reactions\\nINFO:napistu.consensus:All merges names matched exactly\\nINFO:napistu.consensus:==============================\\n\\nINFO:napistu.consensus:Defining species based on unique ids\\nINFO:napistu.utils:creating an edgelist linking index levels model, s_id, entry and linking it to levels defined by ontology, identifier\\nINFO:napistu.consensus:Creating source table\\nINFO:napistu.consensus:Aggregating old sources\\nINFO:napistu.consensus:Returning new source table\\nINFO:napistu.consensus:>>>> 33 s_id entries merged into 13\\nINFO:napistu.consensus:Testing for identical formulas of to-be-merged reactions\\nINFO:napistu.consensus:All merges names matched exactly\\nINFO:napistu.consensus:==============================\\n\\nINFO:napistu.consensus:Defining compartmentalized species based on unique species x compartments\\nINFO:napistu.consensus:>>>> 50 sc_id entries merged into 18\\nINFO:napistu.consensus:Testing for identical formulas of to-be-merged reactions\\nINFO:napistu.consensus:All merges names matched exactly\\nINFO:napistu.consensus:==============================\\n\\nINFO:napistu.consensus:Creating source table\\nINFO:napistu.consensus:Aggregating old sources\\nINFO:napistu.consensus:Returning new source table\\nINFO:napistu.consensus:Define reactions based on membership of identical compartmentalized species\\nINFO:napistu.consensus:Merging reactions based on identical membership (sc_id + stoichiometry)\\nWARNING:napistu.consensus:No merging occurred for r_id\\nINFO:napistu.consensus:Merging reactions identifiers\\nINFO:napistu.consensus:Merging reactions sources\\nINFO:napistu.consensus:Creating source table\\nINFO:napistu.consensus:Aggregating old sources\\nINFO:napistu.consensus:Returning new source table\\nINFO:napistu.consensus:Annotating reversibility based on merged reactions\\nINFO:napistu.consensus:Define reaction species based on reactions\\nWARNING:napistu.consensus:No merging occurred for rsc_id\\n\\n```\\n\\n---\\n',\n",
       " 'r_based_network_visualization': '---\\ntitle: \"Tutorial - R-Based Network Visualization\"\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\nCalico Pathway Resources is primarily a Python framework but it does have some R functions for network visualization and lending some interactivity to network exploration.\\n\\n---\\n',\n",
       " 'suggesting_mechanisms_with_networks': '---\\ntitle: \"Tutorial - Suggesting mechanisms with networks\"\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\nOne of the primary goals of CPR is providing network-based answers to biological questions such as:\\n- how are species *X* and *Y* connected?\\n- what are the regulators of *X* and what are its downstream targets?\\n- what are common patterns shared among a set of species: {*X*, *Y*, *Z*, ...}?\\n\\n---\\n\\n```python\\n#| label: config\\nimport logging\\n\\nimport tutorial_utils\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nconfig = tutorial_utils.NapistuConfig(\"config.yaml\", \"suggesting_mechanisms_with_networks\")\\nsbml_dfs_path = config.load_asset(\"test_pathway\", \"sbml_dfs\")\\nsbml_dfs_path = config.load_asset(\"test_pathway\", \"regulatory_graph\")\\n```\\n\\n---\\n\\n```python\\n#| label: env\\nimport pandas as pd\\n\\nfrom napistu import sbml_dfs_core\\nfrom napistu import mechanism_matching\\nfrom napistu import utils\\n\\nfrom napistu.network import net_create\\nfrom napistu.network import paths\\nfrom napistu.network import neighborhoods\\nfrom napistu.network import net_utils\\n\\nsbml_dfs = utils.load_pickle(config.artifacts[\"sbml_dfs\"])\\ncpr_graph = utils.load_pickle(config.artifacts[\"cpr_graph\"])\\n```\\n\\n---\\n\\nFor this tutorial we will work with the \"test pathway\" which is bundled with Open CPR. This is small metabolic model covering human central carbon metabolism. \\n\\n## Overview of `cpr_graph`\\n\\nBefore we start exploring the metabolic model as a graph, we can first visualize its overall structure. \\n\\nDoing this we\\'ll create a version of the network using the `surrogate` layout. The key feature of this layout is that it places enzymes downstream of their substrates. This doesn\\'t make sense from a regulatory perspective (the substrate is modified by the enzyme not the other way around), but it does make sense for descriptive visualization of networks. \\n\\n---\\n\\n```python\\n#| label: create_and_visualize_surrogate_graph\\n# create the surrogate graph\\ncpr_graph_surrogate = net_create.create_cpr_graph(sbml_dfs, graph_type = \"surrogate\")\\n\\n# network visualization\\nneighborhoods.plot_neighborhood(\\n    net_utils.filter_to_largest_subgraph(cpr_graph_surrogate),\\n    name_nodes = True,\\n    plot_size = 2000,\\n    network_layout = \"kk\" \\n)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.network.net_create:Organizing all network nodes (compartmentalized species and reactions)\\nINFO:napistu.network.net_create:Formatting edges as a surrogate graph\\nINFO:napistu.network.net_create:Formatting 339 reactions species as tiered edges.\\nINFO:napistu.network.net_create:Adding additional attributes to edges, e.g., # of children and parents.\\nINFO:napistu.network.net_create:Done preparing surrogate graph\\nINFO:napistu.network.net_create:Adding reversibility and other meta-data from reactions_data\\nINFO:napistu.network.net_create:No reactions annotations provided in \"graph_attrs\"; returning None\\nINFO:napistu.network.net_create:Creating reverse reactions for reversible reactions on a directed graph\\nWARNING:napistu.network.net_create:3 edges were dropped due to duplicated origin -> target relationiships, use verbose for more information\\nINFO:napistu.network.net_create:Formatting cpr_graph output\\nWARNING:napistu.network.neighborhoods:net_polarity was not defined as an edge attribute so edges will not be colored\\n\\n```\\n```\\n<igraph.drawing.cairo.plot.CairoPlot at 0x14a3e0950>\\n```\\n\\n---\\n\\nThe networks used in cpr are just `igraph` `Graph` object with some additional vertex and edge attributes which are cpr-specific. This allows us to create, manipulate and visualize networks with igraph\\'s extensive library, while also utilize the growing suite of network-based analysis approaches in CPR.\\n\\n## Shortest paths\\n\\n### Define source and destination species\\n\\nAs an example we can try and find a pathway between glucose and pyruvate on the graph. \\n\\n---\\n\\n```python\\n#| label: select_origin_and_dest_species\\nS_NAME_ORIGIN = \"Glc\"\\nS_NAME_DEST = \"PYR\"\\n\\nall_species = sbml_dfs.species[\"s_name\"].tolist()\\nall_species.sort()\\nall_species_str = \\', \\'.join([f\"\\'{x}\\'\" for x in all_species])\\nprint(all_species_str)\\n```\\n\\nOutput:\\n```\\n\\'1,3BPG\\', \\'2\\'-deoxyadenosine 5\\'-monophosphate\\', \\'2,3BPG\\', \\'2OG\\', \\'2PG\\', \\'3PG\\', \\'ACO2\\', \\'ADP\\', \\'ADPGK:Mg2+\\', \\'AMP\\', \\'ATP\\', \\'Ac-CoA\\', \\'BPGM dimer\\', \\'CH3CHO\\', \\'CIT\\', \\'CO2\\', \\'CS dimer\\', \\'CoA-SH\\', \\'D-Fructose 1,6-bisphosphate\\', \\'D-Fructose 2,6-bisphosphate\\', \\'D-Glucono-1,5-lactone 6-phosphate\\', \\'D-ribose\\', \\'DERA\\', \\'DHAP\\', \\'E4P\\', \\'FAHD1:Mg2+ dimer\\', \\'FBP tetramer\\', \\'FH tetramer\\', \\'FUMA\\', \\'Fru 1-P\\', \\'Fru(6)P\\', \\'G1,6BP\\', \\'G6P\\', \\'G6PC\\', \\'G6PC2\\', \\'G6PC3\\', \\'G6PD dimer and tetramer\\', \\'GA3P\\', \\'GAPDH tetramers\\', \\'GCK\\', \\'GCK1:GKRP complex\\', \\'GCK1:GKRP complex\\', \\'GCKR\\', \\'GDP\\', \\'GNPDA1,2 hexamers\\', \\'GOT2 dimer\\', \\'GPI dimer\\', \\'GTP\\', \\'Glc\\', \\'GlcN6P\\', \\'Glycerol\\', \\'H+\\', \\'H2O\\', \\'IDH2 dimer\\', \\'IDH3 complex\\', \\'ISCIT\\', \\'L-Asp\\', \\'L-Glu\\', \\'MAL\\', \\'MDH2 dimer\\', \\'ME2:Mg2+ tetramer\\', \\'ME3:Mg2+ tetramer\\', \\'Mg2+\\', \\'NAD+\\', \\'NADH\\', \\'NADP+\\', \\'NADPH\\', \\'NH4+\\', \\'NNT dimer\\', \\'Nuclear Pore Complex (NPC)\\', \\'OAA\\', \\'PCK1\\', \\'PCK2\\', \\'PDG\\', \\'PEP\\', \\'PFK tetramer\\', \\'PFKFB dimers\\', \\'PFKFB1 dimer\\', \\'PGAM dimers\\', \\'PGD dimer\\', \\'PGK complexes\\', \\'PGLS\\', \\'PGM2:Mg2+\\', \\'PGM2L1:Mg2+\\', \\'PGP:Mg2+ dimer\\', \\'PKA catalytic subunit\\', \\'PP2A-ABdeltaC complex\\', \\'PRPP\\', \\'PRPS1 dimer\\', \\'PRPS2 dimer, PRPS1L dimer\\', \\'PXLP-K259-GOT1 dimer\\', \\'PYR\\', \\'Pi\\', \\'R1P\\', \\'R5P\\', \\'RBKS\\', \\'RPE:Fe2+ dimers\\', \\'RPIA\\', \\'RU5P\\', \\'SDH complex (ox.)\\', \\'SH7P\\', \\'SHPK\\', \\'SLC25A1\\', \\'SLC25A10\\', \\'SLC25A11 homodimer\\', \\'SLC25A12,13\\', \\'SLC37A1,2\\', \\'SLC37A4\\', \\'SUCC-CoA\\', \\'SUCCA\\', \\'SUCLA2:SUCLG1\\', \\'SUCLG1:SUCLG2\\', \\'Sedo\\', \\'Sor6P\\', \\'TALDO1 dimer\\', \\'TKT dimer\\', \\'TPI1 dimer\\', \\'XY5P\\', \\'aldolase tetramer\\', \\'cAMP\\', \\'dATP\\', \\'dR1P\\', \\'dR5P\\', \\'enolase dimer\\', \\'glucokinase and hexokinases\\', \\'lipo-aKGDH\\', \\'malate dehydrogenase 1 dimer\\', \\'phosphoPFKFB1 dimer\\', \\'pyruvate carboxylase holoenzyme\\', \\'pyruvate kinase tetramer\\'\\n\\n```\\n\\n---\\n\\n```python\\n#| label: inspect_source_and_dest\\nspecies = sbml_dfs.species\\n\\nsource_species = species[species[\"s_name\"] == S_NAME_ORIGIN]\\nfor spec in source_species.index:\\n    print(\"\\\\n\" + spec + \"\\\\n\")\\n    display(sbml_dfs_core.species_status(spec, sbml_dfs))\\n\\ndest_species = species[species[\"s_name\"] == S_NAME_DEST]\\nfor spec in dest_species.index:\\n    print(\"\\\\n\" + spec + \"\\\\n\")\\n    display(sbml_dfs_core.species_status(spec, sbml_dfs))\\n```\\n\\nOutput:\\n```\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\n\\n```\\n```\\n\\nS00000075\\n\\n\\n```\\n```\\n                             sc_name  stoichiometry  \\\\\\n0                      Glc [cytosol]           -1.0   \\n1                      Glc [cytosol]           -1.0   \\n2  Glc [endoplasmic reticulum lumen]            1.0   \\n3  Glc [endoplasmic reticulum lumen]            1.0   \\n4  Glc [endoplasmic reticulum lumen]            1.0   \\n5  Glc [endoplasmic reticulum lumen]           -1.0   \\n6         Glc [extracellular region]            1.0   \\n7                  Glc [nucleoplasm]            0.0   \\n\\n                                              r_name  \\\\\\n0          HK1,2,3,GCK phosphorylate Glc to form G6P   \\n1               ADPGK:Mg2+ phosphorylates Glc to G6P   \\n2  G6PC2 hydrolyzes glucose 6-phosphate to form g...   \\n3  G6PC hydrolyzes glucose 6-phosphate to form gl...   \\n4  G6PC3 hydrolyzes glucose 6-phosphate to form g...   \\n5   Efflux of glucose from the endoplasmic reticulum   \\n6   Efflux of glucose from the endoplasmic reticulum   \\n7  nucleoplasmic GCK1:GKRP complex => glucokinase...   \\n\\n                                       r_formula_str  \\n0  Glc -> G6P ---- modifiers: glucokinase and hex...  \\n1  ADP [cytosol] + Glc [cytosol] -> AMP [cytosol]...  \\n2  G6P [endoplasmic reticulum lumen] -> Glc [endo...  \\n3  G6P [endoplasmic reticulum lumen] -> Glc [endo...  \\n4  G6P [endoplasmic reticulum lumen] -> Glc [endo...  \\n5  Glc [endoplasmic reticulum lumen] -> Glc [extr...  \\n6  Glc [endoplasmic reticulum lumen] -> Glc [extr...  \\n7  GCK1:GKRP complex -> GCK + GCKR ---- modifiers...  \\n```\\n```\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\nWARNING:napistu.sbml_dfs_core:reaction_summary is deprecated and will be removed in a future version of rcpr; please use reaction_summaries() instead\\n\\n```\\n```\\n\\nS00000008\\n\\n\\n```\\n```\\n                      sc_name  stoichiometry  \\\\\\n0  PYR [mitochondrial matrix]            1.0   \\n1  PYR [mitochondrial matrix]            1.0   \\n2  PYR [mitochondrial matrix]            1.0   \\n3  PYR [mitochondrial matrix]           -1.0   \\n4               PYR [cytosol]            1.0   \\n\\n                                              r_name  \\\\\\n0  ME2:Mg2+ tetramer oxidatively decarboxylates M...   \\n1  ME3:Mg2+ tetramer oxidatively decarboxylates M...   \\n2              FAHD1:Zn2+ dimer hydrolyses OA to PYR   \\n3  Pyruvate + CO2 + ATP => ADP + Orthophosphate +...   \\n4        phosphoenolpyruvate + ADP => pyruvate + ATP   \\n\\n                                       r_formula_str  \\n0  NAD+ + MAL -> NADH + PYR ---- modifiers: ME2:M...  \\n1  MAL + NADP+ -> PYR + NADPH ---- modifiers: ME3...  \\n2  OAA -> PYR ---- modifiers: FAHD1:Mg2+ dimer] [...  \\n3  PYR -> OAA ---- modifiers: Ac-CoA + pyruvate c...  \\n4  PEP [cytosol] -> PYR [cytosol] ---- modifiers:...  \\n```\\n\\n---\\n\\nSince CPR reactions relate molecular species in a specific compartment (compartmentalized species), we need to find the cspecies which match the source and target species. In a compartmentalized model the source and destination species may exist in multiple compartments so we\\'ll try to identify the path from each source cspecies to each destination cspecies.\\n\\n---\\n\\n```python\\n#| label: compartmentalize_for_paths\\ntarget_species_paths = net_utils.compartmentalize_species_pairs(\\n    sbml_dfs, source_species.index.tolist(), dest_species.index.tolist()\\n)\\ntarget_species_paths\\n```\\n\\nOutput:\\n```\\n  s_id_origin  s_id_dest sc_id_origin  sc_id_dest\\n0   S00000075  S00000008   SC00000097  SC00000014\\n1   S00000075  S00000008   SC00000097  SC00000015\\n2   S00000075  S00000008   SC00000098  SC00000014\\n3   S00000075  S00000008   SC00000098  SC00000015\\n4   S00000075  S00000008   SC00000099  SC00000014\\n5   S00000075  S00000008   SC00000099  SC00000015\\n6   S00000075  S00000008   SC00000100  SC00000014\\n7   S00000075  S00000008   SC00000100  SC00000015\\n```\\n\\n---\\n\\n### Find all shortest weighted paths between the source and destination species\\n\\n---\\n\\n```python\\n#| label: find_shortest_paths\\n(\\n    all_shortest_reaction_paths_df,\\n    all_shortest_reaction_path_edges_df,\\n    edge_sources,\\n    paths_graph,\\n) = paths.find_all_shortest_reaction_paths(\\n    cpr_graph, sbml_dfs, target_species_paths, weight_var=\"weights\"\\n)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.network.paths:precomputed_distances were not provided; all paths will be calculated on-the-fly\\n\\n```\\n\\n---\\n\\n```python\\n#| label: shortest_path\\nwith pd.option_context(\\n    \"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", None\\n):  # more options can be specified also\\n    display(all_shortest_reaction_path_edges_df.query(\"path == 0\"))\\n    display(all_shortest_reaction_path_edges_df.query(\"path == 0\"))\\n```\\n\\nOutput:\\n```\\n   index        from          to  path  weights     sbo_term direction  \\\\\\n0      0  SC00000097   R00000052     0        1  SBO:0000010   forward   \\n1      1   R00000052  SC00000073     0        1  SBO:0000011   forward   \\n2      2  SC00000073  SC00000157     0        1  SBO:0000020   forward   \\n3      3  SC00000157  SC00000094     0        1  SBO:0000013   forward   \\n4      4  SC00000094  SC00000127     0        1  SBO:0000459   forward   \\n5      5  SC00000127  SC00000120     0        1  SBO:0000013   forward   \\n6      6  SC00000120   R00000023     0        1  SBO:0000010   forward   \\n7      7   R00000023  SC00000015     0        1  SBO:0000011   forward   \\n\\n  link_polarity net_polarity      origin        dest  \\n0    activation   activation  SC00000097  SC00000015  \\n1    activation   activation  SC00000097  SC00000015  \\n2    inhibition   inhibition  SC00000097  SC00000015  \\n3    activation   inhibition  SC00000097  SC00000015  \\n4    activation   inhibition  SC00000097  SC00000015  \\n5    activation   inhibition  SC00000097  SC00000015  \\n6    activation   inhibition  SC00000097  SC00000015  \\n7    activation   inhibition  SC00000097  SC00000015  \\n```\\n```\\n   index        from          to  path  weights     sbo_term direction  \\\\\\n0      0  SC00000097   R00000052     0        1  SBO:0000010   forward   \\n1      1   R00000052  SC00000073     0        1  SBO:0000011   forward   \\n2      2  SC00000073  SC00000157     0        1  SBO:0000020   forward   \\n3      3  SC00000157  SC00000094     0        1  SBO:0000013   forward   \\n4      4  SC00000094  SC00000127     0        1  SBO:0000459   forward   \\n5      5  SC00000127  SC00000120     0        1  SBO:0000013   forward   \\n6      6  SC00000120   R00000023     0        1  SBO:0000010   forward   \\n7      7   R00000023  SC00000015     0        1  SBO:0000011   forward   \\n\\n  link_polarity net_polarity      origin        dest  \\n0    activation   activation  SC00000097  SC00000015  \\n1    activation   activation  SC00000097  SC00000015  \\n2    inhibition   inhibition  SC00000097  SC00000015  \\n3    activation   inhibition  SC00000097  SC00000015  \\n4    activation   inhibition  SC00000097  SC00000015  \\n5    activation   inhibition  SC00000097  SC00000015  \\n6    activation   inhibition  SC00000097  SC00000015  \\n7    activation   inhibition  SC00000097  SC00000015  \\n```\\n\\n---\\n\\n```python\\n#| label: plot_shortest_paths\\npaths.plot_shortest_paths(paths_graph)\\n```\\n\\nOutput:\\n```\\n<igraph.drawing.cairo.plot.CairoPlot at 0x14a3a4790>\\n```\\n\\n---\\n\\n### Scaling Shortest Paths with Mechanism Matching\\n\\n---\\n\\n```python\\n#| label: mock_edgelist\\nedgelist = pd.DataFrame([\\n    {\"identifier_upstream\" : \"17925\", \"identifier_downstream\" : \"32966\"}, # glu, fbp\\n    {\"identifier_upstream\" : \"57634\", \"identifier_downstream\" : \"32966\"}, # f6p, fbp\\n    {\"identifier_upstream\" : \"32966\", \"identifier_downstream\" : \"57642\"}, # fbp, dhap\\n    {\"identifier_upstream\" : \"17925\", \"identifier_downstream\" : \"15361\"}, # glu, pyr\\n])\\n\\nspecies_identifiers = sbml_dfs.get_identifiers(\"species\")\\n```\\n\\n---\\n\\n#### Direct interactions\\n\\nParticipants in the same reaction\\n\\n---\\n\\n```python\\n#| label: direct_interactions\\ndirect_interactions = mechanism_matching.filter_to_direct_mechanistic_interactions(\\n    formatted_edgelist=edgelist,\\n    sbml_dfs=sbml_dfs,\\n    species_identifiers=species_identifiers,\\n    ontologies = {\"chebi\"}\\n)\\n\\nutils.style_df(direct_interactions)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.mechanism_matching:14 interactions mapped onto pairs of compartmentalized species in the mechanistic model\\n\\n```\\n```\\n<pandas.io.formats.style.Styler at 0x14a3f1090>\\n```\\n\\n---\\n\\n#### Indirect interactions\\n\\nFinding paths between all pairs of vertices\\n\\n---\\n\\n```python\\n#| label: indirect_interactions\\nindirect_interactions = mechanism_matching.filter_to_indirect_mechanistic_interactions(\\n    formatted_edgelist=edgelist,\\n    sbml_dfs=sbml_dfs,\\n    species_identifiers=species_identifiers,\\n    cpr_graph=cpr_graph,\\n    ontologies = {\"chebi\"},\\n    precomputed_distances=None,\\n    max_path_length=10,\\n)\\n\\nutils.style_df(indirect_interactions.assign(vpath = \"###\").assign(epath = \"###\"))\\n```\\n\\nOutput:\\n```\\nINFO:napistu.mechanism_matching:14 interactions mapped onto pairs of compartmentalized species in the mechanistic model\\n\\n```\\n```\\n<pandas.io.formats.style.Styler at 0x14a1dc210>\\n```\\n\\n---\\n\\n## Find neighbors within N steps of a species\\n\\n---\\n\\n```python\\n#| label: create_hourglass\\n# select the focal species to center the neighborhood on (like in the previous examples we\\'ll use glucose\\n\\nfocal_species = species[species[\"s_name\"] == S_NAME_ORIGIN].index.tolist()\\n\\nfocal_sc_species = net_utils.compartmentalize_species(sbml_dfs, focal_species)[\"sc_id\"].tolist()\\n\\nneighbors = neighborhoods.find_neighborhoods(\\n    sbml_dfs,\\n    cpr_graph,\\n    compartmentalized_species=focal_sc_species,\\n    network_type=\"hourglass\",\\n    order=6,\\n)\\n\\npruned_neighborhoods = neighborhoods.prune_neighborhoods(neighbors, top_n=10)\\n\\nneighborhoods.plot_neighborhood(\\n    pruned_neighborhoods[focal_sc_species[0]][\"graph\"], True\\n)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.network.neighborhoods:SC00000097 neighborhood: ancestors: 3 species; descendants: 24 reactions and 28 species\\nINFO:napistu.network.neighborhoods:SC00000098 neighborhood: ancestors: 1 species; descendants: 3 reactions and 5 species\\nINFO:napistu.network.neighborhoods:SC00000099 neighborhood: ancestors: 8 reactions and 14 species; descendants: 1 reactions and 2 species\\nINFO:napistu.network.neighborhoods:SC00000100 neighborhood: ancestors: 6 reactions and 7 species; descendants: 1 species\\n\\n```\\n```\\n<igraph.drawing.cairo.plot.CairoPlot at 0x14a2632d0>\\n```\\n\\n---\\n',\n",
       " 'understanding_sbml_dfs': '---\\ntitle: \"Tutorial - Understanding the SBML DFs Pathway Format\"\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\n---\\n\\n```python\\n#| label: config\\n\\nimport logging\\nimport os\\n\\nimport pandas as pd\\n\\nfrom napistu import utils\\n\\nimport tutorial_utils\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nconfig = tutorial_utils.NapistuConfig(\"config.yaml\", \"understanding_sbml_dfs\")\\n_ = config.load_asset(\"test_pathway\", \"sbml_dfs\")\\n```\\n\\n---\\n\\n# Overview\\n\\nThis tutorial aims to cover:\\n- What is the `SBML_dfs` format?\\n- How are `SBML_dfs` created?\\n- How can they be modified?\\n\\n# Basic Structure\\n\\nThe [cpr wiki: sbml_dfs](https://github.com/calico/Open-CPR/wiki/SBML-DFs) provides a detailed overview of the `SBML_dfs` data structure. Here, we\\'ll complement that description by showing the attributes of an actual pathway. To get up-and-running quickly we\\'ll just load an existing `SBML_dfs` object constructed from merging multiple metabolic pathways into a consensus pathway.\\n\\n---\\n\\n```python\\n#| label: load_data\\nsbml_dfs = utils.load_pickle(config.artifacts[\"sbml_dfs\"])\\n```\\n\\n---\\n\\n## Compartments\\n\\n---\\n\\n```python\\n#| label: compartments\\nutils.style_df(sbml_dfs.compartments)\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x158364910>\\n```\\n\\n---\\n\\n## Chemical Species (genes, metabolites, complexes, drugs)\\n\\n---\\n\\n```python\\n#| label: species\\nutils.style_df(sbml_dfs.species.head())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x15942ae10>\\n```\\n\\n---\\n\\n## Compartmentalized Species (species in a compartment)\\n\\n---\\n\\n```python\\n#| label: cspecies\\nutils.style_df(sbml_dfs.compartmentalized_species.head())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x159428dd0>\\n```\\n\\n---\\n\\n## Reactions\\n\\n---\\n\\n```python\\n#| label: reactions\\nutils.style_df(sbml_dfs.reactions.head())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x1583c3750>\\n```\\n\\n---\\n\\n## Reactions\\n\\n---\\n\\n```python\\n#| label: reaction_species\\nutils.style_df(sbml_dfs.reaction_species.head())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x1583c07d0>\\n```\\n\\n---\\n\\n## Optional attributes (`species_data` and `reactions_data`)\\n\\nWe can store additional data with species and reactions allowing us to connect molecular data to our graph. These tables `species_data` and `reactions_data` are discussed in the **adding_data_to_graphs** tutorial.\\n\\n# Identifiers and Sources\\n\\nMany of the core tables in `SBML_dfs` contain a column to track systematic identifiers and/or the information source. For example, `s_Identifiers` tracks a molecule\\'s systematic identifiers while `s_Source` keeps track of the pathways including the molecules (this becomes relevant once we start merging network models; see the **merging_networks_as_a_consensus** tutorial).\\n\\n## Identifiers\\n\\nIdentifiers are described in [cpr wiki: identifiers](https://github.com/calico/Open-CPR/wiki/SBML-DFs#identifiers) but here is an actual Identifiers object.\\n\\n---\\n\\n```python\\n#| label: identifiers_a\\nan_identifier = sbml_dfs.species[\"s_Identifiers\"][0]\\ntype(an_identifier)\\n```\\n\\nOutput:\\n```\\nnapistu.identifiers.Identifiers\\n```\\n\\n---\\n\\nAt its core `Identifiers` objects are list of dictionaries\\n\\n---\\n\\n```python\\n#| label: identifiers_b\\nan_identifier.ids\\n```\\n\\nOutput:\\n```\\n[{\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-HSA-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-HSA-198511\\',\\n  \\'bqb\\': \\'BQB_IS\\'},\\n {\\'ontology\\': \\'uniprot\\',\\n  \\'identifier\\': \\'P40926\\',\\n  \\'url\\': \\'https://purl.uniprot.org/uniprot/P40926\\',\\n  \\'bqb\\': \\'BQB_HAS_PART\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-MMU-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-MMU-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-RNO-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-RNO-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-CFA-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-CFA-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-BTA-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-BTA-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-DRE-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-DRE-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-XTR-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-XTR-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-GGA-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-GGA-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-DME-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-DME-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-CEL-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-CEL-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-SPO-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-SPO-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-SCE-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-SCE-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'},\\n {\\'ontology\\': \\'reactome\\',\\n  \\'identifier\\': \\'R-PFA-198511\\',\\n  \\'url\\': \\'https://reactome.org/content/detail/R-PFA-198511\\',\\n  \\'bqb\\': \\'BQB_IS_HOMOLOG_TO\\'}]\\n```\\n\\n---\\n\\nOr, reformatted:\\n\\n---\\n\\n```python\\n#| label: identifiers_c\\nutils.style_df(pd.DataFrame(an_identifier.ids))\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x15844cc90>\\n```\\n\\n---\\n\\n## Sources\\n\\nWhile `Identifiers` track the systematic identifiers associated with entities `Source` objects track the pathway representation information came from. For a single-source `SBML_dfs` object its source\\'s will be empty. For consensus model derived by combining multiple pathways, the `Source` object will track the upstream pathways. See [cpr wiki: sources](https://github.com/calico/Open-CPR/wiki/SBML-DFs#sources) for more details. Here, we can look more closely at a representative `Source` object to better understand its structure.\\n\\n---\\n\\n```python\\n#| label: source_a\\na_source = sbml_dfs.species[\"s_Source\"][0]\\ntype(a_source)\\n```\\n\\nOutput:\\n```\\nnapistu.source.Source\\n```\\n\\n---\\n\\nSource objects core attribute is their `source` pd.DataFrame. Since we are loading an `SBML_dfs` object which was constructed by merging multiple upstream `SBML_dfs` (see dev/create_test_pathway.qmd to see how this was done) the source table tracks which upstream pathway(s) entities came from:\\n\\n---\\n\\n```python\\n#| label: source_b\\nutils.style_df(a_source.source)\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x1590f0190>\\n```\\n\\n---\\n\\nWhen, an `SBML_dfs` model from a single-source is initialized its `Source.source` attributes are generally None. So the presense of source information indicates that the model has been created using the consensus module. This is module is described in the **merging_networks_as_a_consensus** tutorial.\\n\\n# Creating `SBML_dfs`\\n\\n## From a `.sbml` file\\n\\n`SBML_dfs` pathway models can be created in three ways (from a .sbml file, using an edgelist format, and from raw tables). The latter two modes of creating sbml_dfs are shown later in this document but first we\\'ll demonstrate how to create sbml_dfs from .sbml files because it is straight-forward and the sbml convention is arguably the most expressive format for accurately describing molecular mechanisms: [cpr wiki: sbml](https://github.com/calico/Open-CPR/wiki/SBML).\\n\\nHere is how we can load and format the Reactome Glucose Metabolism pathway as an `SBML_dfs` object.\\n\\n---\\n\\n```python\\n#| label: sbml_dfs_from_sbml\\n\\nfrom napistu import sbml_dfs_core\\nfrom napistu.ingestion import sbml\\nfrom napistu import utils\\n\\nEXAMPLE_MODEL = \"reactome_glucose_metabolism.sbml\"\\ntest_data = tutorial_utils.locate_test_data()\\n\\n#| label: create_sbml_dfs\\nmodel_path = os.path.join(test_data, EXAMPLE_MODEL)\\nsbml_model = sbml.SBML(model_path)\\nsbml_dfs = sbml_dfs_core.SBML_dfs(sbml_model)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.utils:creating an edgelist linking index levels s_id, entry and linking it to levels defined by ontology, identifier\\n\\n```\\n\\n---\\n\\n## From the underlying tables\\n\\n---\\n\\n```python\\n#| label: sbml_dfs_from_tables\\n\\nsbml_tbl_dict = {\\n    \"compartments\": sbml_dfs.compartments,\\n    \"species\": sbml_dfs.species,\\n    \"compartmentalized_species\": sbml_dfs.compartmentalized_species,\\n    \"reactions\": sbml_dfs.reactions,\\n    \"reaction_species\": sbml_dfs.reaction_species,\\n}\\n\\nsbml_dfs_core.SBML_dfs(sbml_tbl_dict).species\\n```\\n\\nOutput:\\n```\\n                          s_name  \\\\\\ns_id                               \\nS00000000                    Glc   \\nS00000001                  G6PC2   \\nS00000002                    G6P   \\nS00000003                    H2O   \\nS00000004                     Pi   \\n...                          ...   \\nS00000075  PP2A-ABdeltaC complex   \\nS00000076    phosphoPFKFB1 dimer   \\nS00000077           PFKFB1 dimer   \\nS00000078           PFKFB dimers   \\nS00000079  PKA catalytic subunit   \\n\\n                                               s_Identifiers  \\\\\\ns_id                                                           \\nS00000000  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000001  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000002  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000003  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000004  <napistu.identifiers.Identifiers object at 0x1...   \\n...                                                      ...   \\nS00000075  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000076  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000077  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000078  <napistu.identifiers.Identifiers object at 0x1...   \\nS00000079  <napistu.identifiers.Identifiers object at 0x1...   \\n\\n                                                s_Source  \\ns_id                                                      \\nS00000000  <napistu.source.Source object at 0x158395b90>  \\nS00000001  <napistu.source.Source object at 0x158468110>  \\nS00000002  <napistu.source.Source object at 0x1594abbd0>  \\nS00000003  <napistu.source.Source object at 0x15831aad0>  \\nS00000004  <napistu.source.Source object at 0x1590e51d0>  \\n...                                                  ...  \\nS00000075  <napistu.source.Source object at 0x15949a050>  \\nS00000076  <napistu.source.Source object at 0x15949b510>  \\nS00000077  <napistu.source.Source object at 0x159498b10>  \\nS00000078  <napistu.source.Source object at 0x15949b450>  \\nS00000079  <napistu.source.Source object at 0x15949bd50>  \\n\\n[80 rows x 3 columns]\\n```\\n\\n---\\n\\n## From an edgelist\\n\\n**TO DO**\\n\\n\\n# Modifying `sbml_dfs`\\n\\n## Dropping cofactors\\n\\nWhile cofactors such as ATP and NADH are biologically important they can generate confusion when we translate reactions into networks. For example, a dehydration reaction (X - H20) and a hydration reaction (Y + H20) would not really suggest regulation of Y by X via water. To deal with this issue, for many applications its helpful to remove cofactors.\\n\\n---\\n\\n```python\\n#| label: drop_cofactors\\nfrom napistu.modify import pathwayannot\\n\\nfiltered_pathway = pathwayannot.drop_cofactors(sbml_dfs)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.modify.pathwayannot:There were 13 cofactor species: H2O, Pi, NAD+, NADH, H+, L-Glu, CO2, ATP, ADP, Ac-CoA, GTP, GDP, AMP\\nWARNING:napistu.modify.pathwayannot:26 of 39 cofactors were not located in the pathway model: ADP, ATP, HCO3, H2CO3, GSH, GSSG, Gln, H+, O2, NADH, NAD+, NADPH, NADP+, NADP+, PPi, PPi, SAH, SAM, water, Na+, Cl-, CoA, CoA, FAD, FADH2, UDP\\nINFO:napistu.modify.pathwayannot:Cofactor species are present 70 times in reactions\\nINFO:napistu.modify.pathwayannot:32 of 50 reactions include cofactor species\\nINFO:napistu.modify.pathwayannot:60 of 250 reaction species will be filtered as cofactors\\nINFO:napistu.modify.pathwayannot:<pandas.io.formats.style.Styler object at 0x15950fed0>\\n\\n```\\n\\n---\\n\\n## Uncompartmentalizing\\n\\nCompartments are necessary to represent many mechanisms involving transport reactions such as creating a proton transport to fuel the electron transport chain. But, they add complexity which may be unecessary for some applications. By merging compartments we can create an uncompartmentalized model.\\n\\n---\\n\\n```python\\n#| label: uncompartmentalize\\nfrom napistu.modify import uncompartmentalize\\n\\none_compartment_sbml_dfs = uncompartmentalize.uncompartmentalize_sbml_dfs(sbml_dfs)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.consensus:Merging reactions based on identical membership (sc_id + stoichiometry)\\nINFO:napistu.consensus:>>>> 2 r_id entries merged into 1\\nINFO:napistu.consensus:Creating formulas for to-be-merged reactions to help with reporting merges of reactions with inconsistently named reactants\\nINFO:napistu.consensus:Done creating reaction formulas\\nINFO:napistu.consensus:Testing for identical formulas of to-be-merged reactions\\nWARNING:napistu.consensus:\\n1 merges were of entities with distinct names, including:\\n\\nWARNING:napistu.consensus:2OG [cytosol] + MAL [mitochondrial matrix] -> 2OG [mitochondrial matrix] + MAL [cytosol] ---- modifiers: SLC25A11 homodimer [mitochondrial inner membrane]] & 2OG [mitochondrial matrix] + MAL [cytosol] -> 2OG [cytosol] + MAL [mitochondrial matrix] ---- modifiers: SLC25A11 homodimer [mitochondrial inner membrane]]\\n\\nINFO:napistu.consensus:==============================\\n\\nINFO:napistu.consensus:Merging reactions identifiers\\nINFO:napistu.consensus:Merging reactions sources\\nINFO:napistu.consensus:Creating source table\\nINFO:napistu.consensus:Aggregating old sources\\nINFO:napistu.consensus:Returning new source table\\nINFO:napistu.modify.uncompartmentalize:14 reactions species will be removed because they are substrates and products in the same reaction\\nINFO:napistu.modify.uncompartmentalize:2 reactions where substrates and products cancel out were dropped including: Efflux of glucose from the endoplasmic reticulum & glucokinase [nucleoplasm] => glucokinase [cytosol]\\n\\n```\\n\\n---\\n\\n## Gap-filling\\n\\n**TO DO**\\n\\n---\\n',\n",
       " 'working_with_genome_scale_networks': '---\\ntitle: \"Tutorial - Working with Genome-Scale Networks\"\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\n---\\n\\n```python\\n#| label: config\\nimport logging\\n\\nimport pandas as pd\\n\\nfrom napistu import utils\\n\\nimport tutorial_utils\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nconfig = tutorial_utils.CprConfig(\"config.yaml\", \"working_with_genome_scale_pathways\")\\n```\\n\\n---\\n\\nThis notebook demonstrates how to use CPR\\'s network-based approaches to interrogate a prime-time human multi-source pathway model.\\n\\nThis model, produced by running `1_workflow_cpr_cli.qmd` combines 5 distinct sources:\\n- Reactome: 2,000+ Reactome pathways aggregated into a single graph of genes, complexes, and molecules.\\n- TRRUST: TF->target regulatory relationships\\n- Recon3D (aka BiGG): a genome-scale metabolic model\\n- STRING: consensus, non-mechanistic interactions\\n- Dogmatic Scaffold - a model which just links cognate, genes, transcript, and proteins to promote merging of like-species.\\n\\nFirst, we\\'ll load the `sbml_dfs` pathway representation and a `cpr_graph` object which translates this information into a graph of vertices and edges.\\n\\nThen, we\\'ll demo the shortest paths problem, where we try to find the shortest path between two molecular species. On a densely connected network there will be many equally lengths paths most of which are meaningless.\\n\\nTO DO - we need a notebook talking more about edge weighting and passing vertex attributes. When we are using a weighted networks there are few equivalent paths - in this case the shortest weighted paths is the path which minimizes the summed edge weights.\\n\\nFinally, we\\'ll identify a set of neighbors around a focal vertex to build its molecular neighborhood.\\n\\nThese approaches are often sped up by precomputing the distances between pairs of molecules. Look at the `1_precomputed_distances.ipynb` if you want to learn more.\\n\\n---\\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorial_markdown_dict = dict()\n",
    "for k, v in TUTORIAL_URLS.items():\n",
    "    tutorial_markdown_dict[k] = await run_async(get_tutorial_markdown(k))\n",
    "\n",
    "tutorial_markdown_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "FastMCP.run(\n",
      "    self,\n",
      "    transport: \u001b[33m\"Literal['stdio', 'streamable-http', 'sse'] | None\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **transport_kwargs: \u001b[33m'Any'\u001b[39m,\n",
      ") -> \u001b[33m'None'\u001b[39m\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m run(\n",
      "        self,\n",
      "        transport: Literal[\u001b[33m\"stdio\"\u001b[39m, \u001b[33m\"streamable-http\"\u001b[39m, \u001b[33m\"sse\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **transport_kwargs: Any,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"Run the FastMCP server. Note this is a synchronous function.\u001b[39m\n",
      "\n",
      "\u001b[33m        Args:\u001b[39m\n",
      "\u001b[33m            transport: Transport protocol to use (\"stdio\", \"sse\", or \"streamable-http\")\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        logger.info(\u001b[33mf'Starting server \"{self.name}\"...'\u001b[39m)\n",
      "\n",
      "        anyio.run(partial(self.run_async, transport, **transport_kwargs))\n",
      "\u001b[31mFile:\u001b[39m      ~/Desktop/GITHUB/napistu/tutorials/.venv/lib/python3.11/site-packages/fastmcp/server/server.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "??FastMCP.run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
