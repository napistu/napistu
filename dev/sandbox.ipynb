{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package in development mode if needed\n",
    "# !pip install -e '.[mcp]'\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import the MCP components\n",
    "from napistu.mcp.server import create_server, start_server\n",
    "from napistu.mcp import documentation, codebase, tutorials, execution\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"napistu\")\n",
    "\n",
    "# Helper function to run async code in Jupyter\n",
    "async def run_async(coro):\n",
    "    return await coro\n",
    "\n",
    "# Create a dummy session context for execution components\n",
    "session_context = {}\n",
    "object_registry = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.mcp.profiles import get_profile\n",
    "# define the types of assets to load\n",
    "profile = get_profile(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the relevant components\n",
    "mcp_server = create_server(profile)\n",
    "# initialize the relevant components\n",
    "live_server = start_server(mcp_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.mcp import documentation_utils\n",
    "from napistu.mcp.documentation_utils import read_read_the_docs\n",
    "\n",
    "from napistu.mcp.constants import READMES\n",
    "from napistu.mcp.constants import NAPISTU_PY_READTHEDOCS_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readmes\n",
    "readme = await run_async(documentation_utils.load_readme_content(READMES[\"napistu\"]))\n",
    "readme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-the-docs module and function defs\n",
    "rtd_docs = await run_async(read_read_the_docs(package_toc_url = NAPISTU_PY_READTHEDOCS_API))\n",
    "rtd_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# github wiki\n",
    "\n",
    "from napistu.mcp.github import list_wiki_pages\n",
    "from napistu.constants import PACKAGE_DEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_pages = await run_async(list_wiki_pages(repo = PACKAGE_DEFS.GITHUB_PROJECT_REPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# github issues and PRs\n",
    "\n",
    "from napistu.mcp.github import list_issues\n",
    "from napistu.mcp.github import list_pull_requests\n",
    "from napistu.mcp.github import get_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_ISSUES_INDEXED = \"all\"\n",
    "GITHUB_PRS_INDEXED = \"all\"\n",
    "\n",
    "# load issues (already includes the body)\n",
    "issue_list = await run_async(list_issues(PACKAGE_DEFS.GITHUB_PROJECT_REPO, state = GITHUB_ISSUES_INDEXED))\n",
    "\n",
    "# load PRs\n",
    "prs_list = await run_async(list_pull_requests(PACKAGE_DEFS.GITHUB_PROJECT_REPO, state = GITHUB_PRS_INDEXED))\n",
    "\n",
    "# there is probably no reason to use this since this info is captured in the lists\n",
    "# prs_list = await run_async(get_issue(PACKAGE_DEFS.GITHUB_PROJECT_REPO, number = 11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorials\n",
    "\n",
    "from napistu.mcp.constants import TUTORIAL_URLS\n",
    "from napistu.mcp.tutorials_utils import get_tutorial_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/adding_data_to_graphs.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'adding_data_to_graphs' at 'napistu_data/tutorials/adding_data_to_graphs.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/downloading_pathway_data.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'downloading_pathway_data' at 'napistu_data/tutorials/downloading_pathway_data.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/formatting_sbml_dfs_as_cpr_graphs.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'formatting_sbml_dfs_as_cpr_graphs' at 'napistu_data/tutorials/formatting_sbml_dfs_as_cpr_graphs.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/merging_models_into_a_consensus.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'merging_models_into_a_consensus' at 'napistu_data/tutorials/merging_models_into_a_consensus.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/r_based_network_visualization.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'r_based_network_visualization' at 'napistu_data/tutorials/r_based_network_visualization.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/suggesting_mechanisms_with_networks.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'suggesting_mechanisms_with_networks' at 'napistu_data/tutorials/suggesting_mechanisms_with_networks.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/understanding_sbml_dfs.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'understanding_sbml_dfs' at 'napistu_data/tutorials/understanding_sbml_dfs.ipynb'\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/refs/heads/main/tutorials/working_with_genome_scale_networks.ipynb \"HTTP/1.1 200 OK\"\n",
      "INFO:napistu.mcp.tutorials_utils:Downloaded and cached notebook for tutorial 'working_with_genome_scale_networks' at 'napistu_data/tutorials/working_with_genome_scale_networks.ipynb'\n"
     ]
    }
   ],
   "source": [
    "tutorial_markdown_dict = dict()\n",
    "for k, v in TUTORIAL_URLS.items():\n",
    "    tutorial_markdown_dict[k] = await run_async(get_tutorial_markdown(k))\n",
    "\n",
    "tutorial_markdown_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\ntitle: Tutorial - Adding Data to Graphs\\nauthor: \"Shackett\"\\ndate: \"May 9th 2025\"\\n---\\n\\nThis notebook describes how we can add species- or reaction-level data to pathway representation (`SBML_dfs`), and also how we can propagate these attributes to the vertices and edges in a `cpr_graph`.\\n\\n## Adding data to pathways\\n\\nSpecies- and reaction-level data is associated with the `species_data` or `reactions_data` attribute of an `SBML_dfs` object. Each of these fields can include multiple sources of entity data organized as a dictionary where keys are an information source label, and values are a `pd.DataFrame`. Each DataFrame is indexed by species or reaction ids (s_ids and _r_ids) corresponding to the indecies of the `species` and `reactions` tables.\\n\\nThe main approaches for this are either:\\n1. Adding information during network creation. This is generally how reaction-centric information such as the STRING weights will be passed. \\n2. Directly add species or reaction data joining data based on systematic identifiers stored in `s_Identifiers` or `r_Identifiers` attributes.\\n\\n## Passing information to graphs\\n\\nTo apply network-based methods we generally want to map results onto either vertex or edge attributes. For edges this can involve passing information which can be used for weighting connections (to favor certain sources or weight based on quantitative evidence scores.) For vertices, adding attributes supports either visualization or inference approaches such as network propagation.\\n\\nWe propagate this information by using an `entity_weights` dictionary which specifies both the values we should pluck out of entity data table (as a dictionary key plus a pd.DataFrame column) but also how we can combine these values. This would allow us to combine species_data which may be from different sets of biomolecules (such as proteomics and metabolomics), or to weight edges derived from multiple sources which may be weighted in different ways (or possess no evidence scores at all).\\n\\n# Demos\\n\\n## Adding Data to Pathways\\n\\n### During construction\\n\\nYou can create `SBML_dfs` objects in multiple ways:\\n1. translating results from an .sbml file\\n2. direct creation from a list of component pd.DataFrames (species, compartmentalized_species, compartments, reactions, and reaction_species)\\n3. using the edgelist format to specify pairwise relationships with minimal annotations\\n\\nOf these, the edgelist format supports directly passing edge attributes into `reactions_data`. Basically, when defining edges all of the columns which are not required variables will be added to reactions_data.\\n\\nSome example functions which pass attributes during creation are yeast.convert_idea_kinetics_to_sbml_dfs() and string.convert_string_to_sbml_dfs(). As a quick demo:\\n\\n---\\n\\n```python\\nimport logging\\nlogger = logging.getLogger()\\nlogger.setLevel(\"INFO\")\\n\\nimport tutorial_utils\\nconfig = tutorial_utils.CprConfig(\"config.yaml\", \"downloading_pathway_data\")\\n```\\n\\n---\\n\\n```python\\nimport pandas as pd\\n\\nfrom napistu import sbml_dfs_core\\nfrom napistu import source\\nfrom napistu import identifiers\\nfrom napistu import utils\\n\\n# setup compartments (just treat this as uncompartmentalized for now)\\ncompartments_df = sbml_dfs_core._stub_compartments()\\n\\n# Per convention unaggregated models receive an empty source\\ninteraction_source = source.Source(init=True)\\n```\\n\\n---\\n\\n```python\\ndef _get_example_edgelist_inputs():\\n    interaction_edgelist = pd.DataFrame(\\n        [\\n            {\\n                \"upstream_name\": \"A\",\\n                \"downstream_name\": \"B\",\\n                \"upstream_compartment\": \"cellular_component\",\\n                \"downstream_compartment\": \"cellular_component\",\\n                \"r_name\": \"A -> B\",\\n                \"sbo_term\": \"SBO:0000020\",\\n                \"r_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ncbi.nlm.nih.gov/pubmed/10604467\",\\n                            \"BQB_IS_DESCRIBED_BY\",\\n                        )\\n                    ]\\n                ),\\n                \"r_isreversible\": False,\\n                \"rxn_attr_1\": \"foo\",\\n                \"rxn_attr_2\": 1,\\n            },\\n            {\\n                \"upstream_name\": \"A\",\\n                \"downstream_name\": \"C\",\\n                \"upstream_compartment\": \"cellular_component\",\\n                \"downstream_compartment\": \"cellular_component\",\\n                \"r_name\": \"A -> C\",\\n                \"sbo_term\": \"SBO:0000459\",\\n                \"r_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ncbi.nlm.nih.gov/pubmed/10604467\",\\n                            \"BQB_IS_DESCRIBED_BY\",\\n                        )\\n                    ]\\n                ),\\n                \"r_isreversible\": False,\\n                \"rxn_attr_1\": \"bar\",\\n                \"rxn_attr_2\": 2,\\n            },\\n        ],\\n        index=[0, 1],\\n    )\\n\\n    species_df = pd.DataFrame(\\n        [\\n            {\\n                \"s_name\": \"A\",\\n                \"s_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ensembl.org/Homo_sapiens/geneview?gene=ENSG00000153094\",\\n                            \"BQB_IS\",\\n                        )\\n                    ]\\n                ),\\n                \"spec_attr\": 2,\\n            },\\n            {\\n                \"s_name\": \"B\",\\n                \"s_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"https://purl.uniprot.org/uniprot/Q557I5\", \"BQB_IS\"\\n                        )\\n                    ]\\n                ),\\n                \"spec_attr\": 5,\\n            },\\n            {\\n                \"s_name\": \"C\",\\n                \"s_Identifiers\": identifiers.Identifiers(\\n                    [\\n                        identifiers.format_uri(\\n                            \"http://www.ebi.ac.uk/chebi/searchId.do?chebiId=CHEBI:37136\",\\n                            \"BQB_IS\",\\n                        )\\n                    ]\\n                ),\\n                \"spec_attr\": 1,\\n            },\\n        ],\\n        index=[0, 1, 2],\\n    )\\n\\n    compartments_df = sbml_dfs_core._stub_compartments()\\n\\n    interaction_source = source.Source(init=True)\\n\\n    return (interaction_edgelist, species_df, compartments_df, interaction_source)\\n\\n\\n(\\n    interaction_edgelist,\\n    species_df,\\n    compartments_df,\\n    interaction_source,\\n) = _get_example_edgelist_inputs()\\n\\nsbml_dfs = sbml_dfs_core.sbml_dfs_from_edgelist(\\n    interaction_edgelist,\\n    species_df,\\n    compartments_df,\\n    interaction_source,\\n    keep_species_data=\"data\",\\n    keep_reactions_data=\"data\",\\n)\\n```\\n\\n---\\n\\n#### Mounted species data \\n\\n---\\n\\n```python\\nutils.style_df(sbml_dfs.reactions_data[\"data\"])\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c4ba10>\\n```\\n\\n---\\n\\n#### Mounted reaction data\\n\\n---\\n\\n```python\\nutils.style_df(sbml_dfs.species_data[\"data\"])\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c34b10>\\n```\\n\\n---\\n\\n## Adding entity data to an existing `SBML_dfs` object\\n\\nTo add reaction- or species-level data to an existing `SBML_dfs` object we can create an appropriate pd.DataFrame and directly add it to the object. As with all `species_data` or `reactions_data` entries this table must be indexed by the models species or reaction ids. Because of this, the challenge in merging results determining which species in our model match entries in the to-be-added entity data. To provide some guidance on this we will consider a couple of cases: matching by names, and matching by standard identifiers.\\n\\n### Matching by names\\n\\nMatching by names or symbols is generally not a good idea because there is a many-to-many relationship between many genes and symbols. Still, lots of people do use symbols, and this is a simple case which shows how easy it is to add entity data once we\\'ve matched it to existing pathway species or reactions.\\n\\n\\n---\\n\\n```python\\nnew_species_data = sbml_dfs.species[0:2].assign(new_data=2)[[\"new_data\"]]\\n\\nnew_reactions_data = pd.DataFrame(\\n    [\\n        {\"r_id\": sbml_dfs.reactions.index[0], \"new_data\": 2},\\n        {\"r_id\": sbml_dfs.reactions.index[1], \"new_data\": 3},\\n    ]\\n).set_index(\"r_id\")\\n\\nsbml_dfs.add_species_data(\"new_data\", new_species_data)\\nsbml_dfs.add_reactions_data(\"new_data\", new_reactions_data)\\n\\nutils.style_df(sbml_dfs.species_data[\"new_data\"])\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c26bd0>\\n```\\n\\n---\\n\\n### Matching by identifiers\\n\\nGenerally we will be trying to add molecular data to a network which is associated with one or more systematic ontologies. A nice way to do this is using `mechanism_matching.features_to_pathway_species()`. This function will compare a table containing all species or reactions identifiers in the pathway model to a set of query features to create a lookup table of query identifiers to pathway ids.\\n\\n---\\n\\n```python\\nfrom napistu import mechanism_matching\\n\\n# export identifiers from pathway\\nspecies_identifiers = sbml_dfs.get_identifiers(\"species\")\\n\\nfeature_annotations = pd.DataFrame(\\n    [\\n        {\"identifier\": \"ENSG00000153094\", \"expression\": 1000},\\n        {\"identifier\": \"ENSG0000000000\", \"expression\": 50},\\n    ],\\n    index=[0, 1],\\n)\\n\\nupdated_species_data = mechanism_matching.features_to_pathway_species(\\n    feature_annotations,\\n    species_identifiers,\\n    ontologies={\"ensembl_gene\"},\\n    feature_id_var=\"identifier\",\\n)[[\"s_id\", \"expression\"]].set_index(\"s_id\")\\n\\nsbml_dfs.add_species_data(\"newest_data\", updated_species_data)\\n```\\n\\n---\\n\\n#### Mounted species data\\n\\n---\\n\\n```python\\nsbml_dfs.species_data\\n```\\n\\nOutput:\\n```\\n{\\'data\\':            spec_attr\\n s_id                \\n S00000000          2\\n S00000001          5\\n S00000002          1,\\n \\'new_data\\':            new_data\\n s_id               \\n S00000000         2\\n S00000001         2,\\n \\'newest_data\\':            expression\\n s_id                 \\n S00000000        1000}\\n```\\n\\n---\\n\\n#### Mounted reaction data\\n\\n---\\n\\n```python\\nsbml_dfs.reactions_data\\n```\\n\\nOutput:\\n```\\n{\\'data\\':           rxn_attr_1  rxn_attr_2\\n r_id                            \\n R00000000        foo           1\\n R00000001        bar           2,\\n \\'new_data\\':            new_data\\n r_id               \\n R00000000         2\\n R00000001         3}\\n```\\n\\n---\\n\\n## Passing Information to Graphs \\n\\nNow that we have our data of interest tied to the appropriate species and reactions in our pathway we can carry this information forward as we translate the pathway representation into a graph of vertices connected by edges.\\n\\nThis process is controlled by the settings in the `reaction_graph_attrs` dictionary which specifies the variables which should pulled out of `species_data` or `reactions_data` and can also be used to specify how the graph should be weighted. A real-world example of this can be found in [calcification_causality.ipynb](https://github.com/calico/discovery/blob/main/projects/calcification/calcification_causality/calcification_causality.ipynb).\\n\\n\\n---\\n\\n```python\\nfrom napistu.network import net_create\\n\\nreaction_graph_attrs = {\\n    \"reactions\": {\\n        \"reaction_wts\": {\"table\": \"data\", \"variable\": \"rxn_attr_1\", \"trans\": \"identity\"}\\n    },\\n    \"species\": {\\n        \"species_var1\": {\\n            \"table\": \"data\",\\n            \"variable\": \"spec_attr\",\\n            \"trans\": \"string_inv\",\\n        },\\n        \"species_var2\": {\\n            \"table\": \"newest_data\",\\n            \"variable\": \"expression\",\\n            \"trans\": \"identity\",\\n        },\\n    },\\n}\\n\\ngraph_w_annotations = net_create.create_cpr_graph(\\n    sbml_dfs,\\n    reaction_graph_attrs,\\n    directed=True,\\n    graph_type=\"regulatory\"\\n)\\n```\\n\\nOutput:\\n```\\nINFO:napistu.network.net_create:Organizing all network nodes (compartmentalized species and reactions)\\nINFO:napistu.network.net_create:Formatting edges as a regulatory graph\\nINFO:napistu.network.net_create:Formatting 4 reactions species as tiered edges.\\nINFO:napistu.network.net_create:Adding additional attributes to edges, e.g., # of children and parents.\\nINFO:napistu.network.net_create:Done preparing regulatory graph\\nINFO:napistu.network.net_create:Adding reversibility and other meta-data from reactions_data\\nINFO:napistu.network.net_create:Creating reverse reactions for reversible reactions on a directed graph\\nINFO:napistu.network.net_create:Formatting cpr_graph output\\n\\n```\\n\\n---\\n\\n### Graph vertices (with data)\\n\\n---\\n\\n```python\\nutils.style_df(graph_w_annotations.get_vertex_dataframe())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173d59810>\\n```\\n\\n---\\n\\n### Graph edges (with data)\\n\\n---\\n\\n```python\\nutils.style_df(graph_w_annotations.get_edge_dataframe())\\n```\\n\\nOutput:\\n```\\n<pandas.io.formats.style.Styler at 0x173c48210>\\n```\\n\\n---\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorial_markdown_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
