{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from napistu import utils\n",
    "from napistu.gcs import downloads\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(\"napistu\")\n",
    "\n",
    "import httpx\n",
    "\n",
    "NAPISTU_DATA_DIR = os.path.expanduser(\"~/Desktop/DATA/napistu_data\")\n",
    "NAPISTU_ASSET = \"human_consensus_w_distances\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "napistu_graph_path = \"napistu_data/test_pathway/test_pathway/napistu_graph.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will download the sbml_dfs, napistu_graph, and species_identifiers from a public GCS bucket\n",
    "# or if they already exist in the NAPISTU_DATA_DIR, it will just set the path to the existing asset\n",
    "sbml_dfs_path = downloads.load_public_napistu_asset(\n",
    "    asset = NAPISTU_ASSET,\n",
    "    data_dir = NAPISTU_DATA_DIR,\n",
    "    subasset = \"sbml_dfs\",\n",
    ")\n",
    "\n",
    "napistu_graph_path = downloads.load_public_napistu_asset(\n",
    "    asset = NAPISTU_ASSET,\n",
    "    data_dir = NAPISTU_DATA_DIR,\n",
    "    subasset = \"napistu_graph\"\n",
    ")\n",
    "\n",
    "species_identifiers_path = downloads.load_public_napistu_asset(\n",
    "    asset = NAPISTU_ASSET,\n",
    "    data_dir = NAPISTU_DATA_DIR,\n",
    "    subasset = \"species_identifiers\"\n",
    ")\n",
    "\n",
    "precomputed_distances_path = downloads.load_public_napistu_asset(\n",
    "    asset = NAPISTU_ASSET,\n",
    "    data_dir = NAPISTU_DATA_DIR,\n",
    "    subasset = \"precomputed_distances\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu import utils as napistu_utils\n",
    "from napistu.network.ng_core import NapistuGraph\n",
    "from napistu.sbml_dfs_core import SBML_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu import source\n",
    "from napistu import identifiers\n",
    "from napistu.network import neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbml_dfs = SBML_dfs.from_pickle(sbml_dfs_path)\n",
    "napistu_graph = NapistuGraph.from_pickle(napistu_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = napistu_graph.to_pandas_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_identifiers = pd.read_csv(species_identifiers_path, sep = \"\\t\")\n",
    "precomputed_distances = utils.load_parquet(precomputed_distances_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.network.neighborhoods import find_and_prune_neighborhoods\n",
    "\n",
    "SC_ID = \"SC00002412\"\n",
    "\n",
    "neighborhood = find_and_prune_neighborhoods(\n",
    "    sbml_dfs,\n",
    "    napistu_graph,\n",
    "    compartmentalized_species = SC_ID,\n",
    "    precomputed_distances = precomputed_distances,\n",
    "    top_n = 200,\n",
    "    order = 4,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbml_dfs.species_status(\"S00002412\").sort_values(\"r_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "compartmentalized_species = [\"SC00002412\"]\n",
    "order = 4\n",
    "top_n = 200\n",
    "\n",
    "precomputed_neighbors = neighborhoods._precompute_neighbors(\n",
    "    compartmentalized_species,\n",
    "    precomputed_distances,\n",
    "    sbml_dfs,\n",
    "    network_type=\"hourglass\",\n",
    "    order=order,\n",
    "    top_n=math.ceil(top_n * 1.1),  # ties when using head()?\n",
    ")\n",
    "\n",
    "neighborhoods = neighborhoods.find_neighborhoods(\n",
    "    sbml_dfs,\n",
    "    napistu_graph,\n",
    "    compartmentalized_species = compartmentalized_species,\n",
    "    precomputed_neighbors = precomputed_neighbors,\n",
    "    order = 4,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.network.constants import NEIGHBORHOOD_DICT_KEYS, NAPISTU_GRAPH_EDGES, NAPISTU_GRAPH_VERTICES, NAPISTU_GRAPH_NODE_TYPES, DISTANCES\n",
    "from napistu.network import neighborhoods as neighborhood_module\n",
    "from napistu.constants import SBML_DFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_neighborhood_dicts = dict()\n",
    "\n",
    "for an_sc_id in neighborhoods.keys():\n",
    "    one_neighborhood = neighborhoods[an_sc_id]\n",
    "    raw_graph = one_neighborhood[NEIGHBORHOOD_DICT_KEYS.GRAPH]\n",
    "    \n",
    "    # filter to the desired number of vertices w/ lowest path_weight (from focal node)\n",
    "    # filter neighborhood to high-weight vertices\n",
    "    pruned_vertices = neighborhood_module._prune_vertex_set(one_neighborhood, top_n=top_n)\n",
    "\n",
    "    print(\"pruned vertices\")\n",
    "    print(pruned_vertices)\n",
    "\n",
    "    # reduce neighborhood to this set of high-weight vertices\n",
    "    all_neighbors = pd.DataFrame(\n",
    "        {\n",
    "            NAPISTU_GRAPH_VERTICES.NAME: raw_graph.vs[NAPISTU_GRAPH_VERTICES.NAME]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"all neighbors\")\n",
    "    print(all_neighbors)\n",
    "\n",
    "    pruned_vertices_indices = all_neighbors[\n",
    "        all_neighbors[NAPISTU_GRAPH_VERTICES.NAME].isin(\n",
    "            pruned_vertices[NAPISTU_GRAPH_VERTICES.NAME]\n",
    "        )\n",
    "    ].index.tolist()\n",
    "\n",
    "    pruned_neighborhood = raw_graph.subgraph(\n",
    "        raw_graph.vs[pruned_vertices_indices],\n",
    "        implementation=\"auto\",\n",
    "    )\n",
    "\n",
    "    pruned_edges = pd.DataFrame([e.attributes() for e in pruned_neighborhood.es])\n",
    "\n",
    "    print(pruned_vertices)\n",
    "    print(\"node type\")\n",
    "    print(pruned_vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE])\n",
    "    print(\"reaction spec\")\n",
    "    print(NAPISTU_GRAPH_NODE_TYPES.REACTION)\n",
    "\n",
    "    pruned_reactions = pruned_vertices[\n",
    "        pruned_vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE]\n",
    "        == NAPISTU_GRAPH_NODE_TYPES.REACTION\n",
    "    ][NAPISTU_GRAPH_VERTICES.NAME]\n",
    "\n",
    "    print(\"prune reactions\")\n",
    "    print(pruned_reactions)\n",
    "    if pruned_reactions.shape[0] != 0:\n",
    "\n",
    "        logger.info(f\"Removing {pruned_reactions.shape[0]} reactions from reaction_sources\")\n",
    "\n",
    "        if one_neighborhood[NEIGHBORHOOD_DICT_KEYS.REACTION_SOURCES] is None:\n",
    "\n",
    "            logger.info(\"No reaction sources found in one_neighborhood\")\n",
    "            # allow for missing source information since this is currently optional\n",
    "            pruned_reaction_sources = one_neighborhood[\n",
    "                NEIGHBORHOOD_DICT_KEYS.REACTION_SOURCES\n",
    "            ]\n",
    "        else:\n",
    "            source_filtering_mask = one_neighborhood[NEIGHBORHOOD_DICT_KEYS.REACTION_SOURCES][\n",
    "                    SBML_DFS.R_ID\n",
    "                ].isin(pruned_reactions)\n",
    "            \n",
    "            logger.info(f\"source_filtering_mask contains {sum(source_filtering_mask)} reaction sources of {source_filtering_mask.shape[0]} total sources\")\n",
    "\n",
    "            pruned_reaction_sources = one_neighborhood[\n",
    "                NEIGHBORHOOD_DICT_KEYS.REACTION_SOURCES\n",
    "            ][source_filtering_mask]\n",
    "    else:\n",
    "        pruned_reaction_sources = one_neighborhood[\n",
    "            NEIGHBORHOOD_DICT_KEYS.REACTION_SOURCES\n",
    "        ]\n",
    "\n",
    "    pruned_neighborhood_dict = {\n",
    "        NEIGHBORHOOD_DICT_KEYS.GRAPH: pruned_neighborhood,\n",
    "        NEIGHBORHOOD_DICT_KEYS.VERTICES: pruned_vertices,\n",
    "        NEIGHBORHOOD_DICT_KEYS.EDGES: pruned_edges,\n",
    "        NEIGHBORHOOD_DICT_KEYS.REACTION_SOURCES: pruned_reaction_sources,\n",
    "    }\n",
    "\n",
    "    neighborhood_module._validate_neighborhood_consistency(pruned_neighborhood_dict, an_sc_id)\n",
    "    pruned_neighborhood_dicts[an_sc_id] = pruned_neighborhood_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_neighborhood = neighborhoods[an_sc_id]\n",
    "vertices = one_neighborhood[NEIGHBORHOOD_DICT_KEYS.VERTICES]\n",
    "raw_graph = one_neighborhood[NEIGHBORHOOD_DICT_KEYS.GRAPH]\n",
    "\n",
    "pruned_reactions = set(pruned_vertices.loc[pruned_vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE] == NAPISTU_GRAPH_NODE_TYPES.REACTION, NAPISTU_GRAPH_VERTICES.NAME].tolist())\n",
    "original_reactions = set(vertices.loc[vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE] == NAPISTU_GRAPH_NODE_TYPES.REACTION, NAPISTU_GRAPH_VERTICES.NAME].tolist())\n",
    "reactions_to_remove = original_reactions - pruned_reactions\n",
    "\n",
    "reactions_to_remove\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neighborhood_vertices = one_neighborhood[NEIGHBORHOOD_DICT_KEYS.VERTICES]\n",
    "\n",
    "indexed_neighborhood_species = neighborhood_vertices[\n",
    "    neighborhood_vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE]\n",
    "    == NAPISTU_GRAPH_NODE_TYPES.SPECIES\n",
    "].set_index(\"node_orientation\")\n",
    "\n",
    "pruned_oriented_neighbors = list()\n",
    "for a_node_orientation in indexed_neighborhood_species.index.unique().tolist():\n",
    "    vertex_subset = indexed_neighborhood_species.loc[a_node_orientation]\n",
    "    if type(vertex_subset) is pd.Series:\n",
    "        # handle cases where only one entry exists to DF->series coercion occurs\n",
    "        vertex_subset = vertex_subset.to_frame().T\n",
    "\n",
    "    sorted_vertex_set = vertex_subset.sort_values(DISTANCES.PATH_WEIGHT)\n",
    "    weight_cutoff = sorted_vertex_set[DISTANCES.PATH_WEIGHT].iloc[\n",
    "        min(top_n - 1, sorted_vertex_set.shape[0] - 1)\n",
    "    ]\n",
    "\n",
    "    top_neighbors = sorted_vertex_set[\n",
    "        sorted_vertex_set[DISTANCES.PATH_WEIGHT] <= weight_cutoff\n",
    "    ][NAPISTU_GRAPH_VERTICES.NAME].tolist()\n",
    "\n",
    "    # include reactions and other species necessary to reach the top neighbors\n",
    "    # by pulling in the past solutions to weighted shortest paths problems\n",
    "    if a_node_orientation in one_neighborhood[\"neighborhood_path_entities\"].keys():\n",
    "        # path to/from focal node to each species\n",
    "        neighborhood_path_entities = one_neighborhood[\"neighborhood_path_entities\"][\n",
    "            a_node_orientation\n",
    "        ]\n",
    "\n",
    "        top_neighbors = set().union(\n",
    "            *[neighborhood_path_entities[p] for p in top_neighbors]\n",
    "        )\n",
    "\n",
    "    pruned_oriented_neighbors.append(top_neighbors)\n",
    "\n",
    "# combine all neighbors\n",
    "pruned_neighbors = set().union(*pruned_oriented_neighbors)\n",
    "\n",
    "print(\"pruned neighbors\")\n",
    "print(pruned_neighbors)\n",
    "\n",
    "pruned_vertices = neighborhood_vertices[\n",
    "    neighborhood_vertices[NAPISTU_GRAPH_VERTICES.NAME].isin(pruned_neighbors)\n",
    "].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_reactions = set(pruned_vertices.loc[pruned_vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE] == NAPISTU_GRAPH_NODE_TYPES.REACTION, NAPISTU_GRAPH_VERTICES.NAME].tolist())\n",
    "original_reactions = set(vertices.loc[vertices[NAPISTU_GRAPH_VERTICES.NODE_TYPE] == NAPISTU_GRAPH_NODE_TYPES.REACTION, NAPISTU_GRAPH_VERTICES.NAME].tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_node_orientation = \"downstream\"\n",
    "\n",
    "vertex_subset = indexed_neighborhood_species.loc[a_node_orientation]\n",
    "if type(vertex_subset) is pd.Series:\n",
    "    # handle cases where only one entry exists to DF->series coercion occurs\n",
    "    vertex_subset = vertex_subset.to_frame().T\n",
    "\n",
    "sorted_vertex_set = vertex_subset.sort_values(DISTANCES.PATH_WEIGHT)\n",
    "weight_cutoff = sorted_vertex_set[DISTANCES.PATH_WEIGHT].iloc[\n",
    "    min(top_n - 1, sorted_vertex_set.shape[0] - 1)\n",
    "]\n",
    "\n",
    "top_neighbors = sorted_vertex_set[\n",
    "    sorted_vertex_set[DISTANCES.PATH_WEIGHT] <= weight_cutoff\n",
    "][NAPISTU_GRAPH_VERTICES.NAME].tolist()\n",
    "\n",
    "# include reactions and other species necessary to reach the top neighbors\n",
    "# by pulling in the past solutions to weighted shortest paths problems\n",
    "if a_node_orientation in one_neighborhood[\"neighborhood_path_entities\"].keys():\n",
    "    # path to/from focal node to each species\n",
    "    neighborhood_path_entities = one_neighborhood[\"neighborhood_path_entities\"][\n",
    "        a_node_orientation\n",
    "    ]\n",
    "\n",
    "    top_neighbors = set().union(\n",
    "        *[neighborhood_path_entities[p] for p in top_neighbors]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??neighborhoods.find_neighborhoods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
