{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package in development mode if needed\n",
    "# !pip install -e '.[mcp]'\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import the MCP components\n",
    "from napistu.mcp.server import create_server, start_server\n",
    "from napistu.mcp import documentation, codebase, tutorials, execution\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"napistu\")\n",
    "\n",
    "# Helper function to run async code in Jupyter\n",
    "async def run_async(coro):\n",
    "    return await coro\n",
    "\n",
    "# Create a dummy session context for execution components\n",
    "session_context = {}\n",
    "object_registry = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.mcp.profiles import get_profile\n",
    "# define the types of assets to load\n",
    "profile = get_profile(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the relevant components\n",
    "mcp_server = create_server(profile)\n",
    "# initialize the relevant components\n",
    "live_server = start_server(mcp_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napistu.mcp import documentation_utils\n",
    "from napistu.mcp.constants import READMES\n",
    "from napistu.mcp.constants import NAPISTU_PY_READTHEDOCS\n",
    "from napistu.mcp.constants import NAPISTU_PY_READTHEDOCS_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/napistu/napistu/main/README.md \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Napistu\\n\\nThe Napistu project is an approach for creating and working with genome-scale mechanistic networks. Pathways of interest can be created from multiple sources (e.g., Reactome, STRING, TRRUST), aggregated across sources, and refined to add additional information. This pathway representation can then be turned into a graphical network to identify molecular neighborhoods, find paths between molecules, and to carryout network propagation.\\n\\nNapistu is an active project which we hope will be used for both simple analyses (e.g., basically replacing GSEA) as well as more complex analyses (e.g., multimodal data integration). \\n\\nWith Napistu you can:\\n\\n- Represent a range of publicly-available data sources using a common data structure, `sbml_dfs`, which is meant to faithfully encode molecular biology and biochemistry.\\n- Aggregate complementary sources into a consensus model which allows high-quality but incomplete interactions to be supported by data sources which more comprehensive yet speculative.\\n- Translate pathways models into geneome-scale graphical networks.\\n\\n**Working with Pathways**\\n\\n- Methods for visualizing pathways overlaid with experimental data.\\n- Methods for interacting with the underlying pathway networks.\\n\\nThis repository includes tutorials and documentation for the project while the following repositories contain the core packages:\\n\\n- **[napistu-py](https://github.com/napistu/napistu-py)** - Napistu Python library: the core implementations of pathway representations and network-based searches.\\n- **[napistu-r](https://github.com/napistu/napistu-r)** - Napistu R library: R-based network visualization and a few utilities called from `napitsu-py`.\\n\\nNaptisu is a rebrand and extension of [Calico Pathway Resources (CPR)](https://github.com/calico/opencpr): see [History](https://github.com/napistu/napistu/wiki/History).\\n\\n# Using Napistu\\n\\n## Tutorials\\n\\nThese tutorials are intended as stand-alone demonstrations of Napistu's core functionality. Most examples will focus on small pathways so that results can easily be reproduced by users.\\n\\n- Downloading pathway data\\n- Understanding the `sbml_dfs` format\\n- Merging networks with the `consensus` module\\n- Using the CPR Command Line Interface (CLI)\\n- Formatting `sbml_dfs` as `cpr_graph` networks\\n- Suggesting mechanisms with network approaches\\n- Adding molecule- and reaction-level information to graphs\\n- R-based network visualization\\n\\n## Examples\\n\\nWe'll include examples here of how Napistu is used in the wild to address biological questions. Stay tuned!\\n\\n## Documentation\\n\\n- For bug and issue tracking we use [Github Issues](https://github.com/napistu/napistu/issues).\\n- Napistu's core algorithms and data structures are documented on the [Napistu Wiki](https://github.com/napistu/napistu/wiki).\\n\\n# Contributing to Napistu\\n\\n- See `conventions.md` for an overview of Napistu's code conventions.\\n- Github Actions is used to test the individual R and Python repositories. Ensure that tests pass before contributing a pull request.\\n- Claude Code is used to propose fixes for straight forward issues. It is currently manually triggered:\\n\\n```bash\\n# TO DO - add environment setup directions\\ngh auth login\\n./utils/claude-pr.sh \\n```\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readmes\n",
    "readme = await run_async(documentation_utils.load_readme_content(READMES[\"napistu\"]))\n",
    "readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape read the docs, currently just focusing on the API section\n",
    "# 1. read the package overview to find the urls of the subpackages\n",
    "# 2. for each subpackage list modules\n",
    "# 3. for the main package list its modules dropping the entries for subpackages\n",
    "# 4. for each module scrape its page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from napistu.mcp.documentation_utils import _process_rtd_package_toc\n",
    "from napistu.mcp.documentation_utils import parse_rtd_module_page\n",
    "\n",
    "from types import SimpleNamespace\n",
    "PACKAGE_DEFS = SimpleNamespace(\n",
    "    NAPISTU = \"napistu\",\n",
    ")\n",
    "\n",
    "def _prune_modules_dict(modules_dict: dict) -> dict:\n",
    "\n",
    "    \"\"\"Filter the module_dict to remove links to subpackages since they are separately handled.\"\"\"\n",
    "\n",
    "    invalid_links = list()\n",
    "    for k in modules_dict[PACKAGE_DEFS.NAPISTU].keys():\n",
    "\n",
    "        if f\"{PACKAGE_DEFS.NAPISTU}.{k}\" in modules_dict.keys():\n",
    "            invalid_links.append(k)\n",
    "\n",
    "    refined_modules_dict = copy.deepcopy(modules_dict)\n",
    "    for k in invalid_links:\n",
    "        del refined_modules_dict[PACKAGE_DEFS.NAPISTU][k]\n",
    "\n",
    "    return refined_modules_dict\n",
    "\n",
    "def read_read_the_docs(package_url: str, api_url: str) -> dict:\n",
    "\n",
    "    # load top-level package TOC\n",
    "    packages_dict = await run_async(_process_rtd_package_toc(NAPISTU_PY_READTHEDOCS_API))\n",
    "\n",
    "    # load subpackage TOCs\n",
    "    modules_dict = {}\n",
    "    for package_name, package_url in packages_dict.items():\n",
    "        package_url = NAPISTU_PY_READTHEDOCS + package_url\n",
    "        modules_dict[package_name] = await run_async(_process_rtd_package_toc(package_url))\n",
    "\n",
    "    # drop links for subpackages from the main package's module list\n",
    "    pruned_models_dict = _prune_modules_dict(modules_dict)\n",
    "\n",
    "    # loop through module defs\n",
    "\n",
    "    rtd_docs_dict = dict()\n",
    "    for package in pruned_models_dict.keys():\n",
    "        \n",
    "        rtd_docs_dict[package] = dict()    \n",
    "        for module in pruned_models_dict[package]:\n",
    "\n",
    "            url = NAPISTU_PY_READTHEDOCS + \"/generated\" + pruned_models_dict[package][module]\n",
    "            page_html = await documentation_utils.load_html_page(url)\n",
    "\n",
    "            rtd_docs_dict[package][module] = parse_rtd_module_page(page_html, url)\n",
    "\n",
    "    return rtd_docs_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/api.html \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.html#module-napistu \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.html#module-napistu.network \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.html#module-napistu.ingestion \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.html#module-napistu.modify \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.rpy2.html#module-napistu.rpy2 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.gcs.html#module-napistu.gcs \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.consensus.html#module-napistu.consensus \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.constants.html#module-napistu.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.identifiers.html#module-napistu.identifiers \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.indices.html#module-napistu.indices \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.mechanism_matching.html#module-napistu.mechanism_matching \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_core.html#module-napistu.sbml_dfs_core \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_utils.html#module-napistu.sbml_dfs_utils \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.source.html#module-napistu.source \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.utils.html#module-napistu.utils \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.constants.html#module-napistu.network.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.neighborhoods.html#module-napistu.network.neighborhoods \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_create.html#module-napistu.network.net_create \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_propagation.html#module-napistu.network.net_propagation \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_utils.html#module-napistu.network.net_utils \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.paths.html#module-napistu.network.paths \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.network.precompute.html#module-napistu.network.precompute \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.bigg.html#module-napistu.ingestion.bigg \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.constants.html#module-napistu.ingestion.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.cpr_edgelist.html#module-napistu.ingestion.cpr_edgelist \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.identifiers_etl.html#module-napistu.ingestion.identifiers_etl \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.obo.html#module-napistu.ingestion.obo \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.psi_mi.html#module-napistu.ingestion.psi_mi \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.reactome.html#module-napistu.ingestion.reactome \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.sbml.html#module-napistu.ingestion.sbml \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.string.html#module-napistu.ingestion.string \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.trrust.html#module-napistu.ingestion.trrust \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.yeast.html#module-napistu.ingestion.yeast \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.constants.html#module-napistu.modify.constants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.curation.html#module-napistu.modify.curation \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.gaps.html#module-napistu.modify.gaps \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.pathwayannot.html#module-napistu.modify.pathwayannot \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/napistu.modify.uncompartmentalize.html#module-napistu.modify.uncompartmentalize \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://napistu.readthedocs.io/en/latest/generated/#napistu.rpy2.report_r_exceptions \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Client error '404 Not Found' for url 'https://napistu.readthedocs.io/en/latest/generated/#napistu.rpy2.report_r_exceptions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m pruned_models_dict[package]:\n\u001b[32m      9\u001b[39m     url = NAPISTU_PY_READTHEDOCS + \u001b[33m\"\u001b[39m\u001b[33m/generated\u001b[39m\u001b[33m\"\u001b[39m + pruned_models_dict[package][module]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     page_html = \u001b[38;5;28;01mawait\u001b[39;00m documentation_utils.load_html_page(url)\n\u001b[32m     12\u001b[39m     rtd_docs_dict[package][module] = parse_rtd_module_page(page_html, url)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GITHUB/napistu/tutorials/.venv/lib/python3.11/site-packages/napistu/mcp/documentation_utils.py:119\u001b[39m, in \u001b[36mload_html_page\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m httpx.AsyncClient() \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[32m    118\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m client.get(url)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GITHUB/napistu/tutorials/.venv/lib/python3.11/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    827\u001b[39m error_type = error_types.get(status_class, \u001b[33m\"\u001b[39m\u001b[33mInvalid status code\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'https://napistu.readthedocs.io/en/latest/generated/#napistu.rpy2.report_r_exceptions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from napistu.mcp.documentation_utils import _process_rtd_package_toc\n",
    "from napistu.mcp.documentation_utils import parse_rtd_module_page\n",
    "\n",
    "from types import SimpleNamespace\n",
    "PACKAGE_DEFS = SimpleNamespace(\n",
    "    NAPISTU = \"napistu\",\n",
    ")\n",
    "\n",
    "def _prune_modules_dict(modules_dict: dict) -> dict:\n",
    "\n",
    "    \"\"\"Filter the module_dict to remove links to subpackages since they are separately handled.\"\"\"\n",
    "\n",
    "    invalid_links = list()\n",
    "    for k in modules_dict[PACKAGE_DEFS.NAPISTU].keys():\n",
    "\n",
    "        if f\"{PACKAGE_DEFS.NAPISTU}.{k}\" in modules_dict.keys():\n",
    "            invalid_links.append(k)\n",
    "\n",
    "    refined_modules_dict = copy.deepcopy(modules_dict)\n",
    "    for k in invalid_links:\n",
    "        del refined_modules_dict[PACKAGE_DEFS.NAPISTU][k]\n",
    "\n",
    "    return refined_modules_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'napistu': {'consensus': {'module': 'napistu.consensus',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.consensus.html#module-napistu.consensus',\n",
       "   'functions': {'_add_consensus_sources': {'name': '_add_consensus_sources',\n",
       "     'signature': 'napistu.consensus._add_consensus_sources(new_id_table:DataFrame,agg_table_harmonized:DataFrame,lookup_table:Series,table_schema:dict,pw_index:PWIndex|None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._add_consensus_sources',\n",
       "     'doc': 'Add source information to the consensus table. Parameters: \\uf0c1 new_id_table: pd.DataFrame Consensus table without source information agg_table_harmonized: pd.DataFrame Original table with cluster assignments lookup_table: pd.Series Maps old IDs to new consensus IDs table_schema: dict Schema for the table pw_index: indices.PWIndex | None An index of all tables being aggregated Returns: \\uf0c1 pd.DataFrame Consensus table with source information added'},\n",
       "    '_add_entity_data': {'name': '_add_entity_data',\n",
       "     'signature': 'napistu.consensus._add_entity_data(sbml_dfs:SBML_dfs,sbml_dfs_dict:dict[str,SBML_dfs],lookup_tables:dict)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.consensus._add_entity_data',\n",
       "     'doc': 'Add entity data from component models to the consensus model. Parameters: \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs The consensus model being built sbml_dfs_dict: dict[str, sbml_dfs_core.SBML_dfs] A dictionary of SBML_dfs from different models lookup_tables: dict Dictionary of lookup tables for translating between old and new entity IDs Returns: \\uf0c1 sbml_dfs_core.SBML_dfs The updated consensus model'},\n",
       "    '_check_sbml_dfs': {'name': '_check_sbml_dfs',\n",
       "     'signature': 'napistu.consensus._check_sbml_dfs(sbml_dfs:SBML_dfs,model_label:str,N_examples:int|str=5)→None\\uf0c1',\n",
       "     'id': 'napistu.consensus._check_sbml_dfs',\n",
       "     'doc': 'Check SBML_dfs for identifiers which are associated with different entities before a merge.'},\n",
       "    '_check_sbml_dfs_dict': {'name': '_check_sbml_dfs_dict',\n",
       "     'signature': 'napistu.consensus._check_sbml_dfs_dict(sbml_dfs_dict:dict[str,SBML_dfs])→None\\uf0c1',\n",
       "     'id': 'napistu.consensus._check_sbml_dfs_dict',\n",
       "     'doc': 'Check models in SBML_dfs for problems which can be reported up-front Parameters : sbml_dfs_dict ( dict ( pd.DataFrame ) ) – a dict of sbml_dfs models; construct_consensus_model ( primarily used as an input for ) Returns : None'},\n",
       "    '_create_cluster_identifiers': {'name': '_create_cluster_identifiers',\n",
       "     'signature': 'napistu.consensus._create_cluster_identifiers(meta_identifiers:DataFrame,indexed_cluster:Series,sbml_df:DataFrame,ind_clusters:DataFrame,table_schema:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_cluster_identifiers',\n",
       "     'doc': 'Create identifier objects for each cluster. Parameters : meta_identifiers ( pd.DataFrame ) – All identifiers (including those filtered out by BQB) indexed_cluster ( pd.Series ) – Maps entity indices to cluster IDs sbml_df ( pd.DataFrame ) – Original table of entities ind_clusters ( pd.DataFrame ) – Cluster assignments from graph algorithm table_schema ( dict ) – Schema for the table, used to determine the correct identifier column name Returns : Table mapping clusters to their consensus identifiers, with the identifier column named according to the schema Return type : pd.DataFrame'},\n",
       "    '_create_consensus_entities': {'name': '_create_consensus_entities',\n",
       "     'signature': 'napistu.consensus._create_consensus_entities(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:PWIndex,defining_biological_qualifiers:list[str])→tuple[dict,dict]\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_consensus_entities',\n",
       "     'doc': 'Create consensus entities for all primary tables in the model. This helper function creates consensus compartments, species, compartmentalized species,\\nreactions, and reaction species by finding shared entities across source models. Parameters: \\uf0c1 sbml_dfs_dict: dict{cpr.SBML_dfs} A dictionary of SBML_dfs from different models pw_index: indices.PWIndex An index of all tables being aggregated defining_biological_qualifiers: list[str] Biological qualifier terms that define distinct entities Returns: \\uf0c1 tuple: dict of consensus entities tables dict of lookup tables'},\n",
       "    '_create_consensus_table': {'name': '_create_consensus_table',\n",
       "     'signature': 'napistu.consensus._create_consensus_table(agg_primary_table:DataFrame,lookup_table:Series,updated_identifiers:Series,table_schema:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_consensus_table',\n",
       "     'doc': 'Create a consensus table with merged entities. Parameters: \\uf0c1 agg_primary_table: pd.DataFrame Table of entities lookup_table: pd.Series Lookup table mapping old IDs to new IDs updated_identifiers: pd.Series Series mapping new IDs to merged identifier objects table_schema: dict Schema for the table Returns: \\uf0c1 pd.DataFrame Consensus table with one row per unique entity'},\n",
       "    '_create_entity_consensus': {'name': '_create_entity_consensus',\n",
       "     'signature': 'napistu.consensus._create_entity_consensus(membership_lookup:DataFrame,table_schema:dict)→tuple[DataFrame,Series]\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_entity_consensus',\n",
       "     'doc': 'Create consensus entities based on membership. Parameters: \\uf0c1 membership_lookup: pd.DataFrame Table mapping entities to their member strings table_schema: dict Schema for the table Returns: \\uf0c1 tuple: Consensus entities DataFrame Lookup table mapping old IDs to new IDs'},\n",
       "    '_create_entity_lookup_table': {'name': '_create_entity_lookup_table',\n",
       "     'signature': 'napistu.consensus._create_entity_lookup_table(agg_table_harmonized:DataFrame,table_schema:dict)→Series\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_entity_lookup_table',\n",
       "     'doc': 'Create a lookup table mapping original entity IDs to new consensus IDs. Parameters: \\uf0c1 agg_table_harmonized: pd.DataFrame Table with cluster assignments for each entity table_schema: dict Schema for the table Returns: \\uf0c1 pd.Series Lookup table mapping old entity IDs to new consensus IDs'},\n",
       "    '_create_member_string': {'name': '_create_member_string',\n",
       "     'signature': 'napistu.consensus._create_member_string(x:list[str])→str\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_member_string',\n",
       "     'doc': ''},\n",
       "    '_create_membership_lookup': {'name': '_create_membership_lookup',\n",
       "     'signature': 'napistu.consensus._create_membership_lookup(agg_tbl:DataFrame,table_schema:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._create_membership_lookup',\n",
       "     'doc': 'Create a lookup table for entity membership. Parameters: \\uf0c1 agg_tbl: pd.DataFrame Table with member information table_schema: dict Schema for the table Returns: \\uf0c1 pd.DataFrame Lookup table mapping entity IDs to member strings'},\n",
       "    '_filter_identifiers_by_qualifier': {'name': '_filter_identifiers_by_qualifier',\n",
       "     'signature': 'napistu.consensus._filter_identifiers_by_qualifier(meta_identifiers:DataFrame,defining_biological_qualifiers:list[str])→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._filter_identifiers_by_qualifier',\n",
       "     'doc': 'Filter identifiers to only include those with specific biological qualifiers. Parameters: \\uf0c1 meta_identifiers: pd.DataFrame Table of identifiers defining_biological_qualifiers: list[str] List of biological qualifier types to keep Returns: \\uf0c1 pd.DataFrame Filtered identifiers'},\n",
       "    '_handle_entries_without_identifiers': {'name': '_handle_entries_without_identifiers',\n",
       "     'signature': 'napistu.consensus._handle_entries_without_identifiers(sbml_df:DataFrame,valid_identifiers:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._handle_entries_without_identifiers',\n",
       "     'doc': 'Handle entities that don’t have identifiers by adding dummy identifiers. Parameters: \\uf0c1 sbml_df: pd.DataFrame Original table of entities valid_identifiers: pd.DataFrame Table of identifiers that passed filtering Returns: \\uf0c1 pd.DataFrame Valid identifiers with dummy entries added'},\n",
       "    '_merge_entity_data_create_consensus': {'name': '_merge_entity_data_create_consensus',\n",
       "     'signature': 'napistu.consensus._merge_entity_data_create_consensus(entity_data_dict:dict,lookup_table:Series,entity_schema:dict,an_entity_data_type:str,table:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._merge_entity_data_create_consensus',\n",
       "     'doc': 'Merge Entity Data - Report Mismatches Report cases where a single “new” id is associated with multiple different values of entity_var Args entity_data_dict (dict): dictionary containing all model’s “an_entity_data_type” dictionaries\\nlookup_table (pd.Series): a series where the index is an old model and primary key and the value is the new consensus id entity_schema (dict): schema for “table”\\nan_entity_data_type (str): data_type from species/reactions_data in entity_data_dict\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns : consensus_entity_data (pd.DataFrame) table where index is primary key of “table” and values are all distinct annotations from “an_entity_data_type”.'},\n",
       "    '_merge_entity_data_report_mismatches': {'name': '_merge_entity_data_report_mismatches',\n",
       "     'signature': 'napistu.consensus._merge_entity_data_report_mismatches(combined_entity_data:DataFrame,entity_schema:dict,an_entity_data_type:str,table:str)→None\\uf0c1',\n",
       "     'id': 'napistu.consensus._merge_entity_data_report_mismatches',\n",
       "     'doc': 'Merge Entity Data - Report Mismatches Report cases where a single “new” id is associated with multiple different values of entity_var Args combined_entity_data (pd.DataFrame): indexed by table primary key containing all data from “an_entity_data_type” entity_schema (dict): schema for “table”\\nan_entity_data_type (str): data_type from species/reactions_data in combined_entity_data\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns : None'},\n",
       "    '_merge_entity_identifiers': {'name': '_merge_entity_identifiers',\n",
       "     'signature': 'napistu.consensus._merge_entity_identifiers(agg_primary_table:DataFrame,lookup_table:Series,table_schema:dict)→Series\\uf0c1',\n",
       "     'id': 'napistu.consensus._merge_entity_identifiers',\n",
       "     'doc': 'Merge identifiers from multiple entities. Parameters: \\uf0c1 agg_primary_table: pd.DataFrame Table of entities lookup_table: pd.Series Lookup table mapping old IDs to new IDs table_schema: dict Schema for the table Returns: \\uf0c1 pd.Series Series mapping new IDs to merged identifier objects'},\n",
       "    '_prepare_consensus_table': {'name': '_prepare_consensus_table',\n",
       "     'signature': 'napistu.consensus._prepare_consensus_table(agg_table_harmonized:DataFrame,table_schema:dict,cluster_consensus_identifiers:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._prepare_consensus_table',\n",
       "     'doc': 'Prepare a consensus table with one row per unique entity. Parameters: \\uf0c1 agg_table_harmonized: pd.DataFrame Table with nameness scores and cluster assignments table_schema: dict Schema for the table cluster_consensus_identifiers: pd.DataFrame Consensus identifiers for each cluster Returns: \\uf0c1 pd.DataFrame New consensus table with merged entities'},\n",
       "    '_prepare_identifier_edgelist': {'name': '_prepare_identifier_edgelist',\n",
       "     'signature': 'napistu.consensus._prepare_identifier_edgelist(valid_identifiers:DataFrame,sbml_df:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._prepare_identifier_edgelist',\n",
       "     'doc': 'Prepare an edgelist for clustering identifiers. Parameters: \\uf0c1 valid_identifiers: pd.DataFrame Table of identifiers sbml_df: pd.DataFrame Original table of entities Returns: \\uf0c1 pd.DataFrame Edgelist connecting entities to their identifiers'},\n",
       "    '_prepare_member_table': {'name': '_prepare_member_table',\n",
       "     'signature': \"napistu.consensus._prepare_member_table(sbml_dfs_dict:dict[str,SBML_dfs],defined_by:str,defined_lookup_tables:dict,table_schema:dict,defined_by_schema:dict,defining_attrs:list[str],table:str='reactions')→tuple[DataFrame,str]\\uf0c1\",\n",
       "     'id': 'napistu.consensus._prepare_member_table',\n",
       "     'doc': 'Prepare a table of members and validate their structure. Parameters: \\uf0c1 sbml_dfs_dict: dict[str, sbml_dfs_core.SBML_dfs] Dictionary of SBML_dfs from different models defined_by: str Name of the table whose entries define membership defined_lookup_tables: dict Lookup tables for updating IDs table_schema: dict Schema for the main table defined_by_schema: dict Schema for the defining table defining_attrs: list[str] Attributes that define a unique member table: str Name of the main table (default: REACTIONS) Returns: \\uf0c1 tuple: Updated aggregated table with member strings Name of the foreign key'},\n",
       "    '_resolve_reversibility': {'name': '_resolve_reversibility',\n",
       "     'signature': 'napistu.consensus._resolve_reversibility(sbml_dfs_dict:dict[str,SBML_dfs],rxn_consensus_species:DataFrame,rxn_lookup_table:Series)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._resolve_reversibility',\n",
       "     'doc': 'For a set of merged reactions determine what their consensus reaction reversibilities are'},\n",
       "    '_test_same_schema': {'name': '_test_same_schema',\n",
       "     'signature': 'napistu.consensus._test_same_schema(sbml_dfs_dict:dict[str,SBML_dfs])→None\\uf0c1',\n",
       "     'id': 'napistu.consensus._test_same_schema',\n",
       "     'doc': 'Ensure that all sbml_dfs in the dict have the same schema'},\n",
       "    '_update_foreign_keys': {'name': '_update_foreign_keys',\n",
       "     'signature': 'napistu.consensus._update_foreign_keys(agg_tbl:DataFrame,table_schema:dict,fk_lookup_tables:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus._update_foreign_keys',\n",
       "     'doc': 'Update one or more foreign keys based on old-to-new foreign key lookup table(s).'},\n",
       "    '_validate_consensus_table': {'name': '_validate_consensus_table',\n",
       "     'signature': 'napistu.consensus._validate_consensus_table(new_id_table:DataFrame,sbml_df:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.consensus._validate_consensus_table',\n",
       "     'doc': 'Validate that the new consensus table has the same structure as the original. Parameters: \\uf0c1 new_id_table: pd.DataFrame Newly created consensus table sbml_df: pd.DataFrame Original table from which consensus was built Raises: \\uf0c1 ValueError If index names or columns don’t match'},\n",
       "    '_validate_meta_identifiers': {'name': '_validate_meta_identifiers',\n",
       "     'signature': 'napistu.consensus._validate_meta_identifiers(meta_identifiers:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.consensus._validate_meta_identifiers',\n",
       "     'doc': 'Flag cases where meta identifers are totally missing or BQB codes are not included'},\n",
       "    'build_consensus_identifiers': {'name': 'build_consensus_identifiers',\n",
       "     'signature': \"napistu.consensus.build_consensus_identifiers(sbml_df:DataFrame,table_schema:dict,defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→tuple[Series,DataFrame]\\uf0c1\",\n",
       "     'id': 'napistu.consensus.build_consensus_identifiers',\n",
       "     'doc': 'Build consensus identifiers by clustering entities that share biological identifiers. This function takes a set of entities spanning multiple models and finds all unique entities\\nby grouping them according to the provided biological qualifiers. It returns a mapping from\\noriginal entities to clusters and a DataFrame of consensus identifier objects for each cluster. Parameters : sbml_df ( pd.DataFrame ) – Table of entities from multiple models, with model in the index (as produced by unnest_SBML_df). table_schema ( dict ) – Schema for the table being processed. defining_biological_qualifiers ( list [ str ] , optional ) – List of biological qualifier types to use for grouping. Defaults to BQB_DEFINING_ATTRS. Returns : indexed_cluster ( pd.Series ) – Series mapping the index from sbml_df onto a set of clusters which define unique entities. cluster_consensus_identifiers_df ( pd.DataFrame ) – DataFrame mapping clusters to consensus identifiers (Identifiers objects).'},\n",
       "    'construct_consensus_model': {'name': 'construct_consensus_model',\n",
       "     'signature': 'napistu.consensus.construct_consensus_model(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:PWIndex,dogmatic:bool=True)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.consensus.construct_consensus_model',\n",
       "     'doc': 'Construct a Consensus Model by merging shared entities across pathway models. This function takes a dictionary of pathway models and merges shared entities (compartments, species, reactions, etc.)\\ninto a single consensus model, using a set of rules for entity identity and merging. Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – A dictionary of SBML_dfs objects from different models, keyed by model name. pw_index ( indices.PWIndex ) – An index of all tables being aggregated, used for cross-referencing entities. dogmatic ( bool , default=True ) – If True, preserve genes, transcripts, and proteins as separate species. If False, merge them when possible. Returns : A consensus SBML_dfs object containing the merged model. Return type : sbml_dfs_core.SBML_dfs'},\n",
       "    'construct_meta_entities_fk': {'name': 'construct_meta_entities_fk',\n",
       "     'signature': \"napistu.consensus.construct_meta_entities_fk(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:DataFrame,table:str='compartmentalized_species',fk_lookup_tables:dict={},extra_defining_attrs:list=[])→tuple[DataFrame,Series]\\uf0c1\",\n",
       "     'id': 'napistu.consensus.construct_meta_entities_fk',\n",
       "     'doc': 'Construct Meta Entities Defined by Foreign Keys Aggregating across one entity type for a set of pathway\\nmodels merge entities which are defined by their foreign keys. Parameters: \\uf0c1 sbml_df_dict: dict{“model”: cpr.SBML_dfs} A dictionary of cpr.SBML_dfs pw_index: indices.PWIndex An index of all tables being aggregated table: A table/entity set from the sbml_dfs to work-with fk_lookup_tables: dict Dictionary containing lookup tables for all foreign keys used by the table extra_defining_attrs: list List of terms which uniquely define a reaction species in addition\\nto the foreign keys. A common case is when a species is a modifier\\nand a substrate in a reaction. Returns: \\uf0c1 new_id_table: pd.DataFrame Matching the schema of one of the tables within sbml_df_dict lookup_table: pd.Series Matches the index of the aggregated entities to new_ids'},\n",
       "    'construct_meta_entities_identifiers': {'name': 'construct_meta_entities_identifiers',\n",
       "     'signature': \"napistu.consensus.construct_meta_entities_identifiers(sbml_dfs_dict:dict,pw_index:PWIndex,table:str,fk_lookup_tables:dict={},defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→tuple[DataFrame,Series]\\uf0c1\",\n",
       "     'id': 'napistu.consensus.construct_meta_entities_identifiers',\n",
       "     'doc': 'Construct meta-entities by merging entities across models that share identifiers. Aggregates a single entity type from a set of pathway models and merges entities that share identifiers\\n(as defined by the provided biological qualifiers). Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – A dictionary of SBML_dfs objects from different models, keyed by model name. pw_index ( indices.PWIndex ) – An index of all tables being aggregated. table ( str ) – The name of the table/entity set to aggregate (e.g., ‘species’, ‘compartments’). fk_lookup_tables ( dict , optional ) – Dictionary containing lookup tables for all foreign keys used by the table (default: empty dict). defining_biological_qualifiers ( list [ str ] , optional ) – List of BQB codes which define distinct entities. Defaults to BQB_DEFINING_ATTRS. Returns : new_id_table ( pd.DataFrame ) – Table matching the schema of one of the input models, with merged entities. lookup_table ( pd.Series ) – Series mapping the index of the aggregated entities to new consensus IDs.'},\n",
       "    'construct_meta_entities_members': {'name': 'construct_meta_entities_members',\n",
       "     'signature': \"napistu.consensus.construct_meta_entities_members(sbml_dfs_dict:dict[str,SBML_dfs],pw_index:PWIndex|None,table:str='reactions',defined_by:str='reaction_species',defined_lookup_tables:dict={},defining_attrs:list[str]=['sc_id','stoichiometry'])→tuple[DataFrame,Series]\\uf0c1\",\n",
       "     'id': 'napistu.consensus.construct_meta_entities_members',\n",
       "     'doc': 'Construct Meta Entities Defined by Membership Aggregating across one entity type for a set of pathway models, merge entities with the same members. Parameters: \\uf0c1 sbml_df_dict: dict{“model”: cpr.SBML_dfs} A dictionary of cpr.SBML_dfs pw_index: indices.PWIndex An index of all tables being aggregated table: str A table/entity set from the sbml_dfs to work-with defined_by: dict A table/entity set whose entries are members of “table” defined_lookup_tables: {pd.Series} Lookup table for updating the ids of “defined_by” defining_attrs: [str] A list of attributes which jointly define a unique entity Returns: \\uf0c1 new_id_table: pd.DataFrame Matching the schema of one of the tables within sbml_df_dict lookup_table: pd.Series Matches the index of the aggregated entities to new_ids'},\n",
       "    'construct_sbml_dfs_dict': {'name': 'construct_sbml_dfs_dict',\n",
       "     'signature': 'napistu.consensus.construct_sbml_dfs_dict(pw_index:DataFrame,strict:bool=True)→dict[str,SBML_dfs]\\uf0c1',\n",
       "     'id': 'napistu.consensus.construct_sbml_dfs_dict',\n",
       "     'doc': 'Construct a dictionary of SBML_dfs objects from a pathway index. This function converts all models in the pathway index into SBML_dfs objects and adds them to a dictionary.\\nOptionally, it can skip erroneous files with a warning instead of raising an error. Parameters : pw_index ( pd.DataFrame ) – An index of all tables being aggregated, containing model metadata and file paths. strict ( bool , default=True ) – If True, raise an error on any file that cannot be loaded. If False, skip erroneous files with a warning. Returns : A dictionary mapping model names to SBML_dfs objects. Return type : dict[str, sbml_dfs_core.SBML_dfs ]'},\n",
       "    'create_consensus_sources': {'name': 'create_consensus_sources',\n",
       "     'signature': 'napistu.consensus.create_consensus_sources(agg_tbl:DataFrame,lookup_table:Series,table_schema:dict,pw_index:PWIndex|None)→Series\\uf0c1',\n",
       "     'id': 'napistu.consensus.create_consensus_sources',\n",
       "     'doc': 'Create Consensus Sources Annotate the source of to-be-merged species with the models they came from, and combine with existing annotations. Parameters: \\uf0c1 agg_tbl: pd.DataFrame A table containing existing source.Source objects and a many-1\\n“new_id” of their post-aggregation consensus entity lookup_table: pd.Series A series where the index are old identifiers and the values are\\npost-aggregation new identifiers table_schema: dict Summary of the schema for the operant entitye type pw_index: indices.PWIndex An index of all tables being aggregated Returns: \\uf0c1 new_sources: pd.DataFrame Mapping where the index is new identifiers and values are aggregated source.Source objects'},\n",
       "    'merge_entity_data': {'name': 'merge_entity_data',\n",
       "     'signature': 'napistu.consensus.merge_entity_data(sbml_dfs_dict:dict[str,SBML_dfs],lookup_table:Series,table:str)→dict\\uf0c1',\n",
       "     'id': 'napistu.consensus.merge_entity_data',\n",
       "     'doc': 'Merge Entity Data Report cases where a single “new” id is associated with multiple different values of entity_var Args sbml_dfs_dict (dict): dictionary where values are to-be-merged model nnames and values are sbml_dfs_core.SBML_dfs lookup_table (pd.Series): a series where the index is an old model and primary key and the value is the new consensus id table (str): table whose data is being consolidates (currently species or reactions) Returns : dictionary containing pd.DataFrames which aggregate all of the individual entity_data tables in “sbml_dfs_dict” Return type : entity_data (dict)'},\n",
       "    'post_consensus_source_check': {'name': 'post_consensus_source_check',\n",
       "     'signature': 'napistu.consensus.post_consensus_source_check(sbml_dfs:SBML_dfs,table_name:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus.post_consensus_source_check',\n",
       "     'doc': 'Provide sources of tables in a consensus model; the output df will be used to determine whether models are merged.'},\n",
       "    'post_consensus_species_ontology_check': {'name': 'post_consensus_species_ontology_check',\n",
       "     'signature': 'napistu.consensus.post_consensus_species_ontology_check(sbml_dfs:SBML_dfs)→set[str]\\uf0c1',\n",
       "     'id': 'napistu.consensus.post_consensus_species_ontology_check',\n",
       "     'doc': 'Check and return the set of ontologies shared by different sources in a consensus model’s species table. This function examines the species table in a consensus SBML_dfs object, determines the ontologies\\npresent for each source model, and returns the intersection of ontologies shared by all sources. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The consensus SBML_dfs object containing merged species from multiple models. Returns : Set of ontology terms shared by all sources in the consensus model’s species table. Return type : set[str]'},\n",
       "    'pre_consensus_compartment_check': {'name': 'pre_consensus_compartment_check',\n",
       "     'signature': 'napistu.consensus.pre_consensus_compartment_check(sbml_dfs_dict:dict[str,SBML_dfs],tablename:str)→tuple[list,dict]\\uf0c1',\n",
       "     'id': 'napistu.consensus.pre_consensus_compartment_check',\n",
       "     'doc': 'Find compartments shared across models.'},\n",
       "    'pre_consensus_ontology_check': {'name': 'pre_consensus_ontology_check',\n",
       "     'signature': 'napistu.consensus.pre_consensus_ontology_check(sbml_dfs_dict:dict[str,SBML_dfs],tablename:str)→tuple[list,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.consensus.pre_consensus_ontology_check',\n",
       "     'doc': 'Check for shared ontologies across source models for a given table. For compartments, species, or reactions tables, this function returns the set of ontologies\\nshared among all SBML_dfs in the input dictionary, as well as a DataFrame summarizing ontologies per model. Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – Dictionary of SBML_dfs objects from different models, keyed by model name. tablename ( str ) – Name of the table to check (should be one of ‘compartments’, ‘species’, or ‘reactions’). Returns : shared_onto_list ( list ) – List of ontologies shared by all models for the specified table. sbml_dict_onto_df ( pd.DataFrame ) – DataFrame summarizing ontologies present in each model for the specified table.'},\n",
       "    'reduce_to_consensus_ids': {'name': 'reduce_to_consensus_ids',\n",
       "     'signature': \"napistu.consensus.reduce_to_consensus_ids(sbml_df:DataFrame,table_schema:dict,pw_index:PWIndex|None=None,defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→tuple[DataFrame,Series]\\uf0c1\",\n",
       "     'id': 'napistu.consensus.reduce_to_consensus_ids',\n",
       "     'doc': 'Reduce a table of entities to unique entries based on consensus identifiers. This function clusters entities that share identifiers (as defined by the provided biological qualifiers)\\nand produces a new table of unique entities, along with a lookup table mapping original entities to consensus IDs. Parameters : sbml_df ( pd.DataFrame ) – Table of entities from multiple models, with model in the index (as produced by unnest_SBML_df). table_schema ( dict ) – Schema for the table being reduced. pw_index ( indices.PWIndex , optional ) – An index of all tables being aggregated (default: None). defining_biological_qualifiers ( list [ str ] , optional ) – List of biological qualifier types which define distinct entities. Defaults to BQB_DEFINING_ATTRS. Returns : new_id_table ( pd.DataFrame ) – Table matching the schema of one of the input models, with merged entities. lookup_table ( pd.Series ) – Series mapping the index of the aggregated entities to new consensus IDs.'},\n",
       "    'report_consensus_merges': {'name': 'report_consensus_merges',\n",
       "     'signature': 'napistu.consensus.report_consensus_merges(lookup_table:Series,table_schema:dict,agg_tbl:DataFrame|None=None,sbml_dfs_dict:dict[str,SBML_dfs]|None=None,n_example_merges:int=3)→None\\uf0c1',\n",
       "     'id': 'napistu.consensus.report_consensus_merges',\n",
       "     'doc': 'Report Consensus Merges Print a summary of merges that occurred Parameters: \\uf0c1 lookup_table pd.Series An index of “model” and the entities primary key with values of new_id table_schema dict Schema of the table being merged agg_tbl pd.DataFrame or None Contains the original model, primary keys and a label. Required if the primary key is not r_id (i.e., reactions) sbml_dfs_dict pd.DataFrame or None The dict of full models across all models. Used to create reaction formulas if the primary key is r_id n_example_merges int Number of example merges to report details on Returns: \\uf0c1 None'},\n",
       "    'unnest_SBML_df': {'name': 'unnest_SBML_df',\n",
       "     'signature': 'napistu.consensus.unnest_SBML_df(sbml_dfs_dict:dict[str,SBML_dfs],table:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.consensus.unnest_SBML_df',\n",
       "     'doc': 'Unnest and concatenate a specific table from multiple SBML_dfs models. This function merges corresponding tables from a set of models into a single DataFrame,\\nadding the model name as an index level. Parameters : sbml_dfs_dict ( dict [ str , sbml_dfs_core.SBML_dfs ] ) – A dictionary of SBML_dfs objects from different models, keyed by model name. table ( str ) – The name of the table to aggregate (e.g., ‘species’, ‘reactions’, ‘compartments’). Returns : A concatenated table with a MultiIndex of model and entity ID. Return type : pd.DataFrame'}},\n",
       "   'classes': {}},\n",
       "  'constants': {'module': 'napistu.constants',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.constants.html#module-napistu.constants',\n",
       "   'functions': {'get_biological_qualifier_codes': {'name': 'get_biological_qualifier_codes',\n",
       "     'signature': 'napistu.constants.get_biological_qualifier_codes()\\uf0c1',\n",
       "     'id': 'napistu.constants.get_biological_qualifier_codes',\n",
       "     'doc': ''}},\n",
       "   'classes': {}},\n",
       "  'identifiers': {'module': 'napistu.identifiers',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.identifiers.html#module-napistu.identifiers',\n",
       "   'functions': {'_check_species_identifiers_table': {'name': '_check_species_identifiers_table',\n",
       "     'signature': \"napistu.identifiers._check_species_identifiers_table(species_identifiers:DataFrame,required_vars:set={'bqb','identifier','ontology','s_id','s_name'})\\uf0c1\",\n",
       "     'id': 'napistu.identifiers._check_species_identifiers_table',\n",
       "     'doc': ''},\n",
       "    '_count_reactome_species': {'name': '_count_reactome_species',\n",
       "     'signature': 'napistu.identifiers._count_reactome_species(reactome_series:Series)→Series\\uf0c1',\n",
       "     'id': 'napistu.identifiers._count_reactome_species',\n",
       "     'doc': 'Count the number of species tags in a set of reactome IDs'},\n",
       "    '_format_Identifiers_pubmed': {'name': '_format_Identifiers_pubmed',\n",
       "     'signature': 'napistu.identifiers._format_Identifiers_pubmed(pubmed_id:str)→Identifiers\\uf0c1',\n",
       "     'id': 'napistu.identifiers._format_Identifiers_pubmed',\n",
       "     'doc': 'Format Identifiers for a single PubMed ID. These will generally be used in an r_Identifiers field.'},\n",
       "    '_infer_primary_reactome_species': {'name': '_infer_primary_reactome_species',\n",
       "     'signature': 'napistu.identifiers._infer_primary_reactome_species(reactome_series:Series)→tuple[str,int]\\uf0c1',\n",
       "     'id': 'napistu.identifiers._infer_primary_reactome_species',\n",
       "     'doc': 'Infer the best supported species based on a set of Reactome identifiers'},\n",
       "    '_prepare_species_identifiers': {'name': '_prepare_species_identifiers',\n",
       "     'signature': 'napistu.identifiers._prepare_species_identifiers(sbml_dfs:SBML_dfs,dogmatic:bool=False,species_identifiers:DataFrame|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.identifiers._prepare_species_identifiers',\n",
       "     'doc': 'Accepts and validates species_identifiers, or extracts a fresh table if None.'},\n",
       "    '_reactome_id_species': {'name': '_reactome_id_species',\n",
       "     'signature': 'napistu.identifiers._reactome_id_species(reactome_id:str)→str\\uf0c1',\n",
       "     'id': 'napistu.identifiers._reactome_id_species',\n",
       "     'doc': 'Extract the species code from a Reactome ID'},\n",
       "    '_validate_assets_sbml_ids': {'name': '_validate_assets_sbml_ids',\n",
       "     'signature': 'napistu.identifiers._validate_assets_sbml_ids(sbml_dfs:SBML_dfs,identifiers_df:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.identifiers._validate_assets_sbml_ids',\n",
       "     'doc': 'Check an sbml_dfs file and identifiers table for inconsistencies.'},\n",
       "    '_validate_bqb': {'name': '_validate_bqb',\n",
       "     'signature': 'napistu.identifiers._validate_bqb(bqb)\\uf0c1',\n",
       "     'id': 'napistu.identifiers._validate_bqb',\n",
       "     'doc': ''},\n",
       "    'check_reactome_identifier_compatibility': {'name': 'check_reactome_identifier_compatibility',\n",
       "     'signature': 'napistu.identifiers.check_reactome_identifier_compatibility(reactome_series_a:Series,reactome_series_b:Series)→None\\uf0c1',\n",
       "     'id': 'napistu.identifiers.check_reactome_identifier_compatibility',\n",
       "     'doc': 'Check Reactome Identifier Compatibility Determine whether two sets of Reactome identifiers are from the same species. Parameters : reactome_series_a – pd.Series\\na Series containing Reactome identifiers reactome_series_b – pd.Series\\na Series containing Reactome identifiers Returns : None'},\n",
       "    'create_uri_url': {'name': 'create_uri_url',\n",
       "     'signature': 'napistu.identifiers.create_uri_url(ontology:str,identifier:str,strict:bool=True)→str\\uf0c1',\n",
       "     'id': 'napistu.identifiers.create_uri_url',\n",
       "     'doc': 'Create URI URL Convert from an identifier and ontology to a URL reference for the identifier Parameters:\\nontology (str): An ontology for organizing genes, metabolites, etc.\\nidentifier (str): A systematic identifier from the “ontology” ontology.\\nstrict (bool): if strict then throw errors for invalid IDs otherwise return None Returns:\\nurl (str): A url representing a unique identifier'},\n",
       "    'cv_to_Identifiers': {'name': 'cv_to_Identifiers',\n",
       "     'signature': 'napistu.identifiers.cv_to_Identifiers(entity)\\uf0c1',\n",
       "     'id': 'napistu.identifiers.cv_to_Identifiers',\n",
       "     'doc': 'Convert an SBML controlled vocabulary element into a cpr Identifiers object. Parameters:\\nentity: libsbml.Species An entity (species, reaction, compartment, …) with attached CV terms Returns:'},\n",
       "    'ensembl_id_to_url_regex': {'name': 'ensembl_id_to_url_regex',\n",
       "     'signature': 'napistu.identifiers.ensembl_id_to_url_regex(identifier:str,ontology:str)→tuple[str,str]\\uf0c1',\n",
       "     'id': 'napistu.identifiers.ensembl_id_to_url_regex',\n",
       "     'doc': 'Ensembl ID to URL and Regex Map an ensembl ID to a validation regex and its canonical url on ensembl Parameters : identifier – str\\nA standard identifier from ensembl genes, transcripts, or proteins ontology – str\\nThe standard ontology (ensembl_gene, ensembl_transcript, or ensembl_protein) Returns : a regex which should match a valid entry in this ontology\\nurl: the id’s url on ensembl Return type : id_regex'},\n",
       "    'format_uri': {'name': 'format_uri',\n",
       "     'signature': 'napistu.identifiers.format_uri(uri:str,biological_qualifier_type:str|None=None)→Identifiers\\uf0c1',\n",
       "     'id': 'napistu.identifiers.format_uri',\n",
       "     'doc': 'Convert a RDF URI into an Identifier object'},\n",
       "    'format_uri_url': {'name': 'format_uri_url',\n",
       "     'signature': 'napistu.identifiers.format_uri_url(uri:str)→dict\\uf0c1',\n",
       "     'id': 'napistu.identifiers.format_uri_url',\n",
       "     'doc': ''},\n",
       "    'format_uri_url_identifiers_dot_org': {'name': 'format_uri_url_identifiers_dot_org',\n",
       "     'signature': 'napistu.identifiers.format_uri_url_identifiers_dot_org(split_path:list[str])\\uf0c1',\n",
       "     'id': 'napistu.identifiers.format_uri_url_identifiers_dot_org',\n",
       "     'doc': 'Parse identifiers.org identifiers The identifiers.org identifier have two different formats:\\n1. http://identifiers.org /<ontology>/<id>\\n2. http://identifiers.org /<ontology>:<id> Currently we are identifying the newer format 2. by\\nlooking for the : in the second element of the split path. Also the ontology is converted to lower case letters. Parameters : split_path ( list [ str ] ) – split url path Returns : ontology, identifier Return type : tuple[str, str]'},\n",
       "    'merge_identifiers': {'name': 'merge_identifiers',\n",
       "     'signature': 'napistu.identifiers.merge_identifiers(identifier_series:Series)→Identifiers\\uf0c1',\n",
       "     'id': 'napistu.identifiers.merge_identifiers',\n",
       "     'doc': 'Aggregate Identifiers Merge a pd.Series of Identifiers objects into a single Identifiers object Args:\\nidentifier_series: pd.Series A pd.Series of of identifiers.Identifiers objects Returns:\\nAn identifiers.Identifiers object'},\n",
       "    'parse_ensembl_id': {'name': 'parse_ensembl_id',\n",
       "     'signature': 'napistu.identifiers.parse_ensembl_id(input_str:str)→tuple[str,str,str]\\uf0c1',\n",
       "     'id': 'napistu.identifiers.parse_ensembl_id',\n",
       "     'doc': 'Parse Ensembl ID Extract the molecule type and species name from a string containing an ensembl identifier. Parameters : input_str ( str ) – A string containing an ensembl gene, transcript, or protein identifier Returns : The substring matching the full identifier\\nmolecule_type (str): The ontology the identifier belongs to: G -> ensembl_gene T -> ensembl_transcript P -> ensembl_protein species (str): The species name the identifier belongs to Return type : identifier (str)'}},\n",
       "   'classes': {'Identifiers': {'name': 'Identifiers',\n",
       "     'signature': 'classnapistu.identifiers.Identifiers(id_list:list,verbose:bool=False)\\uf0c1',\n",
       "     'id': 'napistu.identifiers.Identifiers',\n",
       "     'doc': 'Bases: object Identifiers for a single entity or relationship. ids \\uf0c1 a list of identifiers which are each a dict containing an ontology and identifier Type : list verbose \\uf0c1 extra reporting, defaults to False Type : bool print ( ) \\uf0c1 Print a table of identifiers filter ( ontologies , summarize ) \\uf0c1 Returns a bool of whether 1+ of the ontologies was represented hoist ( ontology ) \\uf0c1 Returns value(s) from an ontology __init__ ( id_list : list , verbose : bool = False ) → None \\uf0c1 Tracks a set of identifiers and the ontologies they belong to. Parameters : id_list ( list ) – a list of identifier dictionaries containing ontology, identifier, and optionally url Return type : None. filter ( ontologies , summarize = True ) \\uf0c1 Returns a bool of whether 1+ of the ontologies was represented hoist ( ontology : str , squeeze : bool = True ) → str | list [ str ] | None \\uf0c1 Returns value(s) from an ontology Parameters : ontology ( str ) – the ontology of interest squeeze ( bool ) – if True, return a single value if possible Returns : the value(s) of an ontology of interest Return type : str or list print ( ) \\uf0c1 Print a table of identifiers',\n",
       "     'methods': {'print': {'name': 'print',\n",
       "       'signature': 'print()\\uf0c1',\n",
       "       'id': 'id2',\n",
       "       'doc': 'Print a table of identifiers'},\n",
       "      'filter': {'name': 'filter',\n",
       "       'signature': 'filter(ontologies,summarize=True)\\uf0c1',\n",
       "       'id': 'id0',\n",
       "       'doc': 'Returns a bool of whether 1+ of the ontologies was represented'},\n",
       "      'hoist': {'name': 'hoist',\n",
       "       'signature': 'hoist(ontology:str,squeeze:bool=True)→str|list[str]|None\\uf0c1',\n",
       "       'id': 'id1',\n",
       "       'doc': 'Returns value(s) from an ontology Parameters : ontology ( str ) – the ontology of interest squeeze ( bool ) – if True, return a single value if possible Returns : the value(s) of an ontology of interest Return type : str or list'},\n",
       "      '__init__': {'name': '__init__',\n",
       "       'signature': '__init__(id_list:list,verbose:bool=False)→None\\uf0c1',\n",
       "       'id': 'napistu.identifiers.Identifiers.__init__',\n",
       "       'doc': 'Tracks a set of identifiers and the ontologies they belong to. Parameters : id_list ( list ) – a list of identifier dictionaries containing ontology, identifier, and optionally url Return type : None.'}},\n",
       "     'attributes': {'ids': {'name': 'ids',\n",
       "       'signature': 'ids\\uf0c1',\n",
       "       'id': 'napistu.identifiers.Identifiers.ids',\n",
       "       'doc': 'a list of identifiers which are each a dict containing an ontology and identifier Type : list'},\n",
       "      'verbose': {'name': 'verbose',\n",
       "       'signature': 'verbose\\uf0c1',\n",
       "       'id': 'napistu.identifiers.Identifiers.verbose',\n",
       "       'doc': 'extra reporting, defaults to False Type : bool'}}},\n",
       "    '_IdentifierValidator': {'name': '_IdentifierValidator',\n",
       "     'signature': 'classnapistu.identifiers._IdentifierValidator(*,ontology:str,identifier:str,url:str|None=None,bqb:str|None=None)\\uf0c1',\n",
       "     'id': 'napistu.identifiers._IdentifierValidator',\n",
       "     'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 bqb : str | None \\uf0c1 identifier : str \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict]. ontology : str \\uf0c1 url : str | None \\uf0c1',\n",
       "     'methods': {},\n",
       "     'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "       'signature': '_abc_impl=<_abc._abc_dataobject>\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifierValidator._abc_impl',\n",
       "       'doc': ''},\n",
       "      'bqb': {'name': 'bqb',\n",
       "       'signature': 'bqb:str|None\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifierValidator.bqb',\n",
       "       'doc': ''},\n",
       "      'identifier': {'name': 'identifier',\n",
       "       'signature': 'identifier:str\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifierValidator.identifier',\n",
       "       'doc': ''},\n",
       "      'model_config': {'name': 'model_config',\n",
       "       'signature': 'model_config:ClassVar[ConfigDict]={}\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifierValidator.model_config',\n",
       "       'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'},\n",
       "      'ontology': {'name': 'ontology',\n",
       "       'signature': 'ontology:str\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifierValidator.ontology',\n",
       "       'doc': ''},\n",
       "      'url': {'name': 'url',\n",
       "       'signature': 'url:str|None\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifierValidator.url',\n",
       "       'doc': ''}}},\n",
       "    '_IdentifiersValidator': {'name': '_IdentifiersValidator',\n",
       "     'signature': 'classnapistu.identifiers._IdentifiersValidator(*,id_list:list[_IdentifierValidator])\\uf0c1',\n",
       "     'id': 'napistu.identifiers._IdentifiersValidator',\n",
       "     'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 id_list : list [ _IdentifierValidator ] \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].',\n",
       "     'methods': {},\n",
       "     'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "       'signature': '_abc_impl=<_abc._abc_dataobject>\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifiersValidator._abc_impl',\n",
       "       'doc': ''},\n",
       "      'id_list': {'name': 'id_list',\n",
       "       'signature': 'id_list:list[_IdentifierValidator]\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifiersValidator.id_list',\n",
       "       'doc': ''},\n",
       "      'model_config': {'name': 'model_config',\n",
       "       'signature': 'model_config:ClassVar[ConfigDict]={}\\uf0c1',\n",
       "       'id': 'napistu.identifiers._IdentifiersValidator.model_config',\n",
       "       'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'}}}}},\n",
       "  'indices': {'module': 'napistu.indices',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.indices.html#module-napistu.indices',\n",
       "   'functions': {'adapt_pw_index': {'name': 'adapt_pw_index',\n",
       "     'signature': 'napistu.indices.adapt_pw_index(source:str|PWIndex,species:str|Iterable[str]|None,outdir:str|None=None)→PWIndex\\uf0c1',\n",
       "     'id': 'napistu.indices.adapt_pw_index',\n",
       "     'doc': 'Adapts a pw_index Helpful to filter for species before reconstructing. Parameters : source ( str | PWIndex ) – uri for pw_index.csv file or PWIndex object species ( str ) outdir ( str | None , optional ) – Optional directory to write pw_index to.\\nDefaults to None. Returns : Filtered pw index Return type : PWIndex'}},\n",
       "   'classes': {'PWIndex': {'name': 'PWIndex',\n",
       "     'signature': 'classnapistu.indices.PWIndex(pw_index:PathLike[str]|str|DataFrame,pw_index_base_path=None,validate_paths=True)\\uf0c1',\n",
       "     'id': 'napistu.indices.PWIndex',\n",
       "     'doc': 'Bases: object Pathway Index Organizing metadata (and optionally paths) of individual pathway representations index \\uf0c1 A table describing the location and contents of pathway files. Type : pd.DataFrame base_path \\uf0c1 Path to directory of indexed files Type : str filter ( sources , species ) \\uf0c1 Filter index based on pathway source an/or category search ( query ) \\uf0c1 Filter index to pathways matching the search query __init__ ( pw_index : PathLike [ str ] | str | DataFrame , pw_index_base_path = None , validate_paths = True ) → None \\uf0c1 Tracks pathway file locations and contents. Parameters : pw_index ( str or None ) – Path to index file or a pd.DataFrame containing the contents of PWIndex.index pw_index_base_path ( str or None ) – A Path that relative paths in pw_index will reference validate_paths ( bool ) – If True then paths constructed from base_path + file will be tested for existence.\\nIf False then paths will not be validated and base_path attribute will be set to None Return type : None _check_files ( ) \\uf0c1 Verifies that all files in the pwindex are present Raises : FileNotFoundError – Error if a file not present filter ( sources : str | Iterable [ str ] | None = None , species : str | Iterable [ str ] | None = None ) \\uf0c1 Filter Pathway Index Parameters : sources ( str | Iterable [ str ] | None , optional ) – A list of valid sources or None for all species ( str | Iterable [ str ] | None , optional ) – A list of valid species or None all all search ( query ) \\uf0c1 Search Pathway Index Parameters:\\nquery: str Filter to rows of interest based on case-insensitive match to names. Returns:\\nNone',\n",
       "     'methods': {'filter': {'name': 'filter',\n",
       "       'signature': 'filter(sources:str|Iterable[str]|None=None,species:str|Iterable[str]|None=None)\\uf0c1',\n",
       "       'id': 'id0',\n",
       "       'doc': 'Filter Pathway Index Parameters : sources ( str | Iterable [ str ] | None , optional ) – A list of valid sources or None for all species ( str | Iterable [ str ] | None , optional ) – A list of valid species or None all all'},\n",
       "      'search': {'name': 'search',\n",
       "       'signature': 'search(query)\\uf0c1',\n",
       "       'id': 'id1',\n",
       "       'doc': 'Search Pathway Index Parameters:\\nquery: str Filter to rows of interest based on case-insensitive match to names. Returns:\\nNone'},\n",
       "      '__init__': {'name': '__init__',\n",
       "       'signature': '__init__(pw_index:PathLike[str]|str|DataFrame,pw_index_base_path=None,validate_paths=True)→None\\uf0c1',\n",
       "       'id': 'napistu.indices.PWIndex.__init__',\n",
       "       'doc': 'Tracks pathway file locations and contents. Parameters : pw_index ( str or None ) – Path to index file or a pd.DataFrame containing the contents of PWIndex.index pw_index_base_path ( str or None ) – A Path that relative paths in pw_index will reference validate_paths ( bool ) – If True then paths constructed from base_path + file will be tested for existence.\\nIf False then paths will not be validated and base_path attribute will be set to None Return type : None'},\n",
       "      '_check_files': {'name': '_check_files',\n",
       "       'signature': '_check_files()\\uf0c1',\n",
       "       'id': 'napistu.indices.PWIndex._check_files',\n",
       "       'doc': 'Verifies that all files in the pwindex are present Raises : FileNotFoundError – Error if a file not present'}},\n",
       "     'attributes': {'index': {'name': 'index',\n",
       "       'signature': 'index\\uf0c1',\n",
       "       'id': 'napistu.indices.PWIndex.index',\n",
       "       'doc': 'A table describing the location and contents of pathway files. Type : pd.DataFrame'},\n",
       "      'base_path': {'name': 'base_path',\n",
       "       'signature': 'base_path\\uf0c1',\n",
       "       'id': 'napistu.indices.PWIndex.base_path',\n",
       "       'doc': 'Path to directory of indexed files Type : str'}}}}},\n",
       "  'mechanism_matching': {'module': 'napistu.mechanism_matching',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.mechanism_matching.html#module-napistu.mechanism_matching',\n",
       "   'functions': {'_aggregate_grouped_columns': {'name': '_aggregate_grouped_columns',\n",
       "     'signature': \"napistu.mechanism_matching._aggregate_grouped_columns(df:DataFrame,numeric_cols,non_numeric_cols,numeric_aggregator,feature_id_var:str='feature_id',numeric_agg:str='weighted_mean')→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching._aggregate_grouped_columns',\n",
       "     'doc': 'Aggregate numeric and non-numeric columns for grouped DataFrame.\\nAssumes deduplication by feature_id within each s_id has already been performed.\\nReturns the combined DataFrame.'},\n",
       "    '_edgelist_to_scids_if_needed': {'name': '_edgelist_to_scids_if_needed',\n",
       "     'signature': 'napistu.mechanism_matching._edgelist_to_scids_if_needed(edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,ontologies:set)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.mechanism_matching._edgelist_to_scids_if_needed',\n",
       "     'doc': 'Map a set of edgelist species to cspecies or skip if cspecies were provided.'},\n",
       "    '_ensure_feature_id_var': {'name': '_ensure_feature_id_var',\n",
       "     'signature': \"napistu.mechanism_matching._ensure_feature_id_var(df:DataFrame,feature_id_var:str='feature_id')→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching._ensure_feature_id_var',\n",
       "     'doc': 'Ensure the DataFrame has a feature_id column, creating one if it doesn’t exist. Parameters : df ( pd.DataFrame ) – DataFrame to check/modify feature_id_var ( str , default=FEATURE_ID_VAR_DEFAULT ) – Name of the feature ID column Returns : DataFrame with guaranteed feature_id column Return type : pd.DataFrame'},\n",
       "    '_get_numeric_aggregator': {'name': '_get_numeric_aggregator',\n",
       "     'signature': \"napistu.mechanism_matching._get_numeric_aggregator(method:str='weighted_mean',feature_id_var:str='feature_id')→callable\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching._get_numeric_aggregator',\n",
       "     'doc': 'Get aggregation function for numeric columns with various methods. Parameters : method ( str , default=\"weighted_mean\" ) – Aggregation method to use:\\n- “weighted_mean”: weighted by inverse of feature_id frequency (default)\\n- “mean”: simple arithmetic mean\\n- “first”: first value after sorting by feature_id_var (requires feature_id_var)\\n- “max”: maximum value feature_id_var ( str , default=\"feature_id\" ) – Name of the column specifying a measured feature - used for sorting and weighting Returns : Aggregation function to use with groupby Return type : callable Raises : ValueError – If method is not recognized'},\n",
       "    '_log_feature_species_mapping_stats': {'name': '_log_feature_species_mapping_stats',\n",
       "     'signature': \"napistu.mechanism_matching._log_feature_species_mapping_stats(pathway_species:DataFrame,feature_id_var:str='feature_id')\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching._log_feature_species_mapping_stats',\n",
       "     'doc': 'Log statistics about the mapping between feature_id and s_id in the pathway_species DataFrame.'},\n",
       "    '_split_numeric_non_numeric_columns': {'name': '_split_numeric_non_numeric_columns',\n",
       "     'signature': 'napistu.mechanism_matching._split_numeric_non_numeric_columns(df:DataFrame,always_non_numeric=None)\\uf0c1',\n",
       "     'id': 'napistu.mechanism_matching._split_numeric_non_numeric_columns',\n",
       "     'doc': 'Utility to split DataFrame columns into numeric and non-numeric, always treating specified columns as non-numeric. Parameters : df ( pd.DataFrame ) – The DataFrame to split. always_non_numeric ( list or set , optional ) – Columns to always treat as non-numeric (e.g., [‘feature_id’]). Returns : numeric_cols ( pd.Index ) – Columns considered numeric (int64, float64, and not in always_non_numeric). non_numeric_cols ( pd.Index ) – Columns considered non-numeric (object, string, etc., plus always_non_numeric).'},\n",
       "    '_validate_wide_ontologies': {'name': '_validate_wide_ontologies',\n",
       "     'signature': 'napistu.mechanism_matching._validate_wide_ontologies(wide_df:DataFrame,ontologies:str|Set[str]|Dict[str,str]|None=None)→Set[str]\\uf0c1',\n",
       "     'id': 'napistu.mechanism_matching._validate_wide_ontologies',\n",
       "     'doc': 'Validate ontology specifications against the wide DataFrame and ONTOLOGIES_LIST. Parameters : wide_df ( pd.DataFrame ) – DataFrame with one column per ontology and a results column ontologies ( Optional [ Union [ str , Set [ str ] , Dict [ str , str ] ] ] ) – Either:\\n- String specifying a single ontology column\\n- Set of columns to treat as ontologies\\n- Dict mapping wide column names to ontology names\\n- None to automatically detect ontology columns based on ONTOLOGIES_LIST Returns : Set of validated ontology names. For dictionary mappings, returns the target ontology names. Return type : Set[str] Raises : ValueError – If validation fails for any ontology specification or no valid ontologies are found'},\n",
       "    'bind_wide_results': {'name': 'bind_wide_results',\n",
       "     'signature': \"napistu.mechanism_matching.bind_wide_results(sbml_dfs:SBML_dfs,results_df:DataFrame,results_name:str,ontologies:Set[str]|Dict[str,str]|None=None,dogmatic:bool=False,species_identifiers:DataFrame|None=None,feature_id_var:str='feature_id',numeric_agg:str='weighted_mean',keep_id_col:bool=True,verbose:bool=False)→SBML_dfs\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching.bind_wide_results',\n",
       "     'doc': 'Binds wide results to a sbml_dfs object. Take a table with molecular species-level attributes tied to systematic identifiers and match them to an sbml_dfs_model transferring these attributes to species_data Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The sbml_dfs object to bind the results to. results_df ( pd.DataFrame ) – The table containing the results to bind. results_name ( str ) – The name of the results to bind. ontologies ( Optional [ Union [ Set [ str ] , Dict [ str , str ] ] ] , default=None ) – Either:\\n- Set of columns to treat as ontologies (these should be entries in ONTOLOGIES_LIST )\\n- Dict mapping wide column names to ontology names in the ONTOLOGIES_LIST controlled vocabulary\\n- None to automatically detect valid ontology columns based on ONTOLOGIES_LIST dogmatic ( bool ) – Whether to respect differences between genes, transcripts, and proteins (True) or ignore them (False). species_identifiers ( Optional [ pd.DataFrame ] ) – Systematic identifiers for the molecular species “sbml_dfs”. If None this will be generate on-the-fly. feature_id_var ( str ) – The name of the column in the results_df that contains the feature identifiers. If this does not exist it will be created. numeric_agg ( str ) – The aggregation method to use for resolving degeneracy. keep_id_col ( bool ) – Whether to keep the identifier column in the results_df. verbose ( bool ) – Whether to log cases of 1-to-many and many-to-one mapping and to indicate the behavior for resolving degeneracy Returns : sbml_dfs – The sbml_dfs object with the results bound. Return type : sbml_dfs_core.SBML_dfs'},\n",
       "    'edgelist_to_pathway_species': {'name': 'edgelist_to_pathway_species',\n",
       "     'signature': \"napistu.mechanism_matching.edgelist_to_pathway_species(formatted_edgelist:DataFrame,species_identifiers:DataFrame,ontologies:set,feature_id_var:str='feature_id',verbose:bool=False)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching.edgelist_to_pathway_species',\n",
       "     'doc': 'Edgelist to Pathway Species Match an edgelist of molecular species pairs to their corresponding species in a pathway representation. Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and “identifier_downstream” variables used to to match entries species_identifiers: pd.DataFrame A table of molecular species identifiers produced from sbml_dfs.get_identifiers(“species”) generally using\\nsbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species feature_id_var: str, default=FEATURE_ID_VAR_DEFAULT Variable in “formatted_edgelist” containing feature ids verbose: bool, default=False Whether to print verbose output Returns:\\nedges_on_pathway: pd.DataFrame formatted_edgelist with upstream features mapped\\nto “s_id_upstream” and downstream species mapped\\nto “s_id_downstream”'},\n",
       "    'edgelist_to_scids': {'name': 'edgelist_to_scids',\n",
       "     'signature': 'napistu.mechanism_matching.edgelist_to_scids(formatted_edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,ontologies:set)\\uf0c1',\n",
       "     'id': 'napistu.mechanism_matching.edgelist_to_scids',\n",
       "     'doc': 'Edgelist to Compartmentalized Species IDds Map an edgelist of possible mechanistic interactions onto a\\npathadex pathway Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and\\n“identifier_downstream” variables used to to match entries sbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model species_identifiers: pd.DataFrame A table of molecular species identifiers produced from\\nsbml_dfs.get_identifiers(“species”) generally using sbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species Returns:\\nedgelist_w_scids: pd.DataFrame formatted_edgelist with upstream features mapped to “sc_id_upstream” and\\ndownstream species mapped to “sc_id_downstream”'},\n",
       "    'features_to_pathway_species': {'name': 'features_to_pathway_species',\n",
       "     'signature': \"napistu.mechanism_matching.features_to_pathway_species(feature_identifiers:DataFrame,species_identifiers:DataFrame,ontologies:set,feature_identifiers_var:str='identifier',feature_id_var:str='feature_id',expand_identifiers:bool=False,identifier_delimiter:str='/',verbose:bool=False)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching.features_to_pathway_species',\n",
       "     'doc': 'Features to Pathway Species Match a table of molecular species to their corresponding species in a pathway representation. Parameters:\\nfeature_identifiers: pd.DataFrame pd.Dataframe containing a “feature_identifiers_var” variable used to match entries species_identifiers: pd.DataFrame A table of molecular species identifiers produced from sbml_dfs.get_identifiers(“species”)\\ngenerally using sbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species feature_identifiers_var: str Variable in “feature_identifiers” containing identifiers expand_identifiers: bool, default=False If True, split identifiers in feature_identifiers_var by identifier_delimiter and explode into multiple rows identifier_delimiter: str, default=”/” Delimiter to use for splitting identifiers if expand_identifiers is True verbose: bool, default=False If True, log mapping statistics at the end of the function Returns:\\npathway_species: pd.DataFrame species_identifiers joined to feature_identifiers based on shared identifiers'},\n",
       "    'filter_to_direct_mechanistic_interactions': {'name': 'filter_to_direct_mechanistic_interactions',\n",
       "     'signature': 'napistu.mechanism_matching.filter_to_direct_mechanistic_interactions(formatted_edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,ontologies:set)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.mechanism_matching.filter_to_direct_mechanistic_interactions',\n",
       "     'doc': 'Filter to Direct Mechanistic Interactions Filter an edgelist to direct mechanistic interactions Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and “identifier_downstream” variables used to to match entries sbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model species_identifiers: pd.DataFrame A table of molecular species identifiers\\nproduced from sbml_dfs.get_identifiers(“species”) generally\\nusing sbml_dfs_core.export_sbml_dfs() ontologies: set A set of ontologies used to match features to pathway species Returns:\\nedgelist_w_direct_mechanistic_interactions: pd.DataFrame formatted_edgelist filtered to mechanistic reactions present in the pathway representation'},\n",
       "    'filter_to_indirect_mechanistic_interactions': {'name': 'filter_to_indirect_mechanistic_interactions',\n",
       "     'signature': 'napistu.mechanism_matching.filter_to_indirect_mechanistic_interactions(formatted_edgelist:DataFrame,sbml_dfs:SBML_dfs,species_identifiers:DataFrame,cpr_graph:Graph,ontologies:set,precomputed_distances=None,max_path_length=10)\\uf0c1',\n",
       "     'id': 'napistu.mechanism_matching.filter_to_indirect_mechanistic_interactions',\n",
       "     'doc': 'Filter to Indirect Mechanistic Interactions Filter an edgelist to indirect mechanistic interactions.\\nIndirect relationships are identified by searching a\\nnetwork for paths from an upstream species to a downstream species Parameters:\\nformatted_edgelist: pd.DataFrame pd.Dataframe containing a “identifier_upstream” and\\n“identifier_downstream” variables used to to match entries sbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model species_identifiers: pandas.DataFrame A table of molecular species identifiers produced from\\nsbml_dfs.get_identifiers(“species”) generally using sbml_dfs_core.export_sbml_dfs() cpr_graph: igraph.Graph A network representation of the sbml_dfs model ontologies: set A set of ontologies used to match features to pathway species precomputed_distances: None or a pd.DataFrame containing path lengths and weights between pairs of cspecies. max_path_length: int Maximum number of steps to consider. Returns:\\nedgelist_w_indirect_mechanistic_interactions: pd.DataFrame formatted_edgelist filtered to mechanistic reactions which can be described\\nby an indirect mechanism. The mechanism is described by a path weight, length,\\nand a vpath and epath list of vertices and edges which were traversed to create the path.'},\n",
       "    'match_by_ontology_and_identifier': {'name': 'match_by_ontology_and_identifier',\n",
       "     'signature': \"napistu.mechanism_matching.match_by_ontology_and_identifier(feature_identifiers:DataFrame,species_identifiers:DataFrame,ontologies:str|Set[str]|List[str],feature_identifiers_var:str='identifier',verbose:bool=False)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching.match_by_ontology_and_identifier',\n",
       "     'doc': 'Match features to pathway species based on both ontology and identifier matches.\\nPerforms separate matching for each ontology and concatenates the results. Parameters : feature_identifiers ( pd.DataFrame ) – DataFrame containing feature identifiers and results.\\nMust have columns [ontology, feature_identifiers_var, results] species_identifiers ( pd.DataFrame ) – DataFrame containing species identifiers from pathway.\\nMust have columns [ontology, identifier] ontologies ( Union [ str , Set [ str ] , List [ str ] ] ) – Ontologies to match on. Can be:\\n- A single ontology string\\n- A set of ontology strings\\n- A list of ontology strings feature_identifiers_var ( str , default=\"identifier\" ) – Name of the identifier column in feature_identifiers verbose ( bool , default=False ) – Whether to print verbose output Returns : Concatenated results of matching for each ontology.\\nContains all columns from features_to_pathway_species() Return type : pd.DataFrame Examples >>> # Match using a single ontology >>> result = match_by_ontology_and_identifier ( ... feature_identifiers = features_df , ... species_identifiers = species_df , ... ontologies = \"uniprot\" ... ) >>> # Match using multiple ontologies >>> result = match_by_ontology_and_identifier ( ... feature_identifiers = features_df , ... species_identifiers = species_df , ... ontologies = { \"uniprot\" , \"chebi\" } ... )'},\n",
       "    'match_features_to_wide_pathway_species': {'name': 'match_features_to_wide_pathway_species',\n",
       "     'signature': \"napistu.mechanism_matching.match_features_to_wide_pathway_species(wide_df:DataFrame,species_identifiers:DataFrame,ontologies:Set[str]|Dict[str,str]|None=None,feature_identifiers_var:str='identifier',feature_id_var:str='feature_id',verbose:bool=False)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching.match_features_to_wide_pathway_species',\n",
       "     'doc': 'Convert a wide-format DataFrame with multiple ontology columns to long format,\\nand match features to pathway species by ontology and identifier. Parameters : wide_df ( pd.DataFrame ) – DataFrame with ontology identifier columns and any number of results columns.\\nAll non-ontology columns are treated as results. species_identifiers ( pd.DataFrame ) – DataFrame as required by features_to_pathway_species ontologies ( Optional [ Union [ Set [ str ] , Dict [ str , str ] ] ] , default=None ) – Either:\\n- Set of columns to treat as ontologies (these should be entries in ONTOLOGIES_LIST )\\n- Dict mapping wide column names to ontology names in the ONTOLOGIES_LIST controlled vocabulary\\n- None to automatically detect valid ontology columns based on ONTOLOGIES_LIST feature_identifiers_var ( str , default=\"identifier\" ) – Name for the identifier column in the long format feature_id_var ( str , default=FEATURE_ID_VAR_DEFAULT ) – Name for the feature id column in the long format verbose ( bool , default=False ) – Whether to print verbose output Returns : Output of match_by_ontology_and_identifier Return type : pd.DataFrame Examples >>> # Example with auto-detected ontology columns and multiple results >>> wide_df = pd . DataFrame ({ ... \\'uniprot\\' : [ \\'P12345\\' , \\'Q67890\\' ], ... \\'chebi\\' : [ \\'15377\\' , \\'16810\\' ], ... \\'log2fc\\' : [ 1.0 , 2.0 ], ... \\'pvalue\\' : [ 0.01 , 0.05 ] ... }) >>> result = match_features_to_wide_pathway_species ( ... wide_df = wide_df , ... species_identifiers = species_identifiers ... ) >>> # Example with custom ontology mapping >>> wide_df = pd . DataFrame ({ ... \\'protein_id\\' : [ \\'P12345\\' , \\'Q67890\\' ], ... \\'compound_id\\' : [ \\'15377\\' , \\'16810\\' ], ... \\'expression\\' : [ 1.0 , 2.0 ], ... \\'confidence\\' : [ 0.8 , 0.9 ] ... }) >>> result = match_features_to_wide_pathway_species ( ... wide_df = wide_df , ... species_identifiers = species_identifiers , ... ontologies = { \\'protein_id\\' : \\'uniprot\\' , \\'compound_id\\' : \\'chebi\\' } ... )'},\n",
       "    'resolve_matches': {'name': 'resolve_matches',\n",
       "     'signature': \"napistu.mechanism_matching.resolve_matches(matched_data:DataFrame,feature_id_var:str='feature_id',index_col:str='s_id',numeric_agg:str='weighted_mean',keep_id_col:bool=True)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.mechanism_matching.resolve_matches',\n",
       "     'doc': 'Resolve many-to-1 and 1-to-many matches in matched data. Parameters : matched_data ( pd.DataFrame ) – DataFrame containing matched data with columns:\\n- feature_id_var: identifier column (e.g. feature_id)\\n- index_col: index column (e.g. s_id)\\n- other columns: data columns to be aggregated feature_id_var ( str , default=\"feature_id\" ) – Name of the identifier column index_col ( str , default=\"s_id\" ) – Name of the column to use as index numeric_agg ( str , default=\"weighted_mean\" ) – Method to aggregate numeric columns:\\n- “weighted_mean”: weighted by inverse of feature_id frequency (default)\\n- “mean”: simple arithmetic mean\\n- “first”: first value after sorting by feature_id_var (requires feature_id_var)\\n- “max”: maximum value keep_id_col ( bool , default=True ) – Whether to keep and rollup the feature_id_var in the output.\\nIf False, feature_id_var will be dropped from the output. Returns : DataFrame with resolved matches:\\n- Many-to-1: numeric columns are aggregated using specified method\\n- 1-to-many: adds a count column showing number of matches\\n- Index is set to index_col and named accordingly Return type : pd.DataFrame Raises : KeyError – If feature_id_var is not present in the DataFrame TypeError – If DataFrame contains unsupported data types (boolean or datetime)'}},\n",
       "   'classes': {}},\n",
       "  'sbml_dfs_core': {'module': 'napistu.sbml_dfs_core',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_core.html#module-napistu.sbml_dfs_core',\n",
       "   'functions': {'_sbml_dfs_from_edgelist_check_cspecies_merge': {'name': '_sbml_dfs_from_edgelist_check_cspecies_merge',\n",
       "     'signature': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_check_cspecies_merge(merged_species:DataFrame,original_species:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_check_cspecies_merge',\n",
       "     'doc': 'Check for a mismatch between the provided species data and species implied by the edgelist.'},\n",
       "    '_sbml_dfs_from_edgelist_validate_inputs': {'name': '_sbml_dfs_from_edgelist_validate_inputs',\n",
       "     'signature': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_validate_inputs(interaction_edgelist:DataFrame,species_df:DataFrame,compartments_df:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core._sbml_dfs_from_edgelist_validate_inputs',\n",
       "     'doc': 'Check that the inputs for creating an SBML_dfs from an edgelist are appropriate.'},\n",
       "    '_stub_compartments': {'name': '_stub_compartments',\n",
       "     'signature': \"napistu.sbml_dfs_core._stub_compartments(stubbed_compartment:str='CELLULAR_COMPONENT')→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.sbml_dfs_core._stub_compartments',\n",
       "     'doc': 'Stub Compartments Create a compartments table with only a single compartment Args:\\nstubbed_compartment (str): the name of a compartment which should match the keys in constants.COMPARTMENTS and constants.COMPARTMENTS_GO_TERMS Returns:\\ncompartments_df (pd.DataFrame): compartments dataframe'},\n",
       "    '_validate_matching_data': {'name': '_validate_matching_data',\n",
       "     'signature': 'napistu.sbml_dfs_core._validate_matching_data(data_table:DataFrame,ref_table:DataFrame)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core._validate_matching_data',\n",
       "     'doc': 'Validates a table against a reference This check if the table has the same index, no duplicates in the index\\nand that all values in the index are in the reference table. Parameters : data_table ( pd.DataFrame ) – a table with data that should\\nmatch the reference ref_table ( pd.DataFrame ) – a reference table Raises : ValueError – not same index name ValueError – index contains duplicates ValueError – index not subset of index of reactions table'},\n",
       "    'add_stoi_to_species_name': {'name': 'add_stoi_to_species_name',\n",
       "     'signature': 'napistu.sbml_dfs_core.add_stoi_to_species_name(stoi:float|int,name:str)→str\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.add_stoi_to_species_name',\n",
       "     'doc': 'Add Stoi To Species Name Add # of molecules to a species name Parameters: \\uf0c1 stoi: float or int Number of molecules name: str Name of species Returns: \\uf0c1 name: str Name containing number of species'},\n",
       "    'construct_formula_string': {'name': 'construct_formula_string',\n",
       "     'signature': 'napistu.sbml_dfs_core.construct_formula_string(reaction_species_df:DataFrame,reactions_df:DataFrame,name_var:str)→str\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.construct_formula_string',\n",
       "     'doc': 'Construct Formula String Convert a table of reaction species into a formula string Parameters: \\uf0c1 reaction_species_df: pd.DataFrame Table containing a reactions’ species reactions_df: pd.DataFrame smbl.reactions name_var: str Name used to label species Returns: \\uf0c1 formula_str: str String representation of a reactions substrates, products and\\nmodifiers'},\n",
       "    'export_sbml_dfs': {'name': 'export_sbml_dfs',\n",
       "     'signature': 'napistu.sbml_dfs_core.export_sbml_dfs(model_prefix:str,sbml_dfs:SBML_dfs,outdir:str,overwrite:bool=False,dogmatic:bool=True)→None\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.export_sbml_dfs',\n",
       "     'doc': 'Export SBML_dfs Export summaries of species identifiers and each table underlying\\nan SBML_dfs pathway model Params \\uf0c1 model_prefix: str Label to prepend to all exported files sbml_dfs: sbml.SBML_dfs A pathway model outdir: str Path to an existing directory where results should be saved overwrite: bool Should the directory be overwritten if it already exists? dogmatic: bool If True then treat genes, transcript, and proteins as separate species. If False\\nthen treat them interchangeably. rtype : None'},\n",
       "    'filter_to_characteristic_species_ids': {'name': 'filter_to_characteristic_species_ids',\n",
       "     'signature': \"napistu.sbml_dfs_core.filter_to_characteristic_species_ids(species_ids:DataFrame,max_complex_size:int=4,max_promiscuity:int=20,defining_biological_qualifiers:list[str]=['BQB_IS','IS_HOMOLOG_TO'])→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.sbml_dfs_core.filter_to_characteristic_species_ids',\n",
       "     'doc': 'Filter to Characteristic Species IDs Remove identifiers corresponding to one component within a large protein\\ncomplexes and non-characteristic annotations such as pubmed references and\\nhomologues. Parameters : species_ids ( pd.DataFrame ) – A table of identifiers produced by sdbml_dfs.get_identifiers(“species”) max_complex_size ( int ) – The largest size of a complex, where BQB_HAS_PART terms will be retained.\\nIn most cases, complexes are handled with specific formation and\\ndissolutation reactions,but these identifiers will be pulled in when\\nsearching by identifiers or searching the identifiers associated with a\\nspecies against an external resource such as Open Targets. max_promiscuity ( int ) – Maximum number of species where a single molecule can act as a\\nBQB_HAS_PART component associated with a single identifier (and common ontology). ( list [ str ] ) ( defining_biological_qualifiers ) – BQB codes which define distinct entities. Narrowly this would be BQB_IS, while more\\npermissive settings would include homologs, different forms of the same gene. Returns -------- species_id ( pd.DataFrame ) – Input species filtered to characteristic identifiers'},\n",
       "    'find_underspecified_reactions': {'name': 'find_underspecified_reactions',\n",
       "     'signature': 'napistu.sbml_dfs_core.find_underspecified_reactions(sbml_dfs:SBML_dfs,sc_ids:Iterable[str])→set[str]\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.find_underspecified_reactions',\n",
       "     'doc': 'Find Underspecified reactions Identity reactions which should be removed if a set of molecular species are removed\\nfrom the system. Params:\\nsbml_dfs (SBML_dfs): A pathway representation sc_ids (list[str]) A list of compartmentalized species ids (sc_ids) which will be removed. Returns:\\nunderspecified_reactions (set[str]): A list of reactions which should be removed because they will not occur once\\n“sc_ids” are removed.'},\n",
       "    'infer_sbo_terms': {'name': 'infer_sbo_terms',\n",
       "     'signature': 'napistu.sbml_dfs_core.infer_sbo_terms(sbml_dfs:SBML_dfs)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.infer_sbo_terms',\n",
       "     'doc': 'Infer SBO Terms Define SBO terms based on stoichiometry for reaction_species with missing terms Parameters: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model Returns: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model (with missing/invalid reaction species sbo_terms resolved)'},\n",
       "    'infer_uncompartmentalized_species_location': {'name': 'infer_uncompartmentalized_species_location',\n",
       "     'signature': 'napistu.sbml_dfs_core.infer_uncompartmentalized_species_location(sbml_dfs:SBML_dfs)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.infer_uncompartmentalized_species_location',\n",
       "     'doc': 'Infer Uncompartmentalized Species Location If the compartment of a subset of compartmentalized species\\nwas not specified, infer an appropriate compartment from\\nother members of reactions they particpate in Parameters: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model Returns: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational pathway model (with filled in species compartments)'},\n",
       "    'name_compartmentalized_species': {'name': 'name_compartmentalized_species',\n",
       "     'signature': 'napistu.sbml_dfs_core.name_compartmentalized_species(sbml_dfs)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.name_compartmentalized_species',\n",
       "     'doc': 'Name Compartmentalized Species Rename compartmentalized species if they have the same\\nname as their species Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways Returns ---------- sbml_dfs'},\n",
       "    'reaction_summaries': {'name': 'reaction_summaries',\n",
       "     'signature': 'napistu.sbml_dfs_core.reaction_summaries(sbml_dfs:SBML_dfs,r_ids=None)→Series\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.reaction_summaries',\n",
       "     'doc': 'Reaction Summary Return human-readable formulas for reactions. Parameters: \\uf0c1 sbml_dfs: sbml.SBML_dfs A relational mechanistic model r_ids: [str], str or None Reaction IDs or None for all reactions Returns: \\uf0c1 formula_strs: pd.Series'},\n",
       "    'reaction_summary': {'name': 'reaction_summary',\n",
       "     'signature': 'napistu.sbml_dfs_core.reaction_summary(r_id:str,sbml_dfs:SBML_dfs)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.reaction_summary',\n",
       "     'doc': 'Reaction Summary Return a reaction’s name and a human-readable formula. Parameters:\\nr_id: str A reaction ID sbml_dfs: SBML_dfs Returns:\\none row pd.DataFrame'},\n",
       "    'sbml_dfs_from_edgelist': {'name': 'sbml_dfs_from_edgelist',\n",
       "     'signature': \"napistu.sbml_dfs_core.sbml_dfs_from_edgelist(interaction_edgelist:DataFrame,species_df:DataFrame,compartments_df:DataFrame,interaction_source:Source,upstream_stoichiometry:int=0,downstream_stoichiometry:int=1,downstream_sbo_name:str='product',keep_species_data:bool|str=False,keep_reactions_data:bool|str=False)→SBML_dfs\\uf0c1\",\n",
       "     'id': 'napistu.sbml_dfs_core.sbml_dfs_from_edgelist',\n",
       "     'doc': 'Create SBML_dfs from Edgelist Combine a set of interactions into an sbml.SBML_dfs mechanistic model Parameters:\\ninteraction_edgelist (pd.DataFrame): A table containing interactions: upstream_name (str): matching “s_name” from “species_df” downstream_name (str): matching “s_name” from “species_df” upstream_compartment (str): compartment of “upstream_name” with names matching “c_name” from “compartments_df” downstream_compartment (str): compartment of “downstream_name” with names matching “c_name” from “compartments_df” r_name (str): a name for the interaction sbo_term (str): sbo term defining the type of molecular interaction (see MINI_SBO_FROM_NAME) r_Identifiers (identifiers.Identifiers): identifiers supporting the interaction (e.g., pubmed ids) r_isreversible (bool): Is this reaction reversible? If True, the reaction is reversible\\nBy default, the interactions of TRRUST networks are irreversible, and reversible for STRING networks species_df (pd.DataFrame): A table defining unique molecular species participating in “interaction_edgelist”:\\n- s_name (str): name of molecular species\\n- s_Identifiers (identifiers.Identifiers): identifiers defining the species compartments_df (pd.DataFrame): A table defining compartments where interactions are occurring “interaction_edgelist”:\\n- c_name (str): name of compartment\\n- c_Identifiers (identifiers.Identifiers): identifiers defining the compartment (see\\nbigg.annotate_recon() for a set of names > go categories) interaction_source (source.Source): A source object which will tie model entities to the interaction source upstream_stoichiometry (int): stoichiometry of upstream species in reaction downstream_stoichiometry (int): stoichiometry of downstream species in reaction downstream_sbo_name (str): sbo term defining the type of molecular interaction for the downstream reactand\\n(see MINI_SBO_FROM_NAME) keep_species_data (bool | str): Should species data be kept in the model? If True, all species data will be kept\\nand saved as “species_data” in the SBML_dfs. The label will be ‘source’\\nIf False, no species data will be kept.\\nIf a string: label for the species data to be kept. keep_reactions_data (bool | str): Should reaction data be kept in the model? If True, all reaction data will be kept and saved\\nas “reactions_data” in the SBML_dfs. The label will be ‘source’.\\nIf False, no reaction data will be kept.\\nIf a string: label for the reaction data to be kept. Returns:\\nsbml.SBML_dfs'},\n",
       "    'species_status': {'name': 'species_status',\n",
       "     'signature': 'napistu.sbml_dfs_core.species_status(s_id:str,sbml_dfs:SBML_dfs)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.species_status',\n",
       "     'doc': 'Species Status Return all of the reaction’s a species particpates in. Parameters:\\ns_id: str A species ID sbml_dfs: SBML_dfs Returns:\\npd.DataFrame, one row reaction'},\n",
       "    'species_type_types': {'name': 'species_type_types',\n",
       "     'signature': 'napistu.sbml_dfs_core.species_type_types(x)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.species_type_types',\n",
       "     'doc': 'Assign a high-level molecule type to a molecular species'},\n",
       "    'stub_ids': {'name': 'stub_ids',\n",
       "     'signature': 'napistu.sbml_dfs_core.stub_ids(ids)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.stub_ids',\n",
       "     'doc': ''}},\n",
       "   'classes': {'SBML_dfs': {'name': 'SBML_dfs',\n",
       "     'signature': 'classnapistu.sbml_dfs_core.SBML_dfs(sbml_model:SBML|MutableMapping[str,DataFrame|dict[str,DataFrame]],validate:bool=True,resolve:bool=True)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_core.SBML_dfs',\n",
       "     'doc': 'Bases: object System Biology Markup Language Model Data Frames. compartments \\uf0c1 sub-cellular compartments in the model Type : pd.DataFrame species \\uf0c1 molecular species in the model Type : pd.DataFrame species_data \\uf0c1 DataFrames with additional data and index = species_id Type : Dict[str, pd.DataFrame]: Additional data for species. reactions \\uf0c1 reactions in the model Type : pd.DataFrame reactions_data \\uf0c1 DataFrames with additional data and index = reaction_id Type : Dict[str, pd.DataFrame]: Additional data for reactions. reaction_species \\uf0c1 One entry per species participating in a reaction Type : pd.DataFrame schema \\uf0c1 dictionary reprenting the structure of the other attributes and meaning of their variables Type : dict get_table ( entity_type , required_attributes ) \\uf0c1 Get a table from the SBML_dfs object and optionally validate that it contains a set of required attributes search_by_ids ( ids , entity_type , identifiers_df , ontologies ) \\uf0c1 Pull out identifiers and entities matching a set of query ids which optionally match a set of ontologies search_by_name ( name , entity_type , partial_match ) \\uf0c1 Pull out a set of entities by name or partial string match [default] get_cspecies_features ( ) \\uf0c1 Returns additional attributes of compartmentalized species get_species_features ( ) \\uf0c1 Returns additional attributes of species get_identifiers ( id_type ) \\uf0c1 Returns a DataFrame containing identifiers from the id_type table get_uri_urls ( entity_type , entity_ids = None ) \\uf0c1 Returns a Series containing reference urls for each entity validate ( ) \\uf0c1 Validate that the sbml_dfs follows the schema and identify clear pathologies validate_and_rec ( ) \\uf0c1 Validate the sbml_dfs and attempt to automatically resolve common issues __init__ ( sbml_model : SBML | MutableMapping [ str , DataFrame | dict [ str , DataFrame ] ] , validate : bool = True , resolve : bool = True ) → None \\uf0c1 Creates a pathway Parameters : sbml_model ( cpr.SBML or a dict containing tables following the sbml_dfs schema ) – A SBML model produced by cpr.SBML(). ( bool ) ( resolve ) ( bool ) Return type : None. _attempt_resolve ( e ) \\uf0c1 _get_unused_cspecies ( ) → set [ str ] \\uf0c1 Returns a set of compartmentalized species\\nthat are not part of any reactions _get_unused_species ( ) → set [ str ] \\uf0c1 Returns a list of species that are not part of any reactions _remove_compartmentalized_species ( sc_ids : Iterable [ str ] ) \\uf0c1 Removes compartmentalized species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. Parameters : sc_ids ( Iterable [ str ] ) – the compartmentalized species to remove _remove_species ( s_ids : Iterable [ str ] ) \\uf0c1 Removes species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. This removes the species and corresponding compartmentalized species and\\nreactions_species. Parameters : s_ids ( Iterable [ str ] ) – the species to remove _remove_unused_cspecies ( ) \\uf0c1 Removes compartmentalized species that are no\\nlonger part of any reactions _remove_unused_species ( ) \\uf0c1 Removes species that are no longer part of any\\ncompartmentalized species _validate_reaction_species ( ) \\uf0c1 _validate_reactions_data ( reactions_data_table : DataFrame ) \\uf0c1 Validates reactions data attribute Parameters : reactions_data_table ( pd.DataFrame ) – a reactions data table Raises : ValueError – r_id not index name ValueError – r_id index contains duplicates ValueError – r_id not in reactions table _validate_species_data ( species_data_table : DataFrame ) \\uf0c1 Validates species data attribute Parameters : species_data_table ( pd.DataFrame ) – a species data table Raises : ValueError – s_id not index name ValueError – s_id index contains duplicates ValueError – s_id not in species table add_reactions_data ( label : str , data : DataFrame ) \\uf0c1 Adds additional reaction_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with reactions add_species_data ( label : str , data : DataFrame ) \\uf0c1 Adds additional species_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with species get_cspecies_features ( ) → DataFrame \\uf0c1 get_identifiers ( id_type ) → DataFrame \\uf0c1 get_network_summary ( ) → Mapping [ str , Any ] \\uf0c1 Return diagnostic statistics about the network Returns : A dictionary of diagnostic statistics with entries: n_species_types [int]: Number of species types\\ndict_n_species_per_type [dict[str, int]]: Number of species per species type n_species [int]: Number of species\\nn_cspecies [int]: Number of compartmentalized species\\nn_reaction_species [int]: Number of reaction species\\nn_reactions [int]: Number of reactions\\nn_compartments [int]: Number of compartments\\ndict_n_species_per_compartment [dict[str, int]]: Number of species per compartment stats_species_per_reaction [dict[str, float]]: Statistics on the number of reactands per reaction top10_species_per_reaction [list[dict[str, Any]]]: Top 10 reactions with highest number of reactands stats_degree [dict[str, float]]: Statistics on the degree of a species (number of reactions it is involved in) top10_degree [list[dict[str, Any]]]: Top 10 species with highest degree stats_identifiers_per_species [dict[str, float]]: Statistics on the number of identifiers per species top10_identifiers_per_species [list[dict[str, Any]]]: Top 10 species with highest number of identifiers Return type : Mapping[str, Any] get_species_features ( ) → DataFrame \\uf0c1 get_table ( entity_type : str , required_attributes : None | set [ str ] = None ) → DataFrame \\uf0c1 Get Table Get a table from the SBML_dfs object and optionally validate that it contains a set of required attributes. get_uri_urls ( entity_type : str , entity_ids : Iterable [ str ] | None = None , required_ontology : str | None = None ) → Series \\uf0c1 remove_compartmentalized_species ( sc_ids : Iterable [ str ] ) \\uf0c1 Starting with a set of compartmentalized species determine which reactions should be removed\\nbased on there removal. Then remove these reactions, compartmentalized species, and species. remove_reactions ( r_ids : Iterable [ str ] , remove_species : bool = False ) \\uf0c1 Removes reactions from the model Parameters : r_ids ( List [ str ] ) – the reactions to remove remove_species ( bool , optional ) – whether to remove species that are no longer\\npart of any reactions. Defaults to False. search_by_ids ( ids : list [ str ] , entity_type : str , identifiers_df : DataFrame , ontologies : None | set [ str ] = None ) → tuple [ DataFrame , DataFrame ] \\uf0c1 search_by_name ( name : str , entity_type : str , partial_match : bool = True ) → DataFrame \\uf0c1 validate ( ) \\uf0c1 Validates the object for obvious errors validate_and_resolve ( ) \\uf0c1 Call validate and try to iteratively resolve common validation errors _optional_entities : set [ str ] \\uf0c1 _required_entities : set [ str ] \\uf0c1 compartments : DataFrame \\uf0c1 reaction_species : DataFrame \\uf0c1 reactions : DataFrame \\uf0c1 reactions_data : dict [ str , DataFrame ] \\uf0c1 schema : dict \\uf0c1 species : DataFrame \\uf0c1 species_data : dict [ str , DataFrame ] \\uf0c1',\n",
       "     'methods': {'get_table': {'name': 'get_table',\n",
       "       'signature': 'get_table(entity_type:str,required_attributes:None|set[str]=None)→DataFrame\\uf0c1',\n",
       "       'id': 'id3',\n",
       "       'doc': 'Get Table Get a table from the SBML_dfs object and optionally validate that it contains a set of required attributes.'},\n",
       "      'search_by_ids': {'name': 'search_by_ids',\n",
       "       'signature': 'search_by_ids(ids:list[str],entity_type:str,identifiers_df:DataFrame,ontologies:None|set[str]=None)→tuple[DataFrame,DataFrame]\\uf0c1',\n",
       "       'id': 'id5',\n",
       "       'doc': ''},\n",
       "      'search_by_name': {'name': 'search_by_name',\n",
       "       'signature': 'search_by_name(name:str,entity_type:str,partial_match:bool=True)→DataFrame\\uf0c1',\n",
       "       'id': 'id6',\n",
       "       'doc': ''},\n",
       "      'get_cspecies_features': {'name': 'get_cspecies_features',\n",
       "       'signature': 'get_cspecies_features()→DataFrame\\uf0c1',\n",
       "       'id': 'id0',\n",
       "       'doc': ''},\n",
       "      'get_species_features': {'name': 'get_species_features',\n",
       "       'signature': 'get_species_features()→DataFrame\\uf0c1',\n",
       "       'id': 'id2',\n",
       "       'doc': ''},\n",
       "      'get_identifiers': {'name': 'get_identifiers',\n",
       "       'signature': 'get_identifiers(id_type)→DataFrame\\uf0c1',\n",
       "       'id': 'id1',\n",
       "       'doc': ''},\n",
       "      'get_uri_urls': {'name': 'get_uri_urls',\n",
       "       'signature': 'get_uri_urls(entity_type:str,entity_ids:Iterable[str]|None=None,required_ontology:str|None=None)→Series\\uf0c1',\n",
       "       'id': 'id4',\n",
       "       'doc': ''},\n",
       "      'validate': {'name': 'validate',\n",
       "       'signature': 'validate()\\uf0c1',\n",
       "       'id': 'id7',\n",
       "       'doc': 'Validates the object for obvious errors'},\n",
       "      'validate_and_rec': {'name': 'validate_and_rec',\n",
       "       'signature': 'validate_and_rec()\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.validate_and_rec',\n",
       "       'doc': 'Validate the sbml_dfs and attempt to automatically resolve common issues'},\n",
       "      '__init__': {'name': '__init__',\n",
       "       'signature': '__init__(sbml_model:SBML|MutableMapping[str,DataFrame|dict[str,DataFrame]],validate:bool=True,resolve:bool=True)→None\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.__init__',\n",
       "       'doc': 'Creates a pathway Parameters : sbml_model ( cpr.SBML or a dict containing tables following the sbml_dfs schema ) – A SBML model produced by cpr.SBML(). ( bool ) ( resolve ) ( bool ) Return type : None.'},\n",
       "      '_attempt_resolve': {'name': '_attempt_resolve',\n",
       "       'signature': '_attempt_resolve(e)\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._attempt_resolve',\n",
       "       'doc': ''},\n",
       "      '_get_unused_cspecies': {'name': '_get_unused_cspecies',\n",
       "       'signature': '_get_unused_cspecies()→set[str]\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._get_unused_cspecies',\n",
       "       'doc': 'Returns a set of compartmentalized species\\nthat are not part of any reactions'},\n",
       "      '_get_unused_species': {'name': '_get_unused_species',\n",
       "       'signature': '_get_unused_species()→set[str]\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._get_unused_species',\n",
       "       'doc': 'Returns a list of species that are not part of any reactions'},\n",
       "      '_remove_compartmentalized_species': {'name': '_remove_compartmentalized_species',\n",
       "       'signature': '_remove_compartmentalized_species(sc_ids:Iterable[str])\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_compartmentalized_species',\n",
       "       'doc': 'Removes compartmentalized species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. Parameters : sc_ids ( Iterable [ str ] ) – the compartmentalized species to remove'},\n",
       "      '_remove_species': {'name': '_remove_species',\n",
       "       'signature': '_remove_species(s_ids:Iterable[str])\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_species',\n",
       "       'doc': 'Removes species from the model This should not be directly used by the user, as it can lead to\\ninvalid reactions when removing species without a logic to decide\\nif the reaction needs to be removed as well. This removes the species and corresponding compartmentalized species and\\nreactions_species. Parameters : s_ids ( Iterable [ str ] ) – the species to remove'},\n",
       "      '_remove_unused_cspecies': {'name': '_remove_unused_cspecies',\n",
       "       'signature': '_remove_unused_cspecies()\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_unused_cspecies',\n",
       "       'doc': 'Removes compartmentalized species that are no\\nlonger part of any reactions'},\n",
       "      '_remove_unused_species': {'name': '_remove_unused_species',\n",
       "       'signature': '_remove_unused_species()\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._remove_unused_species',\n",
       "       'doc': 'Removes species that are no longer part of any\\ncompartmentalized species'},\n",
       "      '_validate_reaction_species': {'name': '_validate_reaction_species',\n",
       "       'signature': '_validate_reaction_species()\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._validate_reaction_species',\n",
       "       'doc': ''},\n",
       "      '_validate_reactions_data': {'name': '_validate_reactions_data',\n",
       "       'signature': '_validate_reactions_data(reactions_data_table:DataFrame)\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._validate_reactions_data',\n",
       "       'doc': 'Validates reactions data attribute Parameters : reactions_data_table ( pd.DataFrame ) – a reactions data table Raises : ValueError – r_id not index name ValueError – r_id index contains duplicates ValueError – r_id not in reactions table'},\n",
       "      '_validate_species_data': {'name': '_validate_species_data',\n",
       "       'signature': '_validate_species_data(species_data_table:DataFrame)\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._validate_species_data',\n",
       "       'doc': 'Validates species data attribute Parameters : species_data_table ( pd.DataFrame ) – a species data table Raises : ValueError – s_id not index name ValueError – s_id index contains duplicates ValueError – s_id not in species table'},\n",
       "      'add_reactions_data': {'name': 'add_reactions_data',\n",
       "       'signature': 'add_reactions_data(label:str,data:DataFrame)\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.add_reactions_data',\n",
       "       'doc': 'Adds additional reaction_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with reactions'},\n",
       "      'add_species_data': {'name': 'add_species_data',\n",
       "       'signature': 'add_species_data(label:str,data:DataFrame)\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.add_species_data',\n",
       "       'doc': 'Adds additional species_data with validation Parameters : label ( str ) – the label for the new data data ( pd.DataFrame ) – the data Raises : ValueError – if the data is not valid, ie does not match with species'},\n",
       "      'get_network_summary': {'name': 'get_network_summary',\n",
       "       'signature': 'get_network_summary()→Mapping[str,Any]\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.get_network_summary',\n",
       "       'doc': 'Return diagnostic statistics about the network Returns : A dictionary of diagnostic statistics with entries: n_species_types [int]: Number of species types\\ndict_n_species_per_type [dict[str, int]]: Number of species per species type n_species [int]: Number of species\\nn_cspecies [int]: Number of compartmentalized species\\nn_reaction_species [int]: Number of reaction species\\nn_reactions [int]: Number of reactions\\nn_compartments [int]: Number of compartments\\ndict_n_species_per_compartment [dict[str, int]]: Number of species per compartment stats_species_per_reaction [dict[str, float]]: Statistics on the number of reactands per reaction top10_species_per_reaction [list[dict[str, Any]]]: Top 10 reactions with highest number of reactands stats_degree [dict[str, float]]: Statistics on the degree of a species (number of reactions it is involved in) top10_degree [list[dict[str, Any]]]: Top 10 species with highest degree stats_identifiers_per_species [dict[str, float]]: Statistics on the number of identifiers per species top10_identifiers_per_species [list[dict[str, Any]]]: Top 10 species with highest number of identifiers Return type : Mapping[str, Any]'},\n",
       "      'remove_compartmentalized_species': {'name': 'remove_compartmentalized_species',\n",
       "       'signature': 'remove_compartmentalized_species(sc_ids:Iterable[str])\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.remove_compartmentalized_species',\n",
       "       'doc': 'Starting with a set of compartmentalized species determine which reactions should be removed\\nbased on there removal. Then remove these reactions, compartmentalized species, and species.'},\n",
       "      'remove_reactions': {'name': 'remove_reactions',\n",
       "       'signature': 'remove_reactions(r_ids:Iterable[str],remove_species:bool=False)\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.remove_reactions',\n",
       "       'doc': 'Removes reactions from the model Parameters : r_ids ( List [ str ] ) – the reactions to remove remove_species ( bool , optional ) – whether to remove species that are no longer\\npart of any reactions. Defaults to False.'},\n",
       "      'validate_and_resolve': {'name': 'validate_and_resolve',\n",
       "       'signature': 'validate_and_resolve()\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs.validate_and_resolve',\n",
       "       'doc': 'Call validate and try to iteratively resolve common validation errors'}},\n",
       "     'attributes': {'compartments': {'name': 'compartments',\n",
       "       'signature': 'compartments:DataFrame\\uf0c1',\n",
       "       'id': 'id8',\n",
       "       'doc': ''},\n",
       "      'species': {'name': 'species',\n",
       "       'signature': 'species:DataFrame\\uf0c1',\n",
       "       'id': 'id13',\n",
       "       'doc': ''},\n",
       "      'species_data': {'name': 'species_data',\n",
       "       'signature': 'species_data:dict[str,DataFrame]\\uf0c1',\n",
       "       'id': 'id14',\n",
       "       'doc': ''},\n",
       "      'reactions': {'name': 'reactions',\n",
       "       'signature': 'reactions:DataFrame\\uf0c1',\n",
       "       'id': 'id10',\n",
       "       'doc': ''},\n",
       "      'reactions_data': {'name': 'reactions_data',\n",
       "       'signature': 'reactions_data:dict[str,DataFrame]\\uf0c1',\n",
       "       'id': 'id11',\n",
       "       'doc': ''},\n",
       "      'reaction_species': {'name': 'reaction_species',\n",
       "       'signature': 'reaction_species:DataFrame\\uf0c1',\n",
       "       'id': 'id9',\n",
       "       'doc': ''},\n",
       "      'schema': {'name': 'schema',\n",
       "       'signature': 'schema:dict\\uf0c1',\n",
       "       'id': 'id12',\n",
       "       'doc': ''},\n",
       "      '_optional_entities': {'name': '_optional_entities',\n",
       "       'signature': '_optional_entities:set[str]\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._optional_entities',\n",
       "       'doc': ''},\n",
       "      '_required_entities': {'name': '_required_entities',\n",
       "       'signature': '_required_entities:set[str]\\uf0c1',\n",
       "       'id': 'napistu.sbml_dfs_core.SBML_dfs._required_entities',\n",
       "       'doc': ''}}}}},\n",
       "  'sbml_dfs_utils': {'module': 'napistu.sbml_dfs_utils',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.sbml_dfs_utils.html#module-napistu.sbml_dfs_utils',\n",
       "   'functions': {'_dogmatic_to_defining_bqbs': {'name': '_dogmatic_to_defining_bqbs',\n",
       "     'signature': 'napistu.sbml_dfs_utils._dogmatic_to_defining_bqbs(dogmatic:bool=False)→str\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils._dogmatic_to_defining_bqbs',\n",
       "     'doc': ''},\n",
       "    '_stub_ids': {'name': '_stub_ids',\n",
       "     'signature': 'napistu.sbml_dfs_utils._stub_ids(ids)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils._stub_ids',\n",
       "     'doc': 'Stub with a blank ID if an ids list is blank; otherwise create an Identifiers object from the provided ids'},\n",
       "    'adapt_pw_index': {'name': 'adapt_pw_index',\n",
       "     'signature': 'napistu.sbml_dfs_utils.adapt_pw_index(source:str|PWIndex,species:str|Iterable[str]|None,outdir:str|None=None)→PWIndex\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.adapt_pw_index',\n",
       "     'doc': 'Adapts a pw_index Helpful to filter for species before reconstructing. Parameters : source ( str | PWIndex ) – uri for pw_index.csv file or PWIndex object species ( str ) outdir ( str | None , optional ) – Optional directory to write pw_index to.\\nDefaults to None. Returns : Filtered pw index Return type : indices.PWIndex'},\n",
       "    'check_entity_data_index_matching': {'name': 'check_entity_data_index_matching',\n",
       "     'signature': 'napistu.sbml_dfs_utils.check_entity_data_index_matching(sbml_dfs,table)\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.check_entity_data_index_matching',\n",
       "     'doc': 'Update the input smbl_dfs’s entity_data (dict) index\\nwith match_entitydata_index_to_entity,\\nso that index for dataframe(s) in entity_data (dict) matches the sbml_dfs’\\ncorresponding entity, and then passes sbml_dfs.validate()\\nArgs sbml_dfs (cpr.SBML_dfs): a cpr.SBML_dfs\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns sbml_dfs (cpr.SBML_dfs):\\nsbml_dfs whose entity_data is checked to have the same index\\nas the corresponding entity.'},\n",
       "    'get_characteristic_species_ids': {'name': 'get_characteristic_species_ids',\n",
       "     'signature': 'napistu.sbml_dfs_utils.get_characteristic_species_ids(sbml_dfs:SBML_dfs,dogmatic:bool=True)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.get_characteristic_species_ids',\n",
       "     'doc': 'Get Characteristic Species IDs List the systematic identifiers which are characteristic of molecular species, e.g., excluding subcomponents, and optionally, treating proteins, transcripts, and genes equiavlently. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object. dogmatic ( bool , default=True ) – Whether to use the dogmatic flag to determine which BQB attributes are valid. Returns : A DataFrame containing the systematic identifiers which are characteristic of molecular species. Return type : pd.DataFrame'},\n",
       "    'get_current_max_id': {'name': 'get_current_max_id',\n",
       "     'signature': 'napistu.sbml_dfs_utils.get_current_max_id(sbml_dfs_table:DataFrame)→int\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.get_current_max_id',\n",
       "     'doc': 'Get Current Max ID Look at a table from an SBML_dfs object and find the largest primary key following\\nthe default naming convention for a the table. Params:\\nsbml_dfs_table (pd.DataFrame): A table derived from an SBML_dfs object. Returns:\\ncurrent_max_id (int): The largest id which is already defined in the table using its expected naming\\nconvention. If no IDs following this convention are present then the default\\nwill be -1. In this way new IDs will be added starting with 0.'},\n",
       "    'id_formatter': {'name': 'id_formatter',\n",
       "     'signature': 'napistu.sbml_dfs_utils.id_formatter(id_values:Iterable[Any],id_type:str,id_len:int=8)→list[str]\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.id_formatter',\n",
       "     'doc': ''},\n",
       "    'id_formatter_inv': {'name': 'id_formatter_inv',\n",
       "     'signature': 'napistu.sbml_dfs_utils.id_formatter_inv(ids:list[str])→list[int]\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.id_formatter_inv',\n",
       "     'doc': 'ID Formatter Inverter Convert from internal IDs back to integer IDs'},\n",
       "    'match_entitydata_index_to_entity': {'name': 'match_entitydata_index_to_entity',\n",
       "     'signature': 'napistu.sbml_dfs_utils.match_entitydata_index_to_entity(entity_data_dict:dict,an_entity_data_type:str,consensus_entity_df:DataFrame,entity_schema:dict,table:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.match_entitydata_index_to_entity',\n",
       "     'doc': 'Match the index of entity_data_dict[an_entity_data_type] with the index of corresponding entity.\\nUpdate entity_data_dict[an_entity_data_type]’s index to the same as consensus_entity_df’s index\\nReport cases where entity_data has indices not in corresponding entity’s index.\\nArgs entity_data_dict (dict): dictionary containing all model’s “an_entity_data_type” dictionaries\\nan_entity_data_type (str): data_type from species/reactions_data in entity_data_dict\\nconsensus_entity_df (pd.DataFrame): the dataframe of the corresponding entity\\nentity_schema (dict): schema for “table”\\ntable (str): table whose data is being consolidates (currently species or reactions) Returns : entity_data_df (pd.DataFrame) table for entity_data_dict[an_entity_data_type]'},\n",
       "    'unnest_identifiers': {'name': 'unnest_identifiers',\n",
       "     'signature': 'napistu.sbml_dfs_utils.unnest_identifiers(id_table:DataFrame,id_var:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.sbml_dfs_utils.unnest_identifiers',\n",
       "     'doc': 'Unnest Identifiers Take a pd.DataFrame containing an array of Identifiers and\\nreturn one-row per identifier. Parameters:\\nid_table: pd.DataFrame a table containing an array of Identifiers id_var: str variable containing Identifiers Returns:\\npd.Dataframe containing the index of id_table but expanded\\nto include one row per identifier'}},\n",
       "   'classes': {}},\n",
       "  'source': {'module': 'napistu.source',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.source.html#module-napistu.source',\n",
       "   'functions': {'_collapse_by_membership_string': {'name': '_collapse_by_membership_string',\n",
       "     'signature': 'napistu.source._collapse_by_membership_string(membership_string:str,membership_categories:DataFrame,table_schema:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.source._collapse_by_membership_string',\n",
       "     'doc': 'Assign each member of a membership-string to a set of pathways.'},\n",
       "    '_collapse_source_df': {'name': '_collapse_source_df',\n",
       "     'signature': 'napistu.source._collapse_source_df(source_df:DataFrame)→Series\\uf0c1',\n",
       "     'id': 'napistu.source._collapse_source_df',\n",
       "     'doc': 'Collapse a source_df table into a single entry.'},\n",
       "    '_deduplicate_source_df': {'name': '_deduplicate_source_df',\n",
       "     'signature': 'napistu.source._deduplicate_source_df(source_df:DataFrame,table_schema:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.source._deduplicate_source_df',\n",
       "     'doc': 'Combine entries in a source table when multiple models have the same members.'},\n",
       "    '_safe_source_merge': {'name': '_safe_source_merge',\n",
       "     'signature': 'napistu.source._safe_source_merge(member_Sources:Source|list)→Source\\uf0c1',\n",
       "     'id': 'napistu.source._safe_source_merge',\n",
       "     'doc': 'Combine either a Source or pd.Series of Sources into a single Source object.'},\n",
       "    'create_source_table': {'name': 'create_source_table',\n",
       "     'signature': 'napistu.source.create_source_table(lookup_table:Series,table_schema:dict,pw_index:PWIndex|None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.source.create_source_table',\n",
       "     'doc': 'Create Source Table Create a table with one row per “new_id” and a Source object created from the union of “old_id” Source objects'},\n",
       "    'greedy_set_coverge_of_sources': {'name': 'greedy_set_coverge_of_sources',\n",
       "     'signature': 'napistu.source.greedy_set_coverge_of_sources(source_df:DataFrame,table_schema:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.source.greedy_set_coverge_of_sources',\n",
       "     'doc': 'Greedy Set Coverage of Sources Apply the greedy set coverge algorithm to find the minimal set of sources which cover all entries Parameters:\\nsource_df: pd.DataFrame pd.Dataframe containing the index of source_table but expanded to\\ninclude one row per source. As produced by source.unnest_sources() Returns:\\nminimial_sources: [str] A list of pathway_ids of the minimal source set'},\n",
       "    'merge_sources': {'name': 'merge_sources',\n",
       "     'signature': 'napistu.source.merge_sources(source_list:list|Series)→Source\\uf0c1',\n",
       "     'id': 'napistu.source.merge_sources',\n",
       "     'doc': 'Merge Sources Merge a list of Source objects into a single Source object'},\n",
       "    'unnest_sources': {'name': 'unnest_sources',\n",
       "     'signature': 'napistu.source.unnest_sources(source_table:DataFrame,source_var:str,verbose:bool=False)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.source.unnest_sources',\n",
       "     'doc': 'Unnest Sources Take a pd.DataFrame containing an array of Sources and\\nreturn one-row per source. Parameters:\\nsource_table: pd.DataFrame a table containing an array of Sources source_var: str variable containing Sources Returns:\\npd.Dataframe containing the index of source_table but expanded\\nto include one row per source'}},\n",
       "   'classes': {'Source': {'name': 'Source',\n",
       "     'signature': 'classnapistu.source.Source(source_df:DataFrame|None=None,init:bool=False,pw_index:PWIndex|None=None)\\uf0c1',\n",
       "     'id': 'napistu.source.Source',\n",
       "     'doc': 'Bases: object An Entity’s Source source \\uf0c1 A dataframe containing the model source and other optional variables Type : pd.DataFrame __init__ ( source_df : DataFrame | None = None , init : bool = False , pw_index : PWIndex | None = None ) → None \\uf0c1 Tracks the model(s) an entity (i.e., a compartment, species, reaction) came from. By convention sources exist only for the models that an entity came from rather\\nthan the current model they are part of. For example, when combining Reactome models\\ninto a consensus, a molecule which existed in multiple models would have a source entry\\nfor each, but it would not have a source entry for the consensus model itself. Parameters : source_df ( pd.DataFrame ) – A dataframe containing the model source and other optional variables init ( bool ) – Creates an empty source object. This is typically used when creating an SBML_dfs\\nobject from a single source. pw_index ( indices.PWIndex ) Return type : None.',\n",
       "     'methods': {'__init__': {'name': '__init__',\n",
       "       'signature': '__init__(source_df:DataFrame|None=None,init:bool=False,pw_index:PWIndex|None=None)→None\\uf0c1',\n",
       "       'id': 'napistu.source.Source.__init__',\n",
       "       'doc': 'Tracks the model(s) an entity (i.e., a compartment, species, reaction) came from. By convention sources exist only for the models that an entity came from rather\\nthan the current model they are part of. For example, when combining Reactome models\\ninto a consensus, a molecule which existed in multiple models would have a source entry\\nfor each, but it would not have a source entry for the consensus model itself. Parameters : source_df ( pd.DataFrame ) – A dataframe containing the model source and other optional variables init ( bool ) – Creates an empty source object. This is typically used when creating an SBML_dfs\\nobject from a single source. pw_index ( indices.PWIndex ) Return type : None.'}},\n",
       "     'attributes': {'source': {'name': 'source',\n",
       "       'signature': 'source\\uf0c1',\n",
       "       'id': 'napistu.source.Source.source',\n",
       "       'doc': 'A dataframe containing the model source and other optional variables Type : pd.DataFrame'}}}}},\n",
       "  'utils': {'module': 'napistu.utils',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.utils.html#module-napistu.utils',\n",
       "   'functions': {'_add_nameness_score': {'name': '_add_nameness_score',\n",
       "     'signature': 'napistu.utils._add_nameness_score(df,name_var)\\uf0c1',\n",
       "     'id': 'napistu.utils._add_nameness_score',\n",
       "     'doc': 'Add a nameness_score variable which reflects how name-like each entry is.'},\n",
       "    '_add_nameness_score_wrapper': {'name': '_add_nameness_score_wrapper',\n",
       "     'signature': 'napistu.utils._add_nameness_score_wrapper(df,name_var,table_schema)\\uf0c1',\n",
       "     'id': 'napistu.utils._add_nameness_score_wrapper',\n",
       "     'doc': 'Call _add_nameness_score with default value.'},\n",
       "    'check_unique_index': {'name': 'check_unique_index',\n",
       "     'signature': \"napistu.utils.check_unique_index(df,label='')\\uf0c1\",\n",
       "     'id': 'napistu.utils.check_unique_index',\n",
       "     'doc': 'Validate that each index value only maps to a single row.'},\n",
       "    'click_str_to_list': {'name': 'click_str_to_list',\n",
       "     'signature': 'napistu.utils.click_str_to_list(string:str)→list[str]\\uf0c1',\n",
       "     'id': 'napistu.utils.click_str_to_list',\n",
       "     'doc': 'Convert a string-based representation of a list inputted from the CLI into a list of strings.'},\n",
       "    'copy_uri': {'name': 'copy_uri',\n",
       "     'signature': 'napistu.utils.copy_uri(input_uri:str,output_uri:str,is_file=True)\\uf0c1',\n",
       "     'id': 'napistu.utils.copy_uri',\n",
       "     'doc': 'Copy a file or folder from one uri to another Parameters : input_uri ( str ) – input file uri (gcs, http, …) output_uri ( str ) – path to output file (gcs, local) is_file ( bool , optional ) – Is this a file or folder?. Defaults to True.'},\n",
       "    'download_and_extract': {'name': 'download_and_extract',\n",
       "     'signature': \"napistu.utils.download_and_extract(url:str,output_dir_path:str='.',download_method:str='wget',overwrite:bool=False)→None\\uf0c1\",\n",
       "     'id': 'napistu.utils.download_and_extract',\n",
       "     'doc': 'Download and Unpack Download an archive and then extract to a new folder Parameters : url ( str ) – Url of archive. output_dir_path ( str ) – Path to output directory. overwrite ( bool ) – Overwrite an existing output directory. Returns : None'},\n",
       "    'download_ftp': {'name': 'download_ftp',\n",
       "     'signature': 'napistu.utils.download_ftp(url,path)\\uf0c1',\n",
       "     'id': 'napistu.utils.download_ftp',\n",
       "     'doc': ''},\n",
       "    'download_wget': {'name': 'download_wget',\n",
       "     'signature': 'napistu.utils.download_wget(url:str,path,target_filename:str=None,verify:bool=True)→None\\uf0c1',\n",
       "     'id': 'napistu.utils.download_wget',\n",
       "     'doc': 'Downloades file / archive with wget Parameters : url ( str ) – url path ( FilePath | WriteBuffer ) – file path or buffer target_filename ( str ) – specific file to extract from ZIP if URL is a ZIP file verify ( bool ) – verify argument to pass to requests.get Returns : None'},\n",
       "    'drop_extra_cols': {'name': 'drop_extra_cols',\n",
       "     'signature': 'napistu.utils.drop_extra_cols(df_in:DataFrame,df_out:DataFrame,always_include:List[str]|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.utils.drop_extra_cols',\n",
       "     'doc': \"Remove columns in df_out that are not in df_in, except those specified in always_include. Parameters : df_in ( pd.DataFrame ) – Reference DataFrame whose columns determine what to keep df_out ( pd.DataFrame ) – DataFrame to filter columns from always_include ( Optional [ List [ str ] ] , optional ) – List of column names to always include in output, even if not in df_in Returns : DataFrame with columns filtered to match df_in plus any always_include columns.\\nColumn order follows df_in, with always_include columns appended at the end. Return type : pd.DataFrame Examples >>> df_in = pd . DataFrame ({ 'a' : [ 1 ], 'b' : [ 2 ]}) >>> df_out = pd . DataFrame ({ 'a' : [ 3 ], 'c' : [ 4 ], 'd' : [ 5 ]}) >>> _drop_extra_cols ( df_in , df_out ) # Returns DataFrame with just column 'a' >>> _drop_extra_cols ( df_in , df_out , always_include = [ 'd' ]) # Returns DataFrame with columns ['a', 'd']\"},\n",
       "    'ensure_pd_df': {'name': 'ensure_pd_df',\n",
       "     'signature': 'napistu.utils.ensure_pd_df(pd_df_or_series:DataFrame|Series)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.utils.ensure_pd_df',\n",
       "     'doc': 'Ensure Pandas DataFrame Convert a pd.Series to a DataFrame if needed. Parameters : pd_df_or_series ( pd.Series | pd.DataFrame ) – a pandas df or series Returns : pd_df converted to a pd.DataFrame if needed'},\n",
       "    'extract': {'name': 'extract',\n",
       "     'signature': 'napistu.utils.extract(file:str)\\uf0c1',\n",
       "     'id': 'napistu.utils.extract',\n",
       "     'doc': 'Download and Unpack Untar, unzip and ungzip Parameters : file ( str ) – Path to compressed file Returns : None'},\n",
       "    'extract_regex_match': {'name': 'extract_regex_match',\n",
       "     'signature': 'napistu.utils.extract_regex_match(regex:str,query:str)→str\\uf0c1',\n",
       "     'id': 'napistu.utils.extract_regex_match',\n",
       "     'doc': 'Parameters : regex ( str ) – regular expression to search query ( str ) – string to search against Returns : a character string match Return type : match (str)'},\n",
       "    'extract_regex_search': {'name': 'extract_regex_search',\n",
       "     'signature': 'napistu.utils.extract_regex_search(regex:str,query:str,index_value:int=0)→str\\uf0c1',\n",
       "     'id': 'napistu.utils.extract_regex_search',\n",
       "     'doc': 'Match an identifier substring and otherwise throw an error Parameters : regex ( str ) – regular expression to search query ( str ) – string to search against index_value ( int ) – entry in index to return Returns : a character string match Return type : match (str)'},\n",
       "    'find_weakly_connected_subgraphs': {'name': 'find_weakly_connected_subgraphs',\n",
       "     'signature': 'napistu.utils.find_weakly_connected_subgraphs(edgelist:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.utils.find_weakly_connected_subgraphs',\n",
       "     'doc': 'Find all cliques of loosly connected components.'},\n",
       "    'format_identifiers_as_edgelist': {'name': 'format_identifiers_as_edgelist',\n",
       "     'signature': 'napistu.utils.format_identifiers_as_edgelist(df:DataFrame,defining_vars:list[str])→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.utils.format_identifiers_as_edgelist',\n",
       "     'doc': 'Format Identifiers as Edgelist Collapse a multiindex to an index (if needed), and similarly collapse multiple variables to a single entry.\\nThis indexed pd.Sereies of index - ids can be treated as an edgelist for greedy clustering. Parameters : df ( pd.DataFrame ) – Any pd.DataFrame defining_vars ( list ( str ) ) – A set of attributes which define a distinct entry in df Returns : A pd.DataFrame with an “ind” and “id” variable added indicating rolled up\\nvalues of the index and defining_vars Return type : df (pd.DataFrame)'},\n",
       "    'get_extn_from_url': {'name': 'get_extn_from_url',\n",
       "     'signature': 'napistu.utils.get_extn_from_url(url:str)→str\\uf0c1',\n",
       "     'id': 'napistu.utils.get_extn_from_url',\n",
       "     'doc': 'Retrieves file extension from an URL Parameters : url ( str ) – url Raises : ValueError – Raised when no extension identified Returns : the identified extension Return type : str Examples:\\n>>> get_extn_from_url(’ https://test/test.gz ’)\\n‘.gz’\\n>>> get_extn_from_url(’ https://test/test.tar.gz ’)\\n‘.tar.gz’\\n>>> get_extn_from_url(’ https://test/test.tar.gz/bla ’)\\nTraceback (most recent call last):\\n…\\nValueError: File extension not identifiable: https://test/test.tar.gz/bla'},\n",
       "    'get_source_base_and_path': {'name': 'get_source_base_and_path',\n",
       "     'signature': 'napistu.utils.get_source_base_and_path(uri:str)→tuple[str,str]\\uf0c1',\n",
       "     'id': 'napistu.utils.get_source_base_and_path',\n",
       "     'doc': 'Get the base of a bucket or folder and the path to the file Parameters : uri ( str ) – uri Returns : base: the base folder of the bucket Return type : tuple[str, str] Example:\\n>>> get_source_base_and_path(“gs://bucket/folder/file”)\\n(‘gs://bucket’, ‘folder/file’)\\n>>> get_source_base_and_path(“/bucket/folder/file”)\\n(‘/bucket/folder’, ‘file’)'},\n",
       "    'get_target_base_and_path': {'name': 'get_target_base_and_path',\n",
       "     'signature': 'napistu.utils.get_target_base_and_path(uri)\\uf0c1',\n",
       "     'id': 'napistu.utils.get_target_base_and_path',\n",
       "     'doc': 'Get the base of a bucket + directory and the file Parameters : uri ( str ) – uri Returns : base: the base folder + path of the bucket file: the file Return type : tuple[str, str] Example:\\n>>> get_target_base_and_path(“gs://bucket/folder/file”)\\n(‘gs://bucket/folder’, ‘file’)\\n>>> get_target_base_and_path(“bucket/folder/file”)\\n(‘bucket/folder’, ‘file’)\\n>>> get_target_base_and_path(“/bucket/folder/file”)\\n(‘/bucket/folder’, ‘file’)'},\n",
       "    'gunzip': {'name': 'gunzip',\n",
       "     'signature': 'napistu.utils.gunzip(gzipped_path:str,outpath:str|None=None)→None\\uf0c1',\n",
       "     'id': 'napistu.utils.gunzip',\n",
       "     'doc': 'Gunzip a file to an output path.'},\n",
       "    'initialize_dir': {'name': 'initialize_dir',\n",
       "     'signature': 'napistu.utils.initialize_dir(output_dir_path:str,overwrite:bool)\\uf0c1',\n",
       "     'id': 'napistu.utils.initialize_dir',\n",
       "     'doc': 'Initializes a filesystem directory Parameters : output_dir_path ( str ) – path to new directory overwrite ( bool ) – overwrite? if true, directory will be\\ndeleted and recreated Raises : FileExistsError –'},\n",
       "    'load_json': {'name': 'load_json',\n",
       "     'signature': 'napistu.utils.load_json(uri:str)→Any\\uf0c1',\n",
       "     'id': 'napistu.utils.load_json',\n",
       "     'doc': 'Read json from uri Parameters : uri ( str ) – path to json file'},\n",
       "    'load_pickle': {'name': 'load_pickle',\n",
       "     'signature': 'napistu.utils.load_pickle(path:str)\\uf0c1',\n",
       "     'id': 'napistu.utils.load_pickle',\n",
       "     'doc': 'Loads pickle object to path Parameters : path ( str ) – path to pickle Returns : Object Return type : Any'},\n",
       "    'path_exists': {'name': 'path_exists',\n",
       "     'signature': 'napistu.utils.path_exists(path:str)→bool\\uf0c1',\n",
       "     'id': 'napistu.utils.path_exists',\n",
       "     'doc': 'Checks if path or uri exists Parameters : path ( str ) – path/uri Returns : exists? Return type : bool'},\n",
       "    'pickle_cache': {'name': 'pickle_cache',\n",
       "     'signature': 'napistu.utils.pickle_cache(path:str,overwrite:bool=False)\\uf0c1',\n",
       "     'id': 'napistu.utils.pickle_cache',\n",
       "     'doc': 'A decorator to cache a function call result to pickle Attention: this does not care about the function arguments\\nAll function calls will be served by the same pickle file. Parameters : path ( str ) – path to the cache pickle file overwrite ( bool ) – should an existing cache be overwritten even\\nif it exists? Returns : A function whos output will be cached to pickle.'},\n",
       "    'read_pickle': {'name': 'read_pickle',\n",
       "     'signature': 'napistu.utils.read_pickle(path:str)\\uf0c1',\n",
       "     'id': 'napistu.utils.read_pickle',\n",
       "     'doc': 'Loads pickle object to path Parameters : path ( str ) – path to pickle Returns : Object Return type : Any'},\n",
       "    'requests_retry_session': {'name': 'requests_retry_session',\n",
       "     'signature': 'napistu.utils.requests_retry_session(retries=5,backoff_factor=0.3,status_forcelist=(500,502,503,504),session:Session|None=None,**kwargs)→Session\\uf0c1',\n",
       "     'id': 'napistu.utils.requests_retry_session',\n",
       "     'doc': 'Requests session with retry logic This should help to combat flaky apis, eg Brenda.\\nFrom: https://stackoverflow.com/a/58687549 Parameters : retries ( int , optional ) – Number of retries. Defaults to 5. backoff_factor ( float , optional ) – backoff. Defaults to 0.3. status_forcelist ( tuple , optional ) – errors to retry. Defaults to (500, 502, 503, 504). session ( Optional [ requests.Session ] , optional ) – existing session. Defaults to None. Returns : new requests session Return type : requests.Session'},\n",
       "    'safe_series_tolist': {'name': 'safe_series_tolist',\n",
       "     'signature': 'napistu.utils.safe_series_tolist(x)\\uf0c1',\n",
       "     'id': 'napistu.utils.safe_series_tolist',\n",
       "     'doc': 'Convert either a list or str to a list.'},\n",
       "    'save_json': {'name': 'save_json',\n",
       "     'signature': 'napistu.utils.save_json(uri:str,object:Any)→None\\uf0c1',\n",
       "     'id': 'napistu.utils.save_json',\n",
       "     'doc': 'Write object to json file at uri Parameters : object ( Any ) – object to write uri ( str ) – path to json file'},\n",
       "    'save_pickle': {'name': 'save_pickle',\n",
       "     'signature': 'napistu.utils.save_pickle(path:str,dat:object)\\uf0c1',\n",
       "     'id': 'napistu.utils.save_pickle',\n",
       "     'doc': 'Saves object to path as pickle Parameters : path ( str ) – target path dat ( object ) – object'},\n",
       "    'score_nameness': {'name': 'score_nameness',\n",
       "     'signature': 'napistu.utils.score_nameness(string:str)\\uf0c1',\n",
       "     'id': 'napistu.utils.score_nameness',\n",
       "     'doc': 'Score Nameness This utility assigns a numeric score to a string reflecting how likely it is to be\\na human readable name. This will help to prioritize readable entries when we are\\ntrying to pick out a single name to display from a set of values which may also\\ninclude entries like systematic ids. Parameters : string ( str ) – An alphanumeric string Returns : An integer score indicating how name-like the string is (low is more name-like) Return type : score (int)'},\n",
       "    'style_df': {'name': 'style_df',\n",
       "     'signature': \"napistu.utils.style_df(df:pd.DataFrame,headers:str|list[str]|None='keys',hide_index:bool=False)→pd.io.formats.style.Styler\\uf0c1\",\n",
       "     'id': 'napistu.utils.style_df',\n",
       "     'doc': 'Style DataFrame Provide some simple options for styling a pd.DataFrame Parameters : df – pd.DataFrame\\nA table to style headers – “keys” to use the current column names None to suppress column names list[str] to overwrite and show column names hide_index – bool\\nShould rows be displayed? Returns : pd.io.formats.style.Styler df with styles updated Return type : styled_df'},\n",
       "    'write_file_contents_to_path': {'name': 'write_file_contents_to_path',\n",
       "     'signature': 'napistu.utils.write_file_contents_to_path(path:str,contents)→None\\uf0c1',\n",
       "     'id': 'napistu.utils.write_file_contents_to_path',\n",
       "     'doc': 'Helper function to write file contents to the path. Parameters : path ( str ) – destination contents ( Any ) – file contents Returns : None'},\n",
       "    'write_pickle': {'name': 'write_pickle',\n",
       "     'signature': 'napistu.utils.write_pickle(path:str,dat:object)\\uf0c1',\n",
       "     'id': 'napistu.utils.write_pickle',\n",
       "     'doc': 'Saves object to path as pickle Parameters : path ( str ) – target path dat ( object ) – object'}},\n",
       "   'classes': {'match_pd_vars': {'name': 'match_pd_vars',\n",
       "     'signature': 'classnapistu.utils.match_pd_vars(df:DataFrame|Series,req_vars:set,allow_series:bool=True)\\uf0c1',\n",
       "     'id': 'napistu.utils.match_pd_vars',\n",
       "     'doc': 'Bases: object Match Pandas Variables. req_vars \\uf0c1 A set of variables which should exist in df missing_vars \\uf0c1 Required variables which are not present in df extra_vars \\uf0c1 Non-required variables which are present in df are_present \\uf0c1 Returns True if req_vars are present and False otherwise assert_present ( ) \\uf0c1 Raise an exception of req_vars are absent __init__ ( df : DataFrame | Series , req_vars : set , allow_series : bool = True ) → None \\uf0c1 Connects to an SBML file Parameters : df – A pd.DataFrame or pd.Series req_vars – A set of variables which should exist in df allow_series – Can a pd.Series be provided as df? Return type : None. assert_present ( ) → None \\uf0c1 Raise an error if required variables are missing',\n",
       "     'methods': {'assert_present': {'name': 'assert_present',\n",
       "       'signature': 'assert_present()→None\\uf0c1',\n",
       "       'id': 'id0',\n",
       "       'doc': 'Raise an error if required variables are missing'},\n",
       "      '__init__': {'name': '__init__',\n",
       "       'signature': '__init__(df:DataFrame|Series,req_vars:set,allow_series:bool=True)→None\\uf0c1',\n",
       "       'id': 'napistu.utils.match_pd_vars.__init__',\n",
       "       'doc': 'Connects to an SBML file Parameters : df – A pd.DataFrame or pd.Series req_vars – A set of variables which should exist in df allow_series – Can a pd.Series be provided as df? Return type : None.'}},\n",
       "     'attributes': {'req_vars': {'name': 'req_vars',\n",
       "       'signature': 'req_vars\\uf0c1',\n",
       "       'id': 'napistu.utils.match_pd_vars.req_vars',\n",
       "       'doc': 'A set of variables which should exist in df'},\n",
       "      'missing_vars': {'name': 'missing_vars',\n",
       "       'signature': 'missing_vars\\uf0c1',\n",
       "       'id': 'napistu.utils.match_pd_vars.missing_vars',\n",
       "       'doc': 'Required variables which are not present in df'},\n",
       "      'extra_vars': {'name': 'extra_vars',\n",
       "       'signature': 'extra_vars\\uf0c1',\n",
       "       'id': 'napistu.utils.match_pd_vars.extra_vars',\n",
       "       'doc': 'Non-required variables which are present in df'},\n",
       "      'are_present': {'name': 'are_present',\n",
       "       'signature': 'are_present\\uf0c1',\n",
       "       'id': 'napistu.utils.match_pd_vars.are_present',\n",
       "       'doc': 'Returns True if req_vars are present and False otherwise'}}}}}},\n",
       " 'napistu.network': {'constants': {'module': 'napistu.network.constants',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.constants.html#module-napistu.network.constants',\n",
       "   'functions': {},\n",
       "   'classes': {}},\n",
       "  'neighborhoods': {'module': 'napistu.network.neighborhoods',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.neighborhoods.html#module-napistu.network.neighborhoods',\n",
       "   'functions': {'_build_raw_neighborhood_df': {'name': '_build_raw_neighborhood_df',\n",
       "     'signature': 'napistu.network.neighborhoods._build_raw_neighborhood_df(cpr_graph:Graph,compartmentalized_species:list[str],network_type:str,order:int,precomputed_neighbors:DataFrame|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods._build_raw_neighborhood_df',\n",
       "     'doc': ''},\n",
       "    '_calculate_path_attrs': {'name': '_calculate_path_attrs',\n",
       "     'signature': \"napistu.network.neighborhoods._calculate_path_attrs(neighborhood_paths:list[list],edges:DataFrame,vertices:list,weight_var:str='weights')→tuple[DataFrame,dict[Any,set]]\\uf0c1\",\n",
       "     'id': 'napistu.network.neighborhoods._calculate_path_attrs',\n",
       "     'doc': 'Calculate Path Attributes Return the vertices and path weights (sum of edge weights) for a list of paths. Parameters : neighborhood_paths ( list ) – List of lists of edge indices edges ( pd.DataFrame ) – Edges with rows correponding to entries in neighborhood_paths inner lists vertices ( list ) – List of vertices correponding to the ordering of neighborhood_paths weights_var ( str ) – variable in edges to use for scoring path weights Returns : path_attributes_df ( pd.DataFrame ) – A table containing attributes summarizing the path to each neighbor neighborhood_path_entities ( dict ) – Dict mapping from each neighbor to the entities connecting it to the focal node'},\n",
       "    '_create_neighborhood_dict_entry_logging': {'name': '_create_neighborhood_dict_entry_logging',\n",
       "     'signature': 'napistu.network.neighborhoods._create_neighborhood_dict_entry_logging(sc_id:str,one_neighborhood_df:DataFrame,sbml_dfs:SBML_dfs)\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods._create_neighborhood_dict_entry_logging',\n",
       "     'doc': ''},\n",
       "    '_find_neighbors': {'name': '_find_neighbors',\n",
       "     'signature': 'napistu.network.neighborhoods._find_neighbors(cpr_graph:Graph,compartmentalized_species:list[str],relationship:str,order:int=3,precomputed_neighbors:DataFrame|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods._find_neighbors',\n",
       "     'doc': 'Find Neighbors Identify the neighbors nearby each of the requested compartmentalized_species If ‘precomputed_neighbors’ are provided, neighbors will be summarized by reformatting\\nthis table. Otherwise, neighbors will be found on-the-fly using the igraph.neighborhood() method.'},\n",
       "    '_find_reactions_by_relationship': {'name': '_find_reactions_by_relationship',\n",
       "     'signature': 'napistu.network.neighborhoods._find_reactions_by_relationship(precomputed_neighbors,compartmentalized_species:list,sbml_dfs:SBML_dfs,relationship:str)→DataFrame|None\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods._find_reactions_by_relationship',\n",
       "     'doc': 'Find Reactions by Relationship Based on an ancestor-descendant edgelist of compartmentalized species find all reactions which involve 2+ members Since we primarily care about paths between species and reactions are more of a means-to-an-end of\\nconnecting pairs of species precomputed_distances are generated between just pairs of species\\nthis also makes the problem feasible since the number of species is upper bounded at <100K but\\nthe number of reactions is unbounded. Having a bound ensures that we can calculate\\nthe precomputed_distances efficiently using matrix operations whose memory footprint scales with O(N^2).'},\n",
       "    '_precompute_neighbors': {'name': '_precompute_neighbors',\n",
       "     'signature': \"napistu.network.neighborhoods._precompute_neighbors(compartmentalized_species:list[str],precomputed_distances:DataFrame,sbml_dfs:SBML_dfs,network_type:str='downstream',order:int=3,top_n:int=10)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.network.neighborhoods._precompute_neighbors',\n",
       "     'doc': 'Precompute Neighbors Identify compartmentalized_species’ most tightly connected neighbors using parameters\\nshared by the on-the-fly methods (order for identifying neighbors within N steps;\\ntop_n for identifying the most the lowest weight network paths between the focal node\\nand each possible neighbors). This precomputation will greatly speed up the neighborhood\\ngeneration for highly connected species or densely connected networks. In those situations\\nnaively creating a neighborhood in N steps could contain thousands of neighbors.'},\n",
       "    '_prune_vertex_set': {'name': '_prune_vertex_set',\n",
       "     'signature': 'napistu.network.neighborhoods._prune_vertex_set(one_neighborhood:dict,top_n:int)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods._prune_vertex_set',\n",
       "     'doc': 'Prune Vertex Set Filter a neighborhood to the lowest weight neighbors connected to the focal node.\\nDuring this process upstream and downstream nodes are treated separately. Parameters : one_neighborhood ( dict ) – The neighborhood around a single compartmentalized species - one of the values in dict created by find_neighborhoods(). top_n ( int ) – How many neighboring molecular species should be retained?\\nIf the neighborhood includes both upstream and downstream connections\\n(i.e., hourglass), this filter will be applied to both sets separately. Returns : vertices – the vertices in one_neighborhood with high weight neighbors removed. Return type : pd.DataFrame'},\n",
       "    'add_vertices_uri_urls': {'name': 'add_vertices_uri_urls',\n",
       "     'signature': 'napistu.network.neighborhoods.add_vertices_uri_urls(vertices:DataFrame,sbml_dfs:SBML_dfs)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.add_vertices_uri_urls',\n",
       "     'doc': 'Add Vertices URI URLs Add a url variable to the neighborhood vertices pd.DataFrame Parameters : vertices ( pd.DataFrame ) – table of neighborhood vertices sbml_dfs ( sbml_dfs_core.SBML_dfs ) – consensus network model Returns : vertices – input table with a url field Return type : pd.DataFrame'},\n",
       "    'create_neighborhood_dict_entry': {'name': 'create_neighborhood_dict_entry',\n",
       "     'signature': 'napistu.network.neighborhoods.create_neighborhood_dict_entry(sc_id:str,neighborhood_df:DataFrame,sbml_dfs:SBML_dfs,cpr_graph:Graph,verbose:bool=False)→dict[str,Any]\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.create_neighborhood_dict_entry',\n",
       "     'doc': 'Create Neighborhood Dict Entry Generate a summary of a compartmentalized species’ neighborhood Parameters : sc_id ( str ) – A compartmentalized species id neighborhood_df ( pd.DataFrame ) – A table of upstream and/or downstream neighbors of all compartmentalized species sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic molecular model cpr_graph ( igraph.Graph ) – A network connecting molecular species and reactions verbose ( bool ) – Extra reporting? Returns : graph: igraph.Graph subgraph of sc_id’s neighborhood, vertices: pd.DataFrame nodes in the neighborhood edges: pd.DataFrame edges in the neighborhood edge_sources: pd.DataFrame models that edges were derived from neighborhood_path_entities: dict upstream and downstream dicts representing entities in paths.\\nIf the keys are to be included in a neighborhood, the\\nvalues should be as well in order to maintain connection to the\\nfocal node. Return type : dict containing'},\n",
       "    'create_neighborhood_prefix': {'name': 'create_neighborhood_prefix',\n",
       "     'signature': 'napistu.network.neighborhoods.create_neighborhood_prefix(network_type:str,order:int,top_n:int)→str\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.create_neighborhood_prefix',\n",
       "     'doc': ''},\n",
       "    'create_neighborhoods': {'name': 'create_neighborhoods',\n",
       "     'signature': 'napistu.network.neighborhoods.create_neighborhoods(s_ids:list[str],sbml_dfs:SBML_dfs,cpr_graph:Graph,network_type:str,order:int,top_n:int,verbose:bool=False)→tuple[DataFrame,dict]\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.create_neighborhoods',\n",
       "     'doc': 'Create Neighborhoods Create neighborhoods for a set of species and return Parameters : s_ids ( list ( str ) ) – create a neighborhood around each species sbml_dfs ( sbml_dfs_core.SBML_dfs ) – network model cpr_graph ( igraph.Graph ) – network associated with sbml_dfs network_type ( str ) – downstream, upstream or hourglass (i.e., downstream and upstream) order ( 10 ) – maximum number of steps from the focal node top_n ( 30 ) – target number of upstream and downstream species to retain verbose ( bool ) – extra reporting Returns : all_neighborhoods_df ( pd.DataFrame ) – A table containing all species in each query s_ids neighborhood neighborhoods_dict ( dict ) – Outputs from find_and_prune_neighborhoods for each s_id'},\n",
       "    'find_and_prune_neighborhoods': {'name': 'find_and_prune_neighborhoods',\n",
       "     'signature': \"napistu.network.neighborhoods.find_and_prune_neighborhoods(sbml_dfs:SBML_dfs,cpr_graph:Graph,compartmentalized_species:str|list[str],precomputed_distances:DataFrame|None=None,network_type:str='downstream',order:int=3,verbose:bool=True,top_n:int=10)→dict[str,Any]\\uf0c1\",\n",
       "     'id': 'napistu.network.neighborhoods.find_and_prune_neighborhoods',\n",
       "     'doc': 'Find and Prune Neighborhoods Wrapper which combines find_neighborhoods() and prune_neighborhoods() Parameters cpr_graph igraph.Graph A bipartite network connecting molecular species and reactions compartmentalized_species [str] or str Compartmentalized species IDs for neighborhood centers precomputed_distances pd.DataFrame or None If provided, an edgelist of origin->destination path weights and lengths network_type: str If the network is directed should neighbors be located “downstream”,\\nor “upstream” of each compartmentalized species. The “hourglass” option\\nlocates both upstream and downstream species. order: int Max steps away from center node verbose: bool Extra reporting top_n: int How many neighboring molecular species should be retained?\\nIf the neighborhood includes both upstream and downstream connections\\n(i.e., hourglass), this filter will be applied to both sets separately. Returns: \\uf0c1 A dict containing the neighborhood of each compartmentalized species.\\nEach entry in the dict is a dict of the subgraph, vertices, and edges.'},\n",
       "    'find_neighborhoods': {'name': 'find_neighborhoods',\n",
       "     'signature': \"napistu.network.neighborhoods.find_neighborhoods(sbml_dfs:SBML_dfs,cpr_graph:Graph,compartmentalized_species:list[str],network_type:str='downstream',order:int=3,verbose:bool=True,precomputed_neighbors:DataFrame|None=None)→dict\\uf0c1\",\n",
       "     'id': 'napistu.network.neighborhoods.find_neighborhoods',\n",
       "     'doc': 'Find Neighborhood Create a network composed of all species and reactions within N steps of each of a set of compartmentalized species. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic molecular model cpr_graph ( igraph.Graph ) – A network connecting molecular species and reactions compartmentalized_species ( [ str ] ) – Compartmentalized species IDs for neighborhood centers network_type ( str ) – If the network is directed should neighbors be located “downstream”,\\nor “upstream” of each compartmentalized species. The “hourglass” option\\nlocates both upstream and downstream species. order ( int ) – Max steps away from center node verbose ( bool ) – Extra reporting precomputed_neighbors ( pd.DataFrame or None ) – If provided, a pre-filtered table of nodes nearby the compartmentalized species\\nwhich will be used to skip on-the-fly neighborhood generation. Returns ---------- species. ( A dict containing the neighborhood of each compartmentalized ) – Each entry in the dict is a dict of the subgraph, vertices, and edges.'},\n",
       "    'load_neighborhoods': {'name': 'load_neighborhoods',\n",
       "     'signature': 'napistu.network.neighborhoods.load_neighborhoods(s_ids:list[str],sbml_dfs:SBML_dfs,cpr_graph:Graph,output_dir:str,network_type:str,order:int,top_n:int,overwrite:bool=False,verbose:bool=False)→tuple[DataFrame,dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.load_neighborhoods',\n",
       "     'doc': 'Load Neighborhoods Load existing neighborhoods if they exist\\n(and overwrite = False) and otherwise construct neighborhoods using the provided settings Parameters : s_ids ( list ( str ) ) – create a neighborhood around each species sbml_dfs ( sbml_dfs_core.SBML_dfs ) – network model cpr_graph ( igraph.Graph ) – network associated with sbml_dfs output_dir ( str ) – path to existing output directory network_type ( str ) – downstream, upstream or hourglass (i.e., downstream and upstream) order ( 10 ) – maximum number of steps from the focal node top_n ( 30 ) – target number of upstream and downstream species to retain overwrite ( bool ) – ignore cached files and regenerate neighborhoods verbose ( bool ) – extra reporting Returns : all_neighborhoods_df ( pd.DataFrame ) – A table containing all species in each query s_ids neighborhood neighborhoods_dict ( dict ) – Outputs from find_and_prune_neighborhoods for each s_id'},\n",
       "    'load_neighborhoods_by_partition': {'name': 'load_neighborhoods_by_partition',\n",
       "     'signature': \"napistu.network.neighborhoods.load_neighborhoods_by_partition(selected_partition:int,neighborhood_outdir:str,graph_type:str='regulatory')→None\\uf0c1\",\n",
       "     'id': 'napistu.network.neighborhoods.load_neighborhoods_by_partition',\n",
       "     'doc': 'Load Neighborhoods By Partition Call load_neighborhoods for a subset of species ids defined by a partition.\\nThis function is setup to be called in a slurm job. Params \\uf0c1 selected_partition: int A partition of sids to search neighborhood_outdir: str Output directory rtype : None, used for side-effects'},\n",
       "    'plot_neighborhood': {'name': 'plot_neighborhood',\n",
       "     'signature': \"napistu.network.neighborhoods.plot_neighborhood(neighborhood_graph:Graph,name_nodes:bool=False,plot_size:int=1000,network_layout:str='drl')→plot\\uf0c1\",\n",
       "     'id': 'napistu.network.neighborhoods.plot_neighborhood',\n",
       "     'doc': 'Plot Neighborhood Parameters: \\uf0c1 neighborhood_graph: igraph.Graph An igraph network name_nodes: bool Should nodes be named plot_size: int Plot width/height in pixels network_layout: str Igraph network layout method Returns: \\uf0c1 An igraph plot'},\n",
       "    'prune_neighborhoods': {'name': 'prune_neighborhoods',\n",
       "     'signature': 'napistu.network.neighborhoods.prune_neighborhoods(neighborhoods:dict,top_n:int=100)→dict\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.prune_neighborhoods',\n",
       "     'doc': 'Prune Neighborhoods Take a possibly very large neighborhood around a set of focal nodes\\nand prune to the most highly weighted nodes. Nodes weights are\\nconstructed as the sum of path weights from the focal node to each\\nneighbor so each pruned neighborhood will still be a single subnetwork. Parameters : neighborhoods ( dict ) – A dictionary of sc_id neighborhoods as produced by find_neighborhoods() top_n ( int ) – How many neighbors should be retained? If the neighborhood includes\\nboth upstream and downstream connections (i.e., hourglass), this filter\\nwill be applied to both sets separately Returns : neighborhoods – Same structure as neighborhoods input Return type : dict'},\n",
       "    'read_paritioned_neighborhoods': {'name': 'read_paritioned_neighborhoods',\n",
       "     'signature': 'napistu.network.neighborhoods.read_paritioned_neighborhoods(sbml_dfs:SBML_dfs,cpr_graph:Graph,partitions_path:str,n_partitions:int=200)→tuple[DataFrame,dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.network.neighborhoods.read_paritioned_neighborhoods',\n",
       "     'doc': 'Read Partitioned Neighborhoods Import a set of neighborhoods produced by the find_neighborhoods_batch.sh slurm job Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs network model cpr_graph: igraph.Graph network associated with sbml_dfs partitions_path: str Path to a directory containing folders for each partition’s results n_partitions: int Number of partitions that exist returns : all_neighborhoods_df ( pd.DataFrame ) – A table containing all species in each query s_ids neighborhood neighborhoods_dict ( dict ) – Outputs from find_and_prune_neighborhoods for each s_id'}},\n",
       "   'classes': {}},\n",
       "  'net_create': {'module': 'napistu.network.net_create',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_create.html#module-napistu.network.net_create',\n",
       "   'functions': {'_add_edge_attr_to_vertex_graph': {'name': '_add_edge_attr_to_vertex_graph',\n",
       "     'signature': \"napistu.network.net_create._add_edge_attr_to_vertex_graph(cpr_graph:Graph,edge_attr_list:list,shared_node_key:str='r_id')→Graph\\uf0c1\",\n",
       "     'id': 'napistu.network.net_create._add_edge_attr_to_vertex_graph',\n",
       "     'doc': 'Merge edge attribute(s) from edge_attr_list to vetices of an igraph Parameters : cpr_graph ( iGraph ) – A graph generated by create_cpr_graph() edge_attr_list ( list ) – A list containing attributes to pull out of edges, then to add to vertices shared_node_key ( str ) – key in edge that is shared with vertex, to map edge ids to corresponding vertex ids Returns ---------- network ( An Igraph )'},\n",
       "    '_add_graph_species_attribute': {'name': '_add_graph_species_attribute',\n",
       "     'signature': 'napistu.network.net_create._add_graph_species_attribute(cpr_graph:Graph,sbml_dfs:SBML_dfs,species_graph_attrs:dict,custom_transformations:dict|None=None)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._add_graph_species_attribute',\n",
       "     'doc': 'Add meta-data from species_data to existing igraph’s vertices. This function augments the vertices of an igraph network with additional attributes\\nderived from the species-level data in the provided SBML_dfs object. The attributes\\nto add are specified in the species_graph_attrs dictionary, and can be transformed\\nusing either built-in or user-supplied transformation functions. Parameters : cpr_graph ( ig.Graph ) – The igraph network to augment. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object containing species data. species_graph_attrs ( dict ) – Dictionary specifying which attributes to pull from species_data and how to transform them.\\nThe structure should be {attribute_name: {“table”: …, “variable”: …, “trans”: …}}. custom_transformations ( dict , optional ) – Dictionary mapping transformation names to functions. If provided, these will be checked\\nbefore built-in transformations. Example: {“square”: lambda x: x**2} Returns : The input igraph network with additional vertex attributes added from species_data. Return type : ig.Graph'},\n",
       "    '_add_graph_weights_calibration': {'name': '_add_graph_weights_calibration',\n",
       "     'signature': 'napistu.network.net_create._add_graph_weights_calibration(cpr_graph:Graph,reaction_attrs:dict)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._add_graph_weights_calibration',\n",
       "     'doc': 'Weight a graph using a calibrated strategy which aims to roughly align qualiatively similar weights from different sources.'},\n",
       "    '_add_graph_weights_mixed': {'name': '_add_graph_weights_mixed',\n",
       "     'signature': 'napistu.network.net_create._add_graph_weights_mixed(cpr_graph:Graph,reaction_attrs:dict)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._add_graph_weights_mixed',\n",
       "     'doc': 'Weight a graph using a mixed approach combining source-specific weights and existing edge weights.'},\n",
       "    '_augment_network_edges': {'name': '_augment_network_edges',\n",
       "     'signature': 'napistu.network.net_create._augment_network_edges(network_edges:DataFrame,sbml_dfs:SBML_dfs,reaction_graph_attrs:dict={},custom_transformations:dict|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._augment_network_edges',\n",
       "     'doc': 'Add reversibility and other metadata from reactions. Parameters : network_edges ( pd.DataFrame ) – DataFrame of network edges. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object containing reaction data. reaction_graph_attrs ( dict ) – Dictionary of reaction attributes to add. custom_transformations ( dict , optional ) – Dictionary of custom transformation functions to use for attribute transformation.'},\n",
       "    '_augment_network_nodes': {'name': '_augment_network_nodes',\n",
       "     'signature': 'napistu.network.net_create._augment_network_nodes(network_nodes:DataFrame,sbml_dfs:SBML_dfs,species_graph_attrs:dict={},custom_transformations:dict|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._augment_network_nodes',\n",
       "     'doc': 'Add species-level attributes, expand network_nodes with s_id and c_id and then map to species-level attributes by s_id. This function merges species-level attributes from sbml_dfs into the provided network_nodes DataFrame,\\nusing the mapping in species_graph_attrs. Optionally, custom transformation functions can be provided\\nto transform the attributes as they are added. Parameters : network_nodes ( pd.DataFrame ) – DataFrame of network nodes. Must include columns ‘name’, ‘node_name’, and ‘node_type’. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object containing species data. species_graph_attrs ( dict ) – Dictionary specifying which attributes to pull from species_data and how to transform them.\\nThe structure should be {attribute_name: {“table”: …, “variable”: …, “trans”: …}}. custom_transformations ( dict , optional ) – Dictionary mapping transformation names to functions. If provided, these will be checked\\nbefore built-in transformations. Example: {“square”: lambda x: x**2} Returns : The input network_nodes DataFrame with additional columns for each extracted and transformed attribute. Return type : pd.DataFrame'},\n",
       "    '_create_cpr_graph_bipartite': {'name': '_create_cpr_graph_bipartite',\n",
       "     'signature': 'napistu.network.net_create._create_cpr_graph_bipartite(sbml_dfs:SBML_dfs)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._create_cpr_graph_bipartite',\n",
       "     'doc': 'Turn an sbml_dfs model into a bipartite graph linking molecules to reactions.'},\n",
       "    '_create_cpr_graph_tiered': {'name': '_create_cpr_graph_tiered',\n",
       "     'signature': 'napistu.network.net_create._create_cpr_graph_tiered(sbml_dfs:SBML_dfs,graph_type:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._create_cpr_graph_tiered',\n",
       "     'doc': 'Turn an sbml_dfs model into a tiered graph which links upstream entities to downstream ones.'},\n",
       "    '_create_graph_hierarchy_df': {'name': '_create_graph_hierarchy_df',\n",
       "     'signature': 'napistu.network.net_create._create_graph_hierarchy_df(graph_type:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._create_graph_hierarchy_df',\n",
       "     'doc': 'Create Graph Hierarchy DataFrame Format a graph hierarchy list of lists and a pd.DataFrame Parameters : graph_type ( str ) – The type of tiered graph to work with. Each type has its own specification in constants.py. Returns : A pandas DataFrame with sbo_name, tier, and sbo_term.'},\n",
       "    '_create_source_weights': {'name': '_create_source_weights',\n",
       "     'signature': \"napistu.network.net_create._create_source_weights(edges_df:DataFrame,source_wt_var:str='source_wt',source_vars_dict:dict={'string_wt':10},source_wt_default:int=1)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.network.net_create._create_source_weights',\n",
       "     'doc': '”\\nCreate Source Weights Create weights based on an edges source. This is a simple but crude way of allowing different\\ndata sources to have different support if we think that some are more trustworthly than others. Parameters : edges_df – pd.DataFrame\\nThe edges dataframe to add the source weights to. source_wt_var – str\\nThe name of the column to store the source weights. source_vars_dict – dict\\nDictionary with keys indicating edge attributes and values indicating the weight to assign\\nto that attribute. This value is generally the largest weight that can be assigned to an\\nedge so that the numeric weight is chosen over the default. source_wt_default – int\\nThe default weight to assign to an edge if no other weight attribute is found. Returns : pd.DataFrame The edges dataframe with the source weights added.'},\n",
       "    '_create_topology_weights': {'name': '_create_topology_weights',\n",
       "     'signature': 'napistu.network.net_create._create_topology_weights(cpr_graph:Graph,base_score:float=2,protein_multiplier:int=1,metabolite_multiplier:int=3,unknown_multiplier:int=10,scale_multiplier_by_meandegree:bool=True)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._create_topology_weights',\n",
       "     'doc': 'Create Topology Weights Add weights to a network based on its topology. Edges downstream of nodes\\nwith many connections receive a higher weight suggesting that any one\\nof them is less likely to be regulatory. This is a simple and clearly\\nflawed heuristic which can be combined with more principled weighting\\nschemes. Parameters : cpr_graph ( ig.Graph ) – a graph containing connections between molecules, proteins, and reactions. base_score ( float ) – offset which will be added to all weights. protein_multiplier ( int ) – multiplier for non-metabolite species (lower weight paths will tend to be selected). metabolite_multiplier ( int ) – multiplier for metabolites [defined a species with a ChEBI ID). unknown_multiplier ( int ) – multiplier for species without any identifier. See sbml_dfs_core.species_type_types. scale_multiplier_by_meandegree ( bool ) – if True then multipliers will be rescaled by the average number of\\nconnections a node has (i.e., its degree) so that weights will be relatively similar regardless of network\\nsize and sparsity. Returns : graph with added topology weights Return type : cpr_graph (ig.Graph)'},\n",
       "    '_format_interactors_for_tiered_graph': {'name': '_format_interactors_for_tiered_graph',\n",
       "     'signature': 'napistu.network.net_create._format_interactors_for_tiered_graph(r_id:str,rxn_species:DataFrame,sbml_dfs:SBML_dfs)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._format_interactors_for_tiered_graph',\n",
       "     'doc': 'Format an undirected interactions for tiered graph so interactions are linked even though they would be on the same tier.'},\n",
       "    '_format_tier_combo': {'name': '_format_tier_combo',\n",
       "     'signature': 'napistu.network.net_create._format_tier_combo(upstream_tier:DataFrame,downstream_tier:DataFrame,past_reaction:bool)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._format_tier_combo',\n",
       "     'doc': 'Format Tier Combo Create a set of edges crossing two tiers of a tiered graph. This will involve an all x all combination of entries. Tiers form an ordering along the molecular entities\\nin a reaction plus a tier for the reaction itself. Attributes such as stoichiometry\\nand sbo_term will be passed from the tier which is furthest from the reaction tier\\nto ensure that each tier of molecular data applies its attributes to a single set of\\nedges while the “reaction” tier does not. Reaction entities have neither a\\nstoichiometery or sbo_term annotation. Parameters : upstream_tier ( pd.DataFrame ) – A table containing upstream entities in a reaction,\\ne.g., regulators. downstream_tier ( pd.DataFrame ) – A table containing downstream entities in a reaction,\\ne.g., catalysts. past_reaction ( bool ) – if True then attributes will be taken from downstream_tier and\\nif False they will come from upstream_tier. Returns : A table of edges containing (from, to, stoichiometry, sbo_term, r_id). The\\nnumber of edges is the product of the number of entities in the upstream tier\\ntimes the number in the downstream tier. Return type : formatted_tier_combo (pd.DataFrame)'},\n",
       "    '_format_tiered_reaction_species': {'name': '_format_tiered_reaction_species',\n",
       "     'signature': 'napistu.network.net_create._format_tiered_reaction_species(r_id:str,sorted_reaction_species:DataFrame,sbml_dfs:SBML_dfs,graph_hierarchy_df:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._format_tiered_reaction_species',\n",
       "     'doc': 'Format Tiered Reaction Species Refactor a reaction’s species into tiered edges between substrates, products, enzymes and allosteric regulators.'},\n",
       "    '_reverse_network_edges': {'name': '_reverse_network_edges',\n",
       "     'signature': 'napistu.network.net_create._reverse_network_edges(augmented_network_edges:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._reverse_network_edges',\n",
       "     'doc': 'Flip reversible reactions to derive the reverse reaction.'},\n",
       "    '_summarize_weight_calibration_plots': {'name': '_summarize_weight_calibration_plots',\n",
       "     'signature': 'napistu.network.net_create._summarize_weight_calibration_plots(calibrated_edges:DataFrame,score_calibration_df_calibrated:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._summarize_weight_calibration_plots',\n",
       "     'doc': 'Create a couple of plots summarizing the relationships between different scoring measures.'},\n",
       "    '_summarize_weight_calibration_table': {'name': '_summarize_weight_calibration_table',\n",
       "     'signature': 'napistu.network.net_create._summarize_weight_calibration_table(calibrated_edges:DataFrame,score_calibration_df:DataFrame,score_calibration_df_calibrated:DataFrame)\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._summarize_weight_calibration_table',\n",
       "     'doc': 'Create a table comparing edge weights from multiple sources.'},\n",
       "    '_validate_entity_attrs': {'name': '_validate_entity_attrs',\n",
       "     'signature': 'napistu.network.net_create._validate_entity_attrs(entity_attrs:dict,validate_transformations:bool=True,custom_transformations:dict|None=None)→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._validate_entity_attrs',\n",
       "     'doc': 'Validate that graph attributes are a valid format.'},\n",
       "    '_wt_transformation_identity': {'name': '_wt_transformation_identity',\n",
       "     'signature': 'napistu.network.net_create._wt_transformation_identity(x)\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._wt_transformation_identity',\n",
       "     'doc': 'Identity'},\n",
       "    '_wt_transformation_string': {'name': '_wt_transformation_string',\n",
       "     'signature': 'napistu.network.net_create._wt_transformation_string(x)\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._wt_transformation_string',\n",
       "     'doc': 'Map STRING scores to a similar scale as topology weights.'},\n",
       "    '_wt_transformation_string_inv': {'name': '_wt_transformation_string_inv',\n",
       "     'signature': 'napistu.network.net_create._wt_transformation_string_inv(x)\\uf0c1',\n",
       "     'id': 'napistu.network.net_create._wt_transformation_string_inv',\n",
       "     'doc': 'Map STRING scores so they work with source weights.'},\n",
       "    'add_graph_weights': {'name': 'add_graph_weights',\n",
       "     'signature': \"napistu.network.net_create.add_graph_weights(cpr_graph:Graph,reaction_attrs:dict,weighting_strategy:str='unweighted')→Graph\\uf0c1\",\n",
       "     'id': 'napistu.network.net_create.add_graph_weights',\n",
       "     'doc': 'Add Graph Weights Apply a weighting strategy to generate edge weights on a graph. For directed graphs “upstream_weights” will\\nbe generated as well which should be used when searching for a node’s ancestors. Parameters : cpr_graph ( ig.Graph ) – a graphical network of molecules/reactions (nodes) and edges linking them. reaction_attrs ( dict ) – an optional dict weighting_strategy – a network weighting strategy with options:\\n- unweighted: all weights (and upstream_weights for directed graphs) are set to 1.\\n- topology: weight edges by the degree of the source nodes favoring nodes emerging from nodes with few connections. mixed: transform edges with a quantitative score based on reaction_attrs; and set edges without quantitative score as a source-specific weight. calibrated: transforme edges with a quantitative score based on reaction_attrs and combine them with topology scores to generate a consensus.'},\n",
       "    'apply_weight_transformations': {'name': 'apply_weight_transformations',\n",
       "     'signature': 'napistu.network.net_create.apply_weight_transformations(edges_df:DataFrame,reaction_attrs:dict,custom_transformations:dict=None)\\uf0c1',\n",
       "     'id': 'napistu.network.net_create.apply_weight_transformations',\n",
       "     'doc': 'Apply Weight Transformations Parameters : edges_df ( pd.DataFrame ) – a table of edges and their attributes extracted\\nfrom a cpr_grpah. reaction_attrs ( dict ) – A dictionary of attributes identifying weighting attributes within\\nan sbml_df’s reaction_data, how they will be named in edges_df (the keys),\\nand how they should be transformed (the “trans” aliases”) custom_transformations ( dict , optional ) – A dictionary mapping transformation names to functions. If provided, these\\nwill be checked before built-in transformations. Returns : edges_df with weight variables transformed. Return type : transformed_edges_df (pd.DataFrame)'},\n",
       "    'create_cpr_graph': {'name': 'create_cpr_graph',\n",
       "     'signature': \"napistu.network.net_create.create_cpr_graph(sbml_dfs:SBML_dfs,reaction_graph_attrs:dict|None=None,directed:bool=True,edge_reversed:bool=False,graph_type:str='bipartite',verbose:bool=False,custom_transformations:dict|None=None)→Graph\\uf0c1\",\n",
       "     'id': 'napistu.network.net_create.create_cpr_graph',\n",
       "     'doc': 'Create CPR Graph Create an igraph network from a mechanistic network using one of a set of graph_types. Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways reaction_graph_attrs ( dict ) – Dictionary containing attributes to pull out of reaction_data and\\na weighting scheme for the graph directed ( bool ) – Should a directed (True) or undirected graph be made (False) edge_reversed ( bool ) – Should the directions of edges be reversed or not (False) graph_type ( str ) – Type of graph to create, valid values are: bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products reguatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products surrogate: non-enzymatic modifiers -> substrates -> enzymes -> reaction -> products.\\nIn this representation enzymes are effective standing in for their reaction (eventhough the enzyme is\\nnot modified by a substrate per-se). verbose ( bool ) – Extra reporting custom_transformations ( dict , optional ) – Dictionary of custom transformation functions to use for attribute transformation. Returns ---------- network ( An Igraph )'},\n",
       "    'pluck_entity_data': {'name': 'pluck_entity_data',\n",
       "     'signature': 'napistu.network.net_create.pluck_entity_data(sbml_dfs:SBML_dfs,graph_attrs:dict[str,dict],data_type:str,custom_transformations:dict[str,callable]|None=None)→DataFrame|None\\uf0c1',\n",
       "     'id': 'napistu.network.net_create.pluck_entity_data',\n",
       "     'doc': 'Pluck Entity Attributes Pull species or reaction attributes out of an sbml_dfs based on a set of tables and variables to look for. Parameters:\\nsbml_dfs: sbml_dfs_core.SBML_dfs A mechanistic model graph_attrs: dict A dictionary of species/reaction attributes to pull out. If the requested\\ndata_type (“species” or “reactions”) is not present as a key, or if the value\\nis an empty dict, this function will return None (no error). data_type: str “species” or “reactions” to pull out species_data or reactions_data custom_transformations: dict[str, callable], optional A dictionary mapping transformation names to functions. If provided, these\\nwill be checked before built-in transformations. Example: custom_transformations = {“square”: lambda x: x**2} Returns : A table where all extracted attributes are merged based on a common index or None\\nif no attributes were extracted. If the requested data_type is not present in\\ngraph_attrs, or if the attribute dict is empty, returns None. This is intended\\nto allow optional annotation blocks.'},\n",
       "    'process_cpr_graph': {'name': 'process_cpr_graph',\n",
       "     'signature': \"napistu.network.net_create.process_cpr_graph(sbml_dfs:SBML_dfs,reaction_graph_attrs:dict|None=None,directed:bool=True,edge_reversed:bool=False,graph_type:str='bipartite',weighting_strategy:str='unweighted',verbose:bool=False,custom_transformations:dict=None)→Graph\\uf0c1\",\n",
       "     'id': 'napistu.network.net_create.process_cpr_graph',\n",
       "     'doc': 'Process Consensus Graph Setup an igraph network and then add weights and other maleable attributes. Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways reaction_graph_attrs ( dict ) – Dictionary containing attributes to pull out of reaction_data and\\na weighting scheme for the graph directed ( bool ) – Should a directed (True) or undirected graph be made (False) edge_reversed ( bool ) – Should directions of edges be reversed (False) graph_type ( str ) – Type of graph to create, valid values are:\\n- bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products\\n- reguatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products weighting_strategy ( str ) – a network weighting strategy with options:\\n- unweighted: all weights (and upstream_weights for directed graphs) are set to 1.\\n- topology: weight edges by the degree of the source nodes favoring nodes emerging from nodes with few connections. mixed: transform edges with a quantitative score based on reaction_attrs; and set edges without quantitative score as a source-specific weight. calibrated: transforme edges with a quantitative score based on reaction_attrs and combine them with topology scores to generate a consensus. verbose ( bool ) – Extra reporting custom_transformations ( dict , optional ) – Dictionary of custom transformation functions to use for attribute transformation. Returns : An Igraph network Return type : weighted_graph (ig.Graph)'},\n",
       "    'summarize_weight_calibration': {'name': 'summarize_weight_calibration',\n",
       "     'signature': 'napistu.network.net_create.summarize_weight_calibration(cpr_graph:Graph,reaction_attrs:dict)→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_create.summarize_weight_calibration',\n",
       "     'doc': 'Summarize Weight Calibration For a network with multiple sources for edge weights summarize the alignment of\\ndifferent weighting schemes and how they map onto our notion of “good” versus\\n“dubious” weights. Parameters : cpr_graph ( ig.Graph ) – A graph where edge weights have already been calibrated. reaction_attrs ( dict ) – a dictionary summarizing the types of weights that\\nexist and how they are transformed for calibration. Returns : None'}},\n",
       "   'classes': {'_EntityAttrValidator': {'name': '_EntityAttrValidator',\n",
       "     'signature': \"classnapistu.network.net_create._EntityAttrValidator(*,table:str,variable:str,trans:str|None='identity')\\uf0c1\",\n",
       "     'id': 'napistu.network.net_create._EntityAttrValidator',\n",
       "     'doc': 'Bases: BaseModel _abc_impl = <_abc._abc_data object> \\uf0c1 model_config : ClassVar [ ConfigDict ] = {} \\uf0c1 Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict]. table : str \\uf0c1 trans : str | None \\uf0c1 variable : str \\uf0c1',\n",
       "     'methods': {},\n",
       "     'attributes': {'_abc_impl': {'name': '_abc_impl',\n",
       "       'signature': '_abc_impl=<_abc._abc_dataobject>\\uf0c1',\n",
       "       'id': 'napistu.network.net_create._EntityAttrValidator._abc_impl',\n",
       "       'doc': ''},\n",
       "      'model_config': {'name': 'model_config',\n",
       "       'signature': 'model_config:ClassVar[ConfigDict]={}\\uf0c1',\n",
       "       'id': 'napistu.network.net_create._EntityAttrValidator.model_config',\n",
       "       'doc': 'Configuration for the model, should be a dictionary conforming to [ ConfigDict ][pydantic.config.ConfigDict].'},\n",
       "      'table': {'name': 'table',\n",
       "       'signature': 'table:str\\uf0c1',\n",
       "       'id': 'napistu.network.net_create._EntityAttrValidator.table',\n",
       "       'doc': ''},\n",
       "      'trans': {'name': 'trans',\n",
       "       'signature': 'trans:str|None\\uf0c1',\n",
       "       'id': 'napistu.network.net_create._EntityAttrValidator.trans',\n",
       "       'doc': ''},\n",
       "      'variable': {'name': 'variable',\n",
       "       'signature': 'variable:str\\uf0c1',\n",
       "       'id': 'napistu.network.net_create._EntityAttrValidator.variable',\n",
       "       'doc': ''}}}}},\n",
       "  'net_propagation': {'module': 'napistu.network.net_propagation',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_propagation.html#module-napistu.network.net_propagation',\n",
       "   'functions': {'_ensure_nonnegative_vertex_attribute': {'name': '_ensure_nonnegative_vertex_attribute',\n",
       "     'signature': 'napistu.network.net_propagation._ensure_nonnegative_vertex_attribute(g:Graph,attribute:str)\\uf0c1',\n",
       "     'id': 'napistu.network.net_propagation._ensure_nonnegative_vertex_attribute',\n",
       "     'doc': 'Utility to check that a vertex attribute is present, numeric, and non-negative.\\nRaises ValueError if checks fail.\\nMissing or None values are treated as 0.\\nRaises ValueError if attribute is missing for all vertices or all values are zero.'},\n",
       "    'personalized_pagerank_by_attribute': {'name': 'personalized_pagerank_by_attribute',\n",
       "     'signature': 'napistu.network.net_propagation.personalized_pagerank_by_attribute(g:Graph,attribute:str,damping:float=0.85,calculate_uniform_dist:bool=True,additional_propagation_args:dict|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_propagation.personalized_pagerank_by_attribute',\n",
       "     'doc': \"Run personalized PageRank with reset probability proportional to a vertex attribute.\\nOptionally computes uniform PPR over nonzero attribute nodes. Parameters : g ( igraph.Graph ) – The input graph. attribute ( str ) – The vertex attribute to use for personalization. damping ( float , optional ) – Damping factor (default 0.85). calculate_uniform_dist ( bool , optional ) – If True, also compute uniform PPR over nonzero attribute nodes. additional_propagation_args ( dict , optional ) – Additional arguments to pass to igraph’s personalized_pagerank. Keys must match the method’s signature. Returns : DataFrame with columns [‘name’, ‘pagerank_by_attribute’, attribute] and optionally ‘pagerank_uniform’. Return type : pd.DataFrame Example >>> import igraph as ig >>> from scraps.utils import personalized_pagerank_by_attribute >>> g = ig . Graph . Full ( 3 ) >>> g . vs [ 'name' ] = [ 'A' , 'B' , 'C' ] >>> g . vs [ 'score' ] = [ 1 , 0 , 2 ] >>> df = personalized_pagerank_by_attribute ( g , 'score' ) >>> print ( df )\"}},\n",
       "   'classes': {}},\n",
       "  'net_utils': {'module': 'napistu.network.net_utils',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.net_utils.html#module-napistu.network.net_utils',\n",
       "   'functions': {'_create_induced_subgraph': {'name': '_create_induced_subgraph',\n",
       "     'signature': 'napistu.network.net_utils._create_induced_subgraph(cpr_graph:Graph,vertices=None,n_vertices:int=5000)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._create_induced_subgraph',\n",
       "     'doc': 'Utility function for creating subgraphs including a set of vertices and their connections'},\n",
       "    '_create_network_save_string': {'name': '_create_network_save_string',\n",
       "     'signature': 'napistu.network.net_utils._create_network_save_string(model_prefix:str,outdir:str,directed:bool,graph_type:str)→str\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._create_network_save_string',\n",
       "     'doc': ''},\n",
       "    '_get_top_n_component_stats': {'name': '_get_top_n_component_stats',\n",
       "     'signature': 'napistu.network.net_utils._get_top_n_component_stats(graph:Graph,components,component_sizes:Sequence[int],n:int=10,ascending:bool=False)→list[dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._get_top_n_component_stats',\n",
       "     'doc': 'Summarize the top N components’ network properties.'},\n",
       "    '_get_top_n_idx': {'name': '_get_top_n_idx',\n",
       "     'signature': 'napistu.network.net_utils._get_top_n_idx(arr:Sequence,n:int,ascending:bool=False)→Sequence[int]\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._get_top_n_idx',\n",
       "     'doc': 'Returns the indices of the top n values in an array Parameters : arr ( Sequence ) – An array of values n ( int ) – The number of top values to return ascending ( bool , optional ) – Whether to return the top or bottom n values. Defaults to False. Returns : The indices of the top n values Return type : Sequence[int]'},\n",
       "    '_get_top_n_nodes': {'name': '_get_top_n_nodes',\n",
       "     'signature': 'napistu.network.net_utils._get_top_n_nodes(graph:Graph,vals:Sequence,val_name:str,n:int=10,ascending:bool=False)→list[dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._get_top_n_nodes',\n",
       "     'doc': 'Get the top N nodes by a node attribute.'},\n",
       "    '_get_top_n_objects': {'name': '_get_top_n_objects',\n",
       "     'signature': 'napistu.network.net_utils._get_top_n_objects(object_vals:Sequence,objects:Sequence,n:int=10,ascending:bool=False)→list\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._get_top_n_objects',\n",
       "     'doc': 'Get the top N objects based on a ranking measure.'},\n",
       "    '_validate_assets_graph_dist': {'name': '_validate_assets_graph_dist',\n",
       "     'signature': 'napistu.network.net_utils._validate_assets_graph_dist(cpr_graph:Graph,precomputed_distances:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._validate_assets_graph_dist',\n",
       "     'doc': '“Check an cpr_graph and precomputed distances table for inconsistencies.'},\n",
       "    '_validate_assets_sbml_graph': {'name': '_validate_assets_sbml_graph',\n",
       "     'signature': 'napistu.network.net_utils._validate_assets_sbml_graph(sbml_dfs:SBML_dfs,cpr_graph:Graph)→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._validate_assets_sbml_graph',\n",
       "     'doc': '“Check an sbml_dfs model and cpr_graph for inconsistencies.'},\n",
       "    '_validate_edge_attributes': {'name': '_validate_edge_attributes',\n",
       "     'signature': 'napistu.network.net_utils._validate_edge_attributes(graph:Graph,edge_attributes:list[str])→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._validate_edge_attributes',\n",
       "     'doc': 'Check for the existence of one or more edge attributes.'},\n",
       "    '_validate_vertex_attributes': {'name': '_validate_vertex_attributes',\n",
       "     'signature': 'napistu.network.net_utils._validate_vertex_attributes(graph:Graph,vertex_attributes:list[str])→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils._validate_vertex_attributes',\n",
       "     'doc': 'Check for the existence of one or more vertex attributes.'},\n",
       "    'compartmentalize_species': {'name': 'compartmentalize_species',\n",
       "     'signature': 'napistu.network.net_utils.compartmentalize_species(sbml_dfs:SBML_dfs,species:str|list[str])→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.compartmentalize_species',\n",
       "     'doc': 'Compartmentalize Species Returns the compartmentalized species IDs (sc_ids) corresponding to a list of species (s_ids) Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways species ( list ) – Species IDs Return type : pd.DataFrame containings the s_id and sc_id pairs'},\n",
       "    'compartmentalize_species_pairs': {'name': 'compartmentalize_species_pairs',\n",
       "     'signature': 'napistu.network.net_utils.compartmentalize_species_pairs(sbml_dfs:SBML_dfs,origin_species:str|list[str],dest_species:str|list[str])→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.compartmentalize_species_pairs',\n",
       "     'doc': 'Compartmentalize Shortest Paths For a set of origin and destination species pairs, consider each species in every compartment it operates in, seperately. Parameters : sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways origin_species ( list ) – Species IDs as starting points dest_species ( list ) – Species IDs as ending points Return type : pd.DataFrame containing pairs of origin and destination compartmentalized species'},\n",
       "    'cpr_graph_to_pandas_dfs': {'name': 'cpr_graph_to_pandas_dfs',\n",
       "     'signature': 'napistu.network.net_utils.cpr_graph_to_pandas_dfs(cpr_graph:Graph)\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.cpr_graph_to_pandas_dfs',\n",
       "     'doc': 'CPR Graph to Pandas DataFrames Take an igraph representation of a network and turn it into vertices and edges tables. Parameters : cpr_graph ( ig.Graph ) – an igraph network Returns : A table with one row per vertex.\\nedges (pd.DataFrame): A table with one row per edge. Return type : vertices (pd.DataFrame)'},\n",
       "    'export_networks': {'name': 'export_networks',\n",
       "     'signature': \"napistu.network.net_utils.export_networks(sbml_dfs:SBML_dfs,model_prefix:str,outdir:str,directeds:list[bool]=[True,False],graph_types:list[str]=['bipartite','regulatory'])→None\\uf0c1\",\n",
       "     'id': 'napistu.network.net_utils.export_networks',\n",
       "     'doc': 'Exports Networks Create one or more network from a pathway model and pickle the results Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A pathway model model_prefix ( str ) – Label to prepend to all exported files outdir ( str ) – Path to an existing directory where results should be saved directeds ( [ bool ] ) – List of directed types to export: a directed (True) or undirected graph be made (False) graph_types ( [ str ] ) – Types of graphs to construct, valid values are: bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products regulatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products Returns ---------- None'},\n",
       "    'filter_to_largest_subgraph': {'name': 'filter_to_largest_subgraph',\n",
       "     'signature': 'napistu.network.net_utils.filter_to_largest_subgraph(cpr_graph:Graph)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.filter_to_largest_subgraph',\n",
       "     'doc': 'Filter a graph to its largest weakly connected component.'},\n",
       "    'get_graph_summary': {'name': 'get_graph_summary',\n",
       "     'signature': 'napistu.network.net_utils.get_graph_summary(graph:Graph)→dict[str,Any]\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.get_graph_summary',\n",
       "     'doc': 'Calculates common summary statistics for a network Parameters : graph ( ig.Graph ) – An igraph Returns : A dictionary of summary statistics with values n_edges [int]: number of edges\\nn_vertices [int]: number of vertices\\nn_components [int]: number of weakly connected components (i.e. without considering edge directionality) stats_component_sizes [dict[str, float]]: summary statistics for the component sizes\\ntop10_large_components [list[dict[str, Any]]]: the top 10 largest components with 10 example vertices\\ntop10_smallest_components [list[dict[str, Any]]]: the top 10 smallest components with 10 example vertices\\naverage_path_length [float]: the average shortest path length between all vertices\\ntop10_betweenness [list[dict[str, Any]]]: the top 10 vertices by betweenness centrality. Roughly: measures how many shortest paths go through a vertices top10_harmonic_centrality [list[dict[str, Any]]]: the top 10 vertices by harmonic centrality: Roughly: mean inverse distance to all other vertices Return type : dict'},\n",
       "    'get_minimal_sources_edges': {'name': 'get_minimal_sources_edges',\n",
       "     'signature': 'napistu.network.net_utils.get_minimal_sources_edges(vertices:DataFrame,sbml_dfs:SBML_dfs)→DataFrame|None\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.get_minimal_sources_edges',\n",
       "     'doc': 'Assign edges to a set of sources.'},\n",
       "    'read_graph_attrs_spec': {'name': 'read_graph_attrs_spec',\n",
       "     'signature': 'napistu.network.net_utils.read_graph_attrs_spec(graph_attrs_spec_uri:str)→dict\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.read_graph_attrs_spec',\n",
       "     'doc': 'Read a YAML file containing the specification for adding reaction- and/or species-attributes to a cpr_graph.'},\n",
       "    'read_network_pkl': {'name': 'read_network_pkl',\n",
       "     'signature': 'napistu.network.net_utils.read_network_pkl(model_prefix:str,network_dir:str,graph_type:str,directed:bool=True)→Graph\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.read_network_pkl',\n",
       "     'doc': 'Read Network Pickle Read a saved network representation. Params \\uf0c1 model_prefix: str Type of model to import network_dir: str Path to a directory containing all saved networks. directed bool Should a directed (True) or undirected graph be loaded (False) graph_type [str] Type of graphs to read, valid values are: bipartite: substrates and modifiers point to the reaction they drive, this reaction points to products reguatory: non-enzymatic modifiers point to enzymes, enzymes point to substrates and products returns : network_graph – An igraph network of the pathway rtype : igraph.Graph'},\n",
       "    'safe_fill': {'name': 'safe_fill',\n",
       "     'signature': 'napistu.network.net_utils.safe_fill(x,fill_width=15)\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.safe_fill',\n",
       "     'doc': ''},\n",
       "    'validate_assets': {'name': 'validate_assets',\n",
       "     'signature': 'napistu.network.net_utils.validate_assets(sbml_dfs:SBML_dfs,cpr_graph:Graph,precomputed_distances:DataFrame,identifiers_df:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.network.net_utils.validate_assets',\n",
       "     'doc': 'Validate Assets Perform a few quick checks of inputs to catch inconsistencies. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A pathway representation. cpr_graph ( igraph.Graph ) – A network-based representation of “sbml_dfs”. precomputed_distances ( pd.DataFrame ) – Precomputed distances between vertices in “cpr_graph”. identifiers_df ( pd.DataFrame ) – A table of systematic identifiers for compartmentalized species in “sbml_dfs”. Returns : None'}},\n",
       "   'classes': {}},\n",
       "  'paths': {'module': 'napistu.network.paths',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.paths.html#module-napistu.network.paths',\n",
       "   'functions': {'_calculate_net_polarity': {'name': '_calculate_net_polarity',\n",
       "     'signature': 'napistu.network.paths._calculate_net_polarity(link_polarity_series:Series)→str\\uf0c1',\n",
       "     'id': 'napistu.network.paths._calculate_net_polarity',\n",
       "     'doc': 'Determine whether a path implies activation, inhbition, or an ambiguous regulatory relationship.'},\n",
       "    '_filter_paths_by_precomputed_distances': {'name': '_filter_paths_by_precomputed_distances',\n",
       "     'signature': 'napistu.network.paths._filter_paths_by_precomputed_distances(all_species_pairs:DataFrame,precomputed_distances:DataFrame|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.network.paths._filter_paths_by_precomputed_distances',\n",
       "     'doc': 'Filter source -> destination pairs based on precomputed distances if they were provided.'},\n",
       "    '_label_path_reactions': {'name': '_label_path_reactions',\n",
       "     'signature': 'napistu.network.paths._label_path_reactions(sbml_dfs:SBML_dfs,paths_df:DataFrame)\\uf0c1',\n",
       "     'id': 'napistu.network.paths._label_path_reactions',\n",
       "     'doc': 'Create labels for reactions in a shortest path.'},\n",
       "    '_patch': {'name': '_patch',\n",
       "     'signature': 'napistu.network.paths._patch(x:Any)\\uf0c1',\n",
       "     'id': 'napistu.network.paths._patch',\n",
       "     'doc': ''},\n",
       "    '_terminal_net_polarity': {'name': '_terminal_net_polarity',\n",
       "     'signature': 'napistu.network.paths._terminal_net_polarity(link_polarity_series:Series)→str\\uf0c1',\n",
       "     'id': 'napistu.network.paths._terminal_net_polarity',\n",
       "     'doc': 'Figure out the net polarity for the vertex at the end of a path.'},\n",
       "    'find_all_shortest_reaction_paths': {'name': 'find_all_shortest_reaction_paths',\n",
       "     'signature': \"napistu.network.paths.find_all_shortest_reaction_paths(cpr_graph:Graph,sbml_dfs:SBML_dfs,target_species_paths:DataFrame,weight_var:str='weights',precomputed_distances:DataFrame|None=None)\\uf0c1\",\n",
       "     'id': 'napistu.network.paths.find_all_shortest_reaction_paths',\n",
       "     'doc': 'Shortest Reaction Paths Find all shortest paths between a source and destination entity Parameters : cpr_graph ( igraph.Graph ) – A bipartite network connecting molecular species and reactions sbml_dfs ( SBML_dfs ) – A model formed by aggregating pathways target_species_paths ( pd.DataFrame ) – Pairs of source and destination compartmentalized species; produced by compartmentalize_species_pairs() weight_var ( str ) – An edge attribute to use when forming a weighted shortest path precomputed_distances ( pd.DataFrame | None ) – A table containing precalculated path summaries between pairs of compartmentalized species Returns ---------- all_shortest_reaction_paths_df ( pd.DataFrame ) – Nodes in all shortest paths all_shortest_reaction_path_edges_df ( pd.DataFrame ) – Edges in all shortest paths edge_sources ( pd.DataFrame ) – Sources of edge identifying the models where they originated paths_graph ( igraph.Graph ) – Network formed by all shortest paths'},\n",
       "    'find_shortest_reaction_paths': {'name': 'find_shortest_reaction_paths',\n",
       "     'signature': 'napistu.network.paths.find_shortest_reaction_paths(cpr_graph:Graph,sbml_dfs:SBML_dfs,origin:str,dest:str|list,weight_var:str)→tuple[DataFrame,DataFrame]|None\\uf0c1',\n",
       "     'id': 'napistu.network.paths.find_shortest_reaction_paths',\n",
       "     'doc': 'Shortest Reaction Paths Find all shortest paths between an origin and destination entity Parameters : cpr_graph ( igraph.Graph ) – A bipartite network connecting molecular species and reactions sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A model formed by aggregating pathways origin ( str ) – A node to start at dest ( str | list ) – Node(s) to reach weight_var ( str ) – An edge attribute to use when forming a weighted shortest path Returns ---------- pd.DataFrames ( Node paths and edges )'},\n",
       "    'plot_shortest_paths': {'name': 'plot_shortest_paths',\n",
       "     'signature': 'napistu.network.paths.plot_shortest_paths(paths_graph:Graph)→plot\\uf0c1',\n",
       "     'id': 'napistu.network.paths.plot_shortest_paths',\n",
       "     'doc': 'Plot a shortest paths graph.'}},\n",
       "   'classes': {}},\n",
       "  'precompute': {'module': 'napistu.network.precompute',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.network.precompute.html#module-napistu.network.precompute',\n",
       "   'functions': {'_calculate_distances_subset': {'name': '_calculate_distances_subset',\n",
       "     'signature': \"napistu.network.precompute._calculate_distances_subset(cpr_graph:Graph,vs_to_partition:DataFrame,one_partition:DataFrame,weights_vars:list[str]=['weights','upstream_weights'])→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.network.precompute._calculate_distances_subset',\n",
       "     'doc': 'Calculate distances from a subset of vertices to all vertices.'},\n",
       "    '_filter_precomputed_distances': {'name': '_filter_precomputed_distances',\n",
       "     'signature': \"napistu.network.precompute._filter_precomputed_distances(precomputed_distances:DataFrame,max_steps:float|int=inf,max_score_q:float=1,path_weights_vars:list[str]=['path_weights','path_upstream_weights'])→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.network.precompute._filter_precomputed_distances',\n",
       "     'doc': 'Filter precomputed distances by maximum steps and/or to low scores by quantile.'},\n",
       "    'precompute_distances': {'name': 'precompute_distances',\n",
       "     'signature': \"napistu.network.precompute.precompute_distances(cpr_graph:Graph,max_steps:int=-1,max_score_q:float=1.0,partition_size:int=5000,weights_vars:list[str]=['weights','upstream_weights'])→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.network.precompute.precompute_distances',\n",
       "     'doc': 'Pre-Compute Distances Parameters : cpr_graph ( ig.Graph ) – An igraph network model max_steps ( int ) – The maximum number of steps between pairs of species to save a distance max_score_q ( float ) – Retain up to the “max_score_q” quantiles of all scores (small scores are better) partition_size ( int ) – The number of species to process together when computing distances. Decreasing this\\nvalue will lower the overall memory footprint of distance calculation. weights_vars ( list ) – One or more variables defining edge weights to use when calculating weighted\\nshortest paths. Shortest paths will be separately calculated with each type of\\nweights and used to construct path weights named according to ‘path_{weight_var}’ Returns ---------- containing ( A pd.DataFrame ) sc_id_origin ( - ) sc_id_dest ( - ) path_length ( - ) path_weight* ( - ) – * One variable will exist for each weight specified in ‘weights_vars’'}},\n",
       "   'classes': {}}},\n",
       " 'napistu.ingestion': {'bigg': {'module': 'napistu.ingestion.bigg',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.bigg.html#module-napistu.ingestion.bigg',\n",
       "   'functions': {'annotate_recon': {'name': 'annotate_recon',\n",
       "     'signature': 'napistu.ingestion.bigg.annotate_recon(raw_model_path:str,annotated_model_path:str)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.bigg.annotate_recon',\n",
       "     'doc': 'Annotate Recon3D\\nAdd compartment annotations to Recon3D so it can be merged with other pathways'},\n",
       "    'bigg_sbml_download': {'name': 'bigg_sbml_download',\n",
       "     'signature': 'napistu.ingestion.bigg.bigg_sbml_download(bg_pathway_root:str,overwrite:bool=False)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.bigg.bigg_sbml_download',\n",
       "     'doc': 'BiGG SBML Download Download SBML models from BiGG. Currently just the human Recon3D model Parameters:\\nbg_pathway_root (str): Paths to a directory where a “sbml” directory should be created.\\noverwrite (bool): Overwrite an existing output directory. Returns:\\nNone'},\n",
       "    'construct_bigg_consensus': {'name': 'construct_bigg_consensus',\n",
       "     'signature': 'napistu.ingestion.bigg.construct_bigg_consensus(pw_index_inp:str|PWIndex,species:str|Iterable[str]|None=None,outdir:str|None=None)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.ingestion.bigg.construct_bigg_consensus',\n",
       "     'doc': 'Constructs a BiGG SBML DFs Pathway Representation Attention: curently this does work only for a singly model. Integraiton of multiple\\nmodels is not supported yet in BiGG. Parameters : pw_index_inp ( str | indices.PWIndex ) – PWIndex or uri pointing to PWIndex species ( str | Iterable [ str ] | None ) – one or more species to filter by. Default: no filtering outdir ( str | None , optional ) – output directory used to cache results. Defaults to None. Returns : A consensus SBML Return type : sbml_dfs_core.SBML_dfs'}},\n",
       "   'classes': {}},\n",
       "  'constants': {'module': 'napistu.ingestion.constants',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.constants.html#module-napistu.ingestion.constants',\n",
       "   'functions': {},\n",
       "   'classes': {}},\n",
       "  'cpr_edgelist': {'module': 'napistu.ingestion.cpr_edgelist',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.cpr_edgelist.html#module-napistu.ingestion.cpr_edgelist',\n",
       "   'functions': {'count_fraction_of_reciprocal_interactions': {'name': 'count_fraction_of_reciprocal_interactions',\n",
       "     'signature': 'napistu.ingestion.cpr_edgelist.count_fraction_of_reciprocal_interactions(edgelist:DataFrame,extra_defining_vars:list=[])→float\\uf0c1',\n",
       "     'id': 'napistu.ingestion.cpr_edgelist.count_fraction_of_reciprocal_interactions',\n",
       "     'doc': 'Count the fraction of A-B edges which also show up as B-A edges Parameters : edgelist ( pd.DataFrame ) – edgelist (pd.DataFrame): edgelist where the first two\\ncolumns are assumed to be the edge vertices extra_defining_vars ( list ) – list (which can be empty) of variables which define\\na unique interaction beyond the vertices Returns : fraction of A-B edges which are also included as B-A edges Return type : fraction (float)'},\n",
       "    'remove_reciprocal_interactions': {'name': 'remove_reciprocal_interactions',\n",
       "     'signature': 'napistu.ingestion.cpr_edgelist.remove_reciprocal_interactions(edgelist:DataFrame,extra_defining_vars:list=[])→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.cpr_edgelist.remove_reciprocal_interactions',\n",
       "     'doc': 'Remove reciprocal edges from an edgelist (i.e., if B-A always exists for every A-B then remove B-A) Parameters : edgelist ( pd.DataFrame ) – edgelist (pd.DataFrame): edgelist where the first two\\ncolumns are assumed to be the edge vertices extra_defining_vars ( list ) – list (which can be empty) of variables which define\\na unique interaction beyond the vertices Returns : edgelist with B-A edges removed and A-B retained Return type : indegenerate_edgelist (pd.DataFrame)'}},\n",
       "   'classes': {}},\n",
       "  'identifiers_etl': {'module': 'napistu.ingestion.identifiers_etl',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.identifiers_etl.html#module-napistu.ingestion.identifiers_etl',\n",
       "   'functions': {'read_sbo_ontology': {'name': 'read_sbo_ontology',\n",
       "     'signature': \"napistu.ingestion.identifiers_etl.read_sbo_ontology(url:str='https://raw.githubusercontent.com/EBI-BioModels/SBO/master/SBO_OBO.obo',verbose:bool=False)→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.identifiers_etl.read_sbo_ontology',\n",
       "     'doc': 'Read SBO Ontology\\nRead the Systems Biology Ontology (SBO) identifiers and reformat the obo results into a pd.DataFrame. Params: url (str): url to the obo specification file\\nverbose (bool): throw warnings when attributes are overwritten Returns : pd.DataFrame'},\n",
       "    'read_yeast_identifiers': {'name': 'read_yeast_identifiers',\n",
       "     'signature': \"napistu.ingestion.identifiers_etl.read_yeast_identifiers(url:str='https://www.uniprot.org/docs/yeast.txt')\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.identifiers_etl.read_yeast_identifiers',\n",
       "     'doc': 'Read Yeast Identifiers\\nGenerate a pd.DataFrame which maps between yeast identifiers including\\ncommon and systematic (OLN) names, as well as Swiss-Prot and SGD identifiers. Params: url (str): url to the identifier file Returns : pd.DataFrame with one row per gene'}},\n",
       "   'classes': {}},\n",
       "  'obo': {'module': 'napistu.ingestion.obo',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.obo.html#module-napistu.ingestion.obo',\n",
       "   'functions': {'_download_go_basic_obo': {'name': '_download_go_basic_obo',\n",
       "     'signature': \"napistu.ingestion.obo._download_go_basic_obo(local_obo_path:str='/tmp/go-basic.obo')→None\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.obo._download_go_basic_obo',\n",
       "     'doc': 'Download an OBO file containing GO categories and their relations (but not the genes in each category).'},\n",
       "    '_find_obo_attrib_dups': {'name': '_find_obo_attrib_dups',\n",
       "     'signature': 'napistu.ingestion.obo._find_obo_attrib_dups(one_term)→list\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo._find_obo_attrib_dups',\n",
       "     'doc': 'Identify attributes which are present multiple times.'},\n",
       "    '_format_entry_tuple': {'name': '_format_entry_tuple',\n",
       "     'signature': 'napistu.ingestion.obo._format_entry_tuple(line_str:str)→tuple|None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo._format_entry_tuple',\n",
       "     'doc': 'Split and return a colon-separated tuple.'},\n",
       "    '_isa_str_list_to_dict_list': {'name': '_isa_str_list_to_dict_list',\n",
       "     'signature': 'napistu.ingestion.obo._isa_str_list_to_dict_list(isa_list:list)→list[dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo._isa_str_list_to_dict_list',\n",
       "     'doc': 'Split parent-child relationships from individual strings to dictionaries where parent and child are separated.'},\n",
       "    '_reformat_obo_entry_as_dict': {'name': '_reformat_obo_entry_as_dict',\n",
       "     'signature': 'napistu.ingestion.obo._reformat_obo_entry_as_dict(one_term,degenerate_attribs)→dict\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo._reformat_obo_entry_as_dict',\n",
       "     'doc': ''},\n",
       "    'create_go_ancestors_df': {'name': 'create_go_ancestors_df',\n",
       "     'signature': 'napistu.ingestion.obo.create_go_ancestors_df(parent_child_graph:Graph)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo.create_go_ancestors_df',\n",
       "     'doc': 'Create GO Ancestors DataFrame Parameters : parent_child_graph ( ig.Graph ) – a DAG formed from parent-child relationships. Returns : a table with: go_id: GO ID of a CC GO term of interest ancestor_id: An ancestor (parent, parent of parent, …)’s GO CC ID Return type : go_ancestors_df (pd.DataFrame)'},\n",
       "    'create_go_parents_df': {'name': 'create_go_parents_df',\n",
       "     'signature': 'napistu.ingestion.obo.create_go_parents_df(go_basic_obo_df:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo.create_go_parents_df',\n",
       "     'doc': 'Create the GO Parents Table Reformat a table with GO attributes into a table with child-parent relationships Parameters : go_basic_obo_df ( pd.DataFrame ) – Table generated from parsing go-basic.obo with\\nobo.format_obo_dict_as_df Returns : a table with: parent_id: GO ID of parent (from an is-a entry) parent_name: common name of parent (from an is-a entry) child_id: GO ID from the index Return type : go_parents_df (pd.DataFrame)'},\n",
       "    'create_parent_child_graph': {'name': 'create_parent_child_graph',\n",
       "     'signature': 'napistu.ingestion.obo.create_parent_child_graph(go_parents_df:DataFrame)→Graph\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo.create_parent_child_graph',\n",
       "     'doc': 'Create Parent:Child Graph Format the Simple GO CC Ontology as a Directed Acyclic Graph (DAG). Parameters : go_parents_df ( pd.DataFrame ) – a table with:\\n- parent_id: GO ID of parent (from an is-a entry)\\n- parent_name: common name of parent (from an is-a entry)\\n- child_id: GO ID from the index Returns : a DAG formed from parent-child relationships. Return type : parent_child_graph (ig.Graph)'},\n",
       "    'format_obo_dict_as_df': {'name': 'format_obo_dict_as_df',\n",
       "     'signature': 'napistu.ingestion.obo.format_obo_dict_as_df(obo_term_dict:dict)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo.format_obo_dict_as_df',\n",
       "     'doc': 'Format an OBO Dict as a DataFrame Reorganize a dictionary of tuples into a DataFrame Parameters : term_dict ( dict ) – dictionary where keys are ids and values are tuples\\ncontaining (attribute, value) pairs Returns obo_df (pd.DataFrame): A pd.DataFrame with one row per identifier and one columns for unique attribute'},\n",
       "    'read_obo_as_dict': {'name': 'read_obo_as_dict',\n",
       "     'signature': 'napistu.ingestion.obo.read_obo_as_dict(local_obo_path:str)→dict\\uf0c1',\n",
       "     'id': 'napistu.ingestion.obo.read_obo_as_dict',\n",
       "     'doc': 'Read OBO as Dictionary The Open Biological and Biomedical Ontologies (OBO) format is a standard format\\nfor representing ontologies. Many parsers exist for obo but since we are not\\nrelying extensively on it and we are trying to minimize dependencies here we provide a\\nfew functions for parsing standard obo formats. Parameters : local_obo_path ( str ) – path to a local obo file. Returns term_dict (dict): dictionary where keys are ids and values are tuples containing (attribute, value) pairs'}},\n",
       "   'classes': {}},\n",
       "  'psi_mi': {'module': 'napistu.ingestion.psi_mi',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.psi_mi.html#module-napistu.ingestion.psi_mi',\n",
       "   'functions': {'_download_intact_species': {'name': '_download_intact_species',\n",
       "     'signature': \"napistu.ingestion.psi_mi._download_intact_species(species:str,output_dir_path:str='/tmp/intact_tmp',overwrite:bool=False)\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.psi_mi._download_intact_species',\n",
       "     'doc': 'Download IntAct Species Download the PSM-30 XML files from IntAct for a species of interest. Parameters : species ( str ) – The species name (Genus species) to work with output_dir_path ( str ) – Local directory to create an unzip files into overwrite ( bool ) – Overwrite an existing output directory. Default: False Returns : None'},\n",
       "    '_format_entry': {'name': '_format_entry',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry(an_entry)→dict[str,Any]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry',\n",
       "     'doc': 'Extract a single XML entry of interactors and interactions.'},\n",
       "    '_format_entry_experiment': {'name': '_format_entry_experiment',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_experiment(an_entry)→dict[str,str]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_experiment',\n",
       "     'doc': 'Format experiment-level information in an XML entry.'},\n",
       "    '_format_entry_interaction': {'name': '_format_entry_interaction',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_interaction(interaction)→dict[str,Any]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_interaction',\n",
       "     'doc': 'Format a single interaction in an XML interaction list.'},\n",
       "    '_format_entry_interaction_participants': {'name': '_format_entry_interaction_participants',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_interaction_participants(interaction_participant)→dict[str,str]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_interaction_participants',\n",
       "     'doc': 'Format the participants in an XML interaction.'},\n",
       "    '_format_entry_interactions': {'name': '_format_entry_interactions',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_interactions(an_entry)→list[dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_interactions',\n",
       "     'doc': 'Format the molecular interaction in an XML entry.'},\n",
       "    '_format_entry_interactor': {'name': '_format_entry_interactor',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_interactor(interactor)→dict[str,Any]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_interactor',\n",
       "     'doc': 'Format a single molecular interactor in an interaction list XML node.'},\n",
       "    '_format_entry_interactor_list': {'name': '_format_entry_interactor_list',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_interactor_list(an_entry)→list[dict[str,Any]]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_interactor_list',\n",
       "     'doc': 'Format the molecular interactors in an XML entry.'},\n",
       "    '_format_entry_interactor_xrefs': {'name': '_format_entry_interactor_xrefs',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_interactor_xrefs(interactor)→list[dict[str,str]]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_interactor_xrefs',\n",
       "     'doc': 'Format the cross-references of a single interactor.'},\n",
       "    '_format_entry_source': {'name': '_format_entry_source',\n",
       "     'signature': 'napistu.ingestion.psi_mi._format_entry_source(an_entry)→dict[str,str]\\uf0c1',\n",
       "     'id': 'napistu.ingestion.psi_mi._format_entry_source',\n",
       "     'doc': 'Format the source describing the provenance of an XML entry.'},\n",
       "    'format_psi': {'name': 'format_psi',\n",
       "     'signature': \"napistu.ingestion.psi_mi.format_psi(xml_path:str,xml_namespace:str='{http://psi.hupo.org/mi/mif300}')→list[dict[str,Any]]\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.psi_mi.format_psi',\n",
       "     'doc': 'Format PSI 3.0 Format an .xml file containing molecular interactions following the PSI 3.0 format. Parameters : xml_path ( str ) – path to a .xml file xml_namespace ( str ) – Namespace for the xml file Returns : a list containing molecular interaction entry dicts of the format: source : dict containing the database that interactions were drawn from. experiment : a simple summary of the experimental design and the publication. interactor_list : list containing dictionaries annotating the molecules\\n(defined by their “interactor_id”) involved in interactions. interactions_list : list containing dictionaries annotating molecular\\ninteractions involving a set of “interactor_id”s. Return type : entry_list (list)'}},\n",
       "   'classes': {}},\n",
       "  'reactome': {'module': 'napistu.ingestion.reactome',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.reactome.html#module-napistu.ingestion.reactome',\n",
       "   'functions': {'_build_reactome_pw_index': {'name': '_build_reactome_pw_index',\n",
       "     'signature': 'napistu.ingestion.reactome._build_reactome_pw_index(output_dir:str,file_ext:str,species_filter:Iterable[str]|None=None)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.reactome._build_reactome_pw_index',\n",
       "     'doc': 'Build a reactome pathway index Builds the index based on available files and cross-checkes it with the\\nexpected reactome pathway list. Parameters : output_dir ( str ) – File directory file_ext ( str ) – File extension species_filter ( Optional [ Iterable [ str ] ] , optional ) – Filter the expected\\npathway list based on a list of species. Eg in cases only one species available. Defaults to None. Returns : pathway index Return type : pd.DataFrame'},\n",
       "    '_check_reactome_pw_index': {'name': '_check_reactome_pw_index',\n",
       "     'signature': 'napistu.ingestion.reactome._check_reactome_pw_index(pw_index:PWIndex,reactome_pathway_list:list)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.reactome._check_reactome_pw_index',\n",
       "     'doc': 'Compare local files defined in the pathway index to a list of Reactome’s pathways.'},\n",
       "    '_get_reactome_pathway_list': {'name': '_get_reactome_pathway_list',\n",
       "     'signature': 'napistu.ingestion.reactome._get_reactome_pathway_list()\\uf0c1',\n",
       "     'id': 'napistu.ingestion.reactome._get_reactome_pathway_list',\n",
       "     'doc': 'Reactome Pathway List\\nProduce a pd.DataFrame listing all pathways in reactome and their internal ids Parameters : None Returns : pd.DataFrame containing pathway_id, name and species'},\n",
       "    'construct_reactome_consensus': {'name': 'construct_reactome_consensus',\n",
       "     'signature': 'napistu.ingestion.reactome.construct_reactome_consensus(pw_index_inp:str|PWIndex,species:str|Iterable[str]|None=None,outdir:str|None=None,strict:bool=True)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.ingestion.reactome.construct_reactome_consensus',\n",
       "     'doc': 'Constructs a basic consensus model by merging all models from a pw_index Parameters : pw_index_inp ( str | indices.PWIndex ) – PWIndex or uri pointing to PWIndex species ( str | Iterable [ str ] | None ) – one or more species to filter by. Default: no filtering outdir ( str | None , optional ) – output directory used to cache results. Defaults to None. strict ( bool ) – should failure of loading any given model throw an exception? If False a warning is thrown. Returns : A consensus SBML Return type : sbml_dfs_core.SBML_dfs'},\n",
       "    'reactome_sbml_download': {'name': 'reactome_sbml_download',\n",
       "     'signature': 'napistu.ingestion.reactome.reactome_sbml_download(output_dir_path:str,overwrite:bool=False)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.reactome.reactome_sbml_download',\n",
       "     'doc': 'Reactome SBML Download Download Reactome SBML (systems biology markup language) for all reactome species. Parameters : output_dir_path ( str ) – Paths to a directory where .sbml files should be saved. overwrite ( bool ) – Overwrite an existing output directory. Default: False'}},\n",
       "   'classes': {}},\n",
       "  'sbml': {'module': 'napistu.ingestion.sbml',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.sbml.html#module-napistu.ingestion.sbml',\n",
       "   'functions': {'_get_gene_product_dict': {'name': '_get_gene_product_dict',\n",
       "     'signature': 'napistu.ingestion.sbml._get_gene_product_dict(gp)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.sbml._get_gene_product_dict',\n",
       "     'doc': 'Read a gene product node from an sbml file.'},\n",
       "    'add_sbml_annotations': {'name': 'add_sbml_annotations',\n",
       "     'signature': 'napistu.ingestion.sbml.add_sbml_annotations(sbml_model:SBML,annotations:DataFrame,save_path:str)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.sbml.add_sbml_annotations',\n",
       "     'doc': 'Add SBML Annotations Add additional identifiers to an sbml file and save the updated document Parameters:\\nsbml_model: SBML A .sbml model annotations: pd.DataFrame A table of annotations to add containing an “id” matching the\\nprimary key of an entity, “type” matching the type of entity,\\nand “uri” representing the annotation to add. save_path: str Path to save the model to Returns:\\nNone'},\n",
       "    'sbml_df_from_sbml': {'name': 'sbml_df_from_sbml',\n",
       "     'signature': 'napistu.ingestion.sbml.sbml_df_from_sbml(self,sbml_model:SBML)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.sbml.sbml_df_from_sbml',\n",
       "     'doc': ''},\n",
       "    'setup_cspecies': {'name': 'setup_cspecies',\n",
       "     'signature': 'napistu.ingestion.sbml.setup_cspecies(sbml_model:SBML)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.sbml.setup_cspecies',\n",
       "     'doc': 'Setup Compartmentalized Species Read all compartmentalized species from a model\\nand setup as a pd.DataFrame.\\nThis operation is functionalized to test the subsequent call of\\nconsensus.reduce_to_consensus_ids()\\nwhich collapses compartmentalized_species -> species\\nbased on shared identifiers.'}},\n",
       "   'classes': {'SBML': {'name': 'SBML',\n",
       "     'signature': 'classnapistu.ingestion.sbml.SBML(sbml_path:str)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.sbml.SBML',\n",
       "     'doc': 'Bases: object System Biology Markup Language Connections. document \\uf0c1 Connection to the SBML document model \\uf0c1 Connection to the SBML model summary ( ) \\uf0c1 Prints a summary of the sbml model sbml_errors ( reduced_log , return_df ) \\uf0c1 Print a summary of all errors in the SBML file __init__ ( sbml_path : str ) → None \\uf0c1 Connects to an SBML file Parameters : sbml_path ( str ) – path to a .sbml file. Return type : None. sbml_errors ( reduced_log : bool = True , return_df : bool = False ) \\uf0c1 Format and print all SBML errors Parameters : reduced_log ( bool ) – Reduced log aggregates errors across categories an severity levels return_df ( bool ) – If False then print a log, if True then return a pd.DataFrame Return type : None or pd.DataFrame. summary ( ) → DataFrame \\uf0c1 Returns a pd.DataFrame summary of an SBML model.',\n",
       "     'methods': {'summary': {'name': 'summary',\n",
       "       'signature': 'summary()→DataFrame\\uf0c1',\n",
       "       'id': 'id1',\n",
       "       'doc': 'Returns a pd.DataFrame summary of an SBML model.'},\n",
       "      'sbml_errors': {'name': 'sbml_errors',\n",
       "       'signature': 'sbml_errors(reduced_log:bool=True,return_df:bool=False)\\uf0c1',\n",
       "       'id': 'id0',\n",
       "       'doc': 'Format and print all SBML errors Parameters : reduced_log ( bool ) – Reduced log aggregates errors across categories an severity levels return_df ( bool ) – If False then print a log, if True then return a pd.DataFrame Return type : None or pd.DataFrame.'},\n",
       "      '__init__': {'name': '__init__',\n",
       "       'signature': '__init__(sbml_path:str)→None\\uf0c1',\n",
       "       'id': 'napistu.ingestion.sbml.SBML.__init__',\n",
       "       'doc': 'Connects to an SBML file Parameters : sbml_path ( str ) – path to a .sbml file. Return type : None.'}},\n",
       "     'attributes': {'document': {'name': 'document',\n",
       "       'signature': 'document\\uf0c1',\n",
       "       'id': 'napistu.ingestion.sbml.SBML.document',\n",
       "       'doc': 'Connection to the SBML document'},\n",
       "      'model': {'name': 'model',\n",
       "       'signature': 'model\\uf0c1',\n",
       "       'id': 'napistu.ingestion.sbml.SBML.model',\n",
       "       'doc': 'Connection to the SBML model'}}},\n",
       "    'SBML_reaction': {'name': 'SBML_reaction',\n",
       "     'signature': 'classnapistu.ingestion.sbml.SBML_reaction(sbml_reaction:Reaction)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.sbml.SBML_reaction',\n",
       "     'doc': 'Bases: object System Biology Markup Language Model Reactions. reaction_dict \\uf0c1 dictionary of reaction-level attributes, id, name, identifiers Type : dict species \\uf0c1 table of substrates, products, and modifiers Type : pd.DataFrame __init__ ( sbml_reaction : Reaction ) → None \\uf0c1 Convenience class for working with sbml reactions',\n",
       "     'methods': {'__init__': {'name': '__init__',\n",
       "       'signature': '__init__(sbml_reaction:Reaction)→None\\uf0c1',\n",
       "       'id': 'napistu.ingestion.sbml.SBML_reaction.__init__',\n",
       "       'doc': 'Convenience class for working with sbml reactions'}},\n",
       "     'attributes': {'reaction_dict': {'name': 'reaction_dict',\n",
       "       'signature': 'reaction_dict\\uf0c1',\n",
       "       'id': 'napistu.ingestion.sbml.SBML_reaction.reaction_dict',\n",
       "       'doc': 'dictionary of reaction-level attributes, id, name, identifiers Type : dict'},\n",
       "      'species': {'name': 'species',\n",
       "       'signature': 'species\\uf0c1',\n",
       "       'id': 'napistu.ingestion.sbml.SBML_reaction.species',\n",
       "       'doc': 'table of substrates, products, and modifiers Type : pd.DataFrame'}}}}},\n",
       "  'string': {'module': 'napistu.ingestion.string',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.string.html#module-napistu.ingestion.string',\n",
       "   'functions': {'_build_interactor_edgelist': {'name': '_build_interactor_edgelist',\n",
       "     'signature': \"napistu.ingestion.string._build_interactor_edgelist(edgelist:DataFrame,upstream_col_name:str='protein1',downstream_col_name:str='protein2',add_reverse_interactions:bool=False,sbo_term:str='interactor',compartment:str='cellular_component')→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.string._build_interactor_edgelist',\n",
       "     'doc': 'Format STRING interactions as reactions.'},\n",
       "    '_build_species_df': {'name': '_build_species_df',\n",
       "     'signature': \"napistu.ingestion.string._build_species_df(edgelist:DataFrame,aliases:DataFrame,alias_to_identifier:dict,source_col:str='protein1',target_col:str='protein2')→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.ingestion.string._build_species_df',\n",
       "     'doc': 'Builds the species dataframe from the edgelist and aliases Parameters : edgelist ( pd.DataFrame ) – edgelist aliases ( pd.DataFrame ) – aliases alias_to_identifier ( dict [ str , tuple [ str , str ] ] ) – map from an alias source to an ontology and a qualifier Returns : species dataframe Return type : pd.DataFrame'},\n",
       "    '_build_string_reaction_name': {'name': '_build_string_reaction_name',\n",
       "     'signature': 'napistu.ingestion.string._build_string_reaction_name(from_col:Series,to_col:Series)→Series\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string._build_string_reaction_name',\n",
       "     'doc': 'Helper to build the reaction name for string reactions Parameters : from_col ( pd.Series ) – from species to_col ( pd.Series ) – to species Returns : new name column Return type : pd.Series'},\n",
       "    '_get_identifiers': {'name': '_get_identifiers',\n",
       "     'signature': 'napistu.ingestion.string._get_identifiers(row:DataFrame,alias_to_identifier:dict[str,tuple[str,str]],dat_alias:DataFrame)→Identifiers\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string._get_identifiers',\n",
       "     'doc': 'Helper function to get identifiers from a row of the string alias file Parameters : row ( pd.DataFrame ) – grouped dataframe alias_to_identifier ( dict [ str , tuple [ str , str ] ] ) – map from an alias source to an ontology and a qualifier dat_alias ( pd.DataFrame ) – Helper dataframe with index=string_protein_id\\nand columns=source (the source name), alias (the identifier) Returns : An Identifiers object containing all identifiers Return type : identifiers.Identifiers'},\n",
       "    '_read_string': {'name': '_read_string',\n",
       "     'signature': 'napistu.ingestion.string._read_string(string_uri:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string._read_string',\n",
       "     'doc': 'Reads string from uri Parameters : string_uri ( str ) – string uri Returns : string edgelist Return type : pd.DataFrame'},\n",
       "    '_read_string_aliases': {'name': '_read_string_aliases',\n",
       "     'signature': 'napistu.ingestion.string._read_string_aliases(string_aliases_uri:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string._read_string_aliases',\n",
       "     'doc': 'Reads string from uri Parameters : string_aliases_uri ( str ) – string aliases uri Returns : string aliases Return type : pd.DataFrame'},\n",
       "    'convert_string_to_sbml_dfs': {'name': 'convert_string_to_sbml_dfs',\n",
       "     'signature': 'napistu.ingestion.string.convert_string_to_sbml_dfs(string_uri:str,string_aliases_uri:str)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string.convert_string_to_sbml_dfs',\n",
       "     'doc': 'Ingests string to sbml dfs Parameters : string_uri ( str ) – string uri string_aliases_uri ( str ) – string aliases uri Returns : sbml dfs Return type : sbml_dfs_core.SBML_dfs'},\n",
       "    'download_string': {'name': 'download_string',\n",
       "     'signature': 'napistu.ingestion.string.download_string(target_uri:str,species:str)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string.download_string',\n",
       "     'doc': 'Downloads string to the target uri Parameters : target_uri ( str ) – target url species ( str ) – A species name: e.g., Homo sapiens Returns : None'},\n",
       "    'download_string_aliases': {'name': 'download_string_aliases',\n",
       "     'signature': 'napistu.ingestion.string.download_string_aliases(target_uri:str,species:str)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string.download_string_aliases',\n",
       "     'doc': 'Downloads string aliases to the target uri Parameters : target_uri ( str ) – target url species ( str ) – A species name: e.g., Homo sapiens Returns : None'},\n",
       "    'get_string_species_url': {'name': 'get_string_species_url',\n",
       "     'signature': 'napistu.ingestion.string.get_string_species_url(species:str,asset:str,version:float=11.5)→str\\uf0c1',\n",
       "     'id': 'napistu.ingestion.string.get_string_species_url',\n",
       "     'doc': 'STRING Species URL\\nConstruct urls for downloading specific STRING tables\\n:param species: A species name: e.g., Homo sapiens.\\n:type species: str\\n:param asset: The type of table to be downloaded. Currently “interactions” or “aliases”.\\n:type asset: str\\n:param version: The version of STRING to work with.\\n:type version: float Returns : The download url Return type : str'}},\n",
       "   'classes': {}},\n",
       "  'trrust': {'module': 'napistu.ingestion.trrust',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.trrust.html#module-napistu.ingestion.trrust',\n",
       "   'functions': {'_format_pubmed_for_interactions': {'name': '_format_pubmed_for_interactions',\n",
       "     'signature': 'napistu.ingestion.trrust._format_pubmed_for_interactions(pubmed_set)\\uf0c1',\n",
       "     'id': 'napistu.ingestion.trrust._format_pubmed_for_interactions',\n",
       "     'doc': 'Format a set of pubmed ids as an Identifiers object.'},\n",
       "    '_get_uniprot_2_symbol_mapping': {'name': '_get_uniprot_2_symbol_mapping',\n",
       "     'signature': 'napistu.ingestion.trrust._get_uniprot_2_symbol_mapping()→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.trrust._get_uniprot_2_symbol_mapping',\n",
       "     'doc': 'Create a mapping from Uniprot IDs to human gene symbols.'},\n",
       "    '_read_trrust': {'name': '_read_trrust',\n",
       "     'signature': 'napistu.ingestion.trrust._read_trrust(trrust_uri:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.ingestion.trrust._read_trrust',\n",
       "     'doc': 'Read trrust csv Parameters : trrust_uri ( str ) – uri to the trrust csv Returns : Data Frame Return type : pd.DataFrame'},\n",
       "    '_summarize_trrust_pairs': {'name': '_summarize_trrust_pairs',\n",
       "     'signature': 'napistu.ingestion.trrust._summarize_trrust_pairs(pair_data:DataFrame)→Series\\uf0c1',\n",
       "     'id': 'napistu.ingestion.trrust._summarize_trrust_pairs',\n",
       "     'doc': 'Summarize a TF->target relationship based on the sign and source of the interaction.'},\n",
       "    'convert_trrust_to_sbml_dfs': {'name': 'convert_trrust_to_sbml_dfs',\n",
       "     'signature': 'napistu.ingestion.trrust.convert_trrust_to_sbml_dfs(trrust_uri:str)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.ingestion.trrust.convert_trrust_to_sbml_dfs',\n",
       "     'doc': 'Ingests trrust to sbml dfs Parameters : trrust_uri ( str ) – trrust uri Returns : sbml_dfs'},\n",
       "    'download_trrust': {'name': 'download_trrust',\n",
       "     'signature': 'napistu.ingestion.trrust.download_trrust(target_uri:str)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.trrust.download_trrust',\n",
       "     'doc': 'Downloads trrust to the target uri Parameters : target_uri ( str ) – target url Returns : None'}},\n",
       "   'classes': {}},\n",
       "  'yeast': {'module': 'napistu.ingestion.yeast',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.ingestion.yeast.html#module-napistu.ingestion.yeast',\n",
       "   'functions': {'_summarize_idea_pairs': {'name': '_summarize_idea_pairs',\n",
       "     'signature': 'napistu.ingestion.yeast._summarize_idea_pairs(pairs_data:DataFrame)→Series\\uf0c1',\n",
       "     'id': 'napistu.ingestion.yeast._summarize_idea_pairs',\n",
       "     'doc': 'Rollup multiple records of a TF->target pair into a single summary.'},\n",
       "    'convert_idea_kinetics_to_sbml_dfs': {'name': 'convert_idea_kinetics_to_sbml_dfs',\n",
       "     'signature': 'napistu.ingestion.yeast.convert_idea_kinetics_to_sbml_dfs(idea_path:str)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.ingestion.yeast.convert_idea_kinetics_to_sbml_dfs',\n",
       "     'doc': 'Convert IDEA Kinetics to SBML DFs Format yeast induction regulator->target relationships as a directed graph. Parameters : idea_path – Path to the IDEA Kinetics file. Returns : an SBML_dfs object containing molecular species and their interactions.\\nKinetic attributes are included as reactions_data. Return type : SBML_dfs'},\n",
       "    'download_idea': {'name': 'download_idea',\n",
       "     'signature': 'napistu.ingestion.yeast.download_idea(output_dir:str)→None\\uf0c1',\n",
       "     'id': 'napistu.ingestion.yeast.download_idea',\n",
       "     'doc': ''}},\n",
       "   'classes': {}}},\n",
       " 'napistu.modify': {'constants': {'module': 'napistu.modify.constants',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.constants.html#module-napistu.modify.constants',\n",
       "   'functions': {},\n",
       "   'classes': {}},\n",
       "  'curation': {'module': 'napistu.modify.curation',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.curation.html#module-napistu.modify.curation',\n",
       "   'functions': {'_expand_entities_by_fks': {'name': '_expand_entities_by_fks',\n",
       "     'signature': 'napistu.modify.curation._expand_entities_by_fks(sbml_dfs:SBML_dfs,pk_dict:dict)→dict\\uf0c1',\n",
       "     'id': 'napistu.modify.curation._expand_entities_by_fks',\n",
       "     'doc': 'Expand Entities By Foreign Keys Starting with a dictionary of foreign keys, add all primary keys that are defined by these foreign keys Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model pk_dict: dict Dictionary where keys are types of primary keys in sbml_dfs returns : pk_dict – Input where additional primary keys may have been added rtype : dict'},\n",
       "    '_find_invalid_entities': {'name': '_find_invalid_entities',\n",
       "     'signature': 'napistu.modify.curation._find_invalid_entities(sbml_dfs:SBML_dfs,invalid_entities:DataFrame)→dict[str,set]\\uf0c1',\n",
       "     'id': 'napistu.modify.curation._find_invalid_entities',\n",
       "     'doc': 'Find Invalid Entities Based on a set of entity names or attributes, find each entities\\ncorresponding primary key Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model invalid_entities: pd.DataFrame A table containing entities to be removed (“remove”),\\nthe table where the entity resides (“table”) and variable used\\nto find the entity (“variable”) returns : invalid_entities_dict – A dictionary containing the primary keys of invalid entities rtype : dict'},\n",
       "    '_format_explicit_reaction_species': {'name': '_format_explicit_reaction_species',\n",
       "     'signature': 'napistu.modify.curation._format_explicit_reaction_species(curation_dict:dict[str,DataFrame])→DataFrame|None\\uf0c1',\n",
       "     'id': 'napistu.modify.curation._format_explicit_reaction_species',\n",
       "     'doc': 'Format reaction species which are deirectly defined among curated species.'},\n",
       "    '_format_implicit_reaction_species': {'name': '_format_implicit_reaction_species',\n",
       "     'signature': 'napistu.modify.curation._format_implicit_reaction_species(curation_dict:dict[str,DataFrame])→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.curation._format_implicit_reaction_species',\n",
       "     'doc': 'Construct reaction species which are defined in reactions’ stoichiometry.'},\n",
       "    '_remove_entities': {'name': '_remove_entities',\n",
       "     'signature': 'napistu.modify.curation._remove_entities(sbml_dfs:SBML_dfs,pk_dict:dict)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.modify.curation._remove_entities',\n",
       "     'doc': 'Remove Entities Remove entities whose primary keys are in pk_dict Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model pk_dict: dict Dictionary where keys are types of primary keys in sbml_dfs returns : sbml_dfs – Input with some entities removed rtype : sbml_dfs_core.SBML_dfs'},\n",
       "    'curate_sbml_dfs': {'name': 'curate_sbml_dfs',\n",
       "     'signature': 'napistu.modify.curation.curate_sbml_dfs(curation_dir:str,sbml_dfs:SBML_dfs,verbose:bool=True)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.modify.curation.curate_sbml_dfs',\n",
       "     'doc': 'Curate SBML_dfs Update a pathway model using manual annotations. The current workflow is to:\\n- annotate pathways in https://docs.google.com/spreadsheets/d/1waVXSVMOthL5QAT0PITgLMDdXGHIS50LZ2P1_F_c-6s/edit#gid=101210748 - parse annotations into flat files using parse_manual_annotation.Rmd\\n- call this function to format flat files and update a current SBML_dfs pathway model Params \\uf0c1 curation_dir: str Directory containing annotations generated using parse_manual_annotation.Rmd sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model verbose: bool Extra reporting returns : sbml_df – A curated pathway model rtype : sbml_dfs_core.SBML_dfs'},\n",
       "    'format_curated_entities': {'name': 'format_curated_entities',\n",
       "     'signature': \"napistu.modify.curation.format_curated_entities(entity_type:str,new_curated_entities:dict[Any,DataFrame],new_entities:dict[str,DataFrame],sbml_dfs:SBML_dfs,curation_id:str='Calicocurations')→DataFrame\\uf0c1\",\n",
       "     'id': 'napistu.modify.curation.format_curated_entities',\n",
       "     'doc': 'Format Curated Entities Convert entities from the curation format to the stucture of SBML_dfs tables Params \\uf0c1 entity_type: str The type of entity to update (e.g., reactions, species, …) new_curated_entities: dict Curation pd.DataFrames generated using read_pathway_curations new_entities: dict Curations formatted as sbml_dfs_core.SBML_dfs tables sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model curation_id: str Name to use as a pathway id in source.Source objects returns : new_entity_df – Input for entity_type formatted as an SBML_dfs table rtype : pd.DataFrame'},\n",
       "    'format_curations': {'name': 'format_curations',\n",
       "     'signature': 'napistu.modify.curation.format_curations(curation_dict:dict[str,DataFrame],sbml_dfs:SBML_dfs)→dict[str,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.curation.format_curations',\n",
       "     'doc': 'Format Curations Format manual curations into a set of table that can be appended to an sbml_dfs’s tables Params \\uf0c1 curation_dict: Curations imported using read_pathway_curations sbml_dfs: A pathway model returns : new_entities – Curations formatted as sbml_dfs_core.SBML_dfs tables rtype : dict'},\n",
       "    'read_pathway_curations': {'name': 'read_pathway_curations',\n",
       "     'signature': 'napistu.modify.curation.read_pathway_curations(curation_dir:str)→dict[str,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.curation.read_pathway_curations',\n",
       "     'doc': 'Read Pathway Curations Load curations that were prepared by parse_manual_annotations.Rmd Params \\uf0c1 curation_dir: str Directory containing annotations generated using parse_manual_annotation.Rmd returns : curations – Dictionary containing different types of annoations rtype : dict'}},\n",
       "   'classes': {}},\n",
       "  'gaps': {'module': 'napistu.modify.gaps',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.gaps.html#module-napistu.modify.gaps',\n",
       "   'functions': {'_add_new_exchange_cspecies': {'name': '_add_new_exchange_cspecies',\n",
       "     'signature': 'napistu.modify.gaps._add_new_exchange_cspecies(new_exchange_cspecies:set,sbml_dfs:SBML_dfs,exchange_compartment_id:str,exchange_compartment:str,gap_filling_source_obj:Source)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._add_new_exchange_cspecies',\n",
       "     'doc': 'Add new compartmentalized species to the exchange compartment. Parameters : new_exchange_cspecies ( set ) – Set of s_ids needing new compartmentalized species in the exchange compartment. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object exchange_compartment_id ( str ) – The compartment ID for the exchange compartment exchange_compartment ( str ) – The name of the exchange compartment gap_filling_source_obj ( source.Source ) – Source object for gap-filling Returns : DataFrame of new compartmentalized species to add. Return type : pd.DataFrame'},\n",
       "    '_build_transport_rxn_edgelist': {'name': '_build_transport_rxn_edgelist',\n",
       "     'signature': 'napistu.modify.gaps._build_transport_rxn_edgelist(updated_sbml_dfs:SBML_dfs,species_needing_transport_rxns:ndarray,exchange_compartment_id:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._build_transport_rxn_edgelist',\n",
       "     'doc': 'Build the edgelist for new transport reactions, ensuring only one reversible reaction per compartment pair. Parameters : updated_sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The updated SBML_dfs object species_needing_transport_rxns ( np.ndarray ) – Vector of molecular species (s_ids) with no or insufficient transportation reactions exchange_compartment_id ( str ) – The compartment ID for the exchange compartment Returns : Edgelist for new transport reactions. Return type : pd.DataFrame'},\n",
       "    '_create_new_reaction_species': {'name': '_create_new_reaction_species',\n",
       "     'signature': 'napistu.modify.gaps._create_new_reaction_species(transport_rxn_edgelist:DataFrame,sbml_dfs:SBML_dfs)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._create_new_reaction_species',\n",
       "     'doc': 'Create new reaction species DataFrame for gap-filling transport reactions. Parameters : transport_rxn_edgelist ( pd.DataFrame ) – Edgelist for new transport reactions. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object Returns : DataFrame of new reaction species to add. Return type : pd.DataFrame'},\n",
       "    '_create_new_reactions': {'name': '_create_new_reactions',\n",
       "     'signature': 'napistu.modify.gaps._create_new_reactions(transport_rxn_edgelist:DataFrame,sbml_dfs:SBML_dfs,gap_filling_id_obj:Identifiers,gap_filling_source_obj:Source)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._create_new_reactions',\n",
       "     'doc': 'Create new reactions DataFrame for gap-filling transport reactions. Parameters : transport_rxn_edgelist ( pd.DataFrame ) – Edgelist for new transport reactions. sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object gap_filling_id_obj ( identifiers.Identifiers ) – Identifiers object for gap-filling gap_filling_source_obj ( source.Source ) – Source object for gap-filling Returns : DataFrame of new reactions to add. Return type : pd.DataFrame'},\n",
       "    '_eval_existing_inter_cspecies_paths': {'name': '_eval_existing_inter_cspecies_paths',\n",
       "     'signature': 'napistu.modify.gaps._eval_existing_inter_cspecies_paths(comp_specs:DataFrame,existing_cspecies_paths:DataFrame)→dict\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._eval_existing_inter_cspecies_paths',\n",
       "     'doc': 'Evaluate whether paths between compartments found in _find_existing_inter_cspecies_paths cover all of the compartments where the protein exists. Parameters : comp_specs ( pd.DataFrame ) – Compartmentalized species for a single s_id existing_cspecies_paths ( pd.DataFrame ) – An edgelist of a from and to compartmentalized species and a label of the path connecting them. Returns : type: the status category the species falls in\\nmsg: an optional message describing the type Return type : dict'},\n",
       "    '_find_existing_inter_cspecies_paths': {'name': '_find_existing_inter_cspecies_paths',\n",
       "     'signature': 'napistu.modify.gaps._find_existing_inter_cspecies_paths(comp_specs:DataFrame,uniprot_id:str,directed_graph:Graph,partial_protein_cspecies:DataFrame)→DataFrame|None\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._find_existing_inter_cspecies_paths',\n",
       "     'doc': 'Find which compartments a protein exists in can be reached from one another by traversing a directed graph of reactions and molecular species including the protein. Parameters : comp_specs ( pd.DataFrame ) – Compartmentalized species for a single s_id uniprot_id ( str ) – The Uniprot ID for the protein of interest directed_graph ( ig.Graph ) – An igraph version of the sbml_dfs model partial_protein_cspecies ( pd.DataFrame ) – A table of proteins included in each species ID (this includes BQB_HAS_PART qualifiers in addition to the BQB_IS qualifiers which generally define distinct species Returns : An edgelist of a from and to compartmentalized species and a label of the path connecting them. Return type : pd.DataFrame or None'},\n",
       "    '_find_new_exchange_cspecies': {'name': '_find_new_exchange_cspecies',\n",
       "     'signature': 'napistu.modify.gaps._find_new_exchange_cspecies(species_needing_transport_rxns:ndarray,sbml_dfs:SBML_dfs,exchange_compartment_id:str)→set\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._find_new_exchange_cspecies',\n",
       "     'doc': 'Find species which need exchange reactions but are not currently present in the exchange compartment. Parameters : species_needing_transport_rxns ( np.ndarray ) – Vector of molecular species (s_ids) with no or insufficient transportation reactions sbml_dfs ( sbml_dfs_core.SBML_dfs ) – The SBML_dfs object exchange_compartment_id ( str ) – The compartment ID for the exchange compartment Returns : Set of s_ids needing new compartmentalized species in the exchange compartment. Return type : set'},\n",
       "    '_identify_species_needing_transport_reactions': {'name': '_identify_species_needing_transport_reactions',\n",
       "     'signature': 'napistu.modify.gaps._identify_species_needing_transport_reactions(sbml_dfs:SBML_dfs)→ndarray\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._identify_species_needing_transport_reactions',\n",
       "     'doc': 'Identify molecular species needing transport reactions so all of the compartments where it exists are connected. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic model containing a set of molecular species which exist\\nin multiple compartments and are interconverted by reactions Returns : Vector of molecular species (s_ids) with no or insufficient transportation reactions Return type : np.ndarray'},\n",
       "    '_log_protein_transport_gapfilling': {'name': '_log_protein_transport_gapfilling',\n",
       "     'signature': 'napistu.modify.gaps._log_protein_transport_gapfilling(species_transport_status_df:DataFrame)→None\\uf0c1',\n",
       "     'id': 'napistu.modify.gaps._log_protein_transport_gapfilling',\n",
       "     'doc': 'Log summary statistics and example messages for protein transport gapfilling. Parameters : species_transport_status_df ( pd.DataFrame ) – DataFrame summarizing transport status for each species'},\n",
       "    'add_transportation_reactions': {'name': 'add_transportation_reactions',\n",
       "     'signature': \"napistu.modify.gaps.add_transportation_reactions(sbml_dfs:SBML_dfs,exchange_compartment:str='cytosol')→SBML_dfs\\uf0c1\",\n",
       "     'id': 'napistu.modify.gaps.add_transportation_reactions',\n",
       "     'doc': 'Add transportation reactions to connect all forms of a protein across compartments. Identifies proteins whose various compartmentalized forms cannot reach one\\nanother via existing transportation reactions and then adds transportation\\nreactions which connect all forms of a protein. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic model containing a set of molecular species which exist\\nin multiple compartments and are interconverted by reactions. exchange_compartment ( str , optional ) – The name of an exchange compartment matching a c_name from sbml_dfs.compartments. Returns : The input sbml_dfs with additional transport reactions and compartmentalized species\\n(in the exchange compartment) added. Return type : sbml_dfs_core.SBML_dfs'},\n",
       "    'update_sbml_df_with_exchange': {'name': 'update_sbml_df_with_exchange',\n",
       "     'signature': \"napistu.modify.gaps.update_sbml_df_with_exchange(species_needing_transport_rxns:ndarray,sbml_dfs:SBML_dfs,exchange_compartment:str='cytosol')→SBML_dfs\\uf0c1\",\n",
       "     'id': 'napistu.modify.gaps.update_sbml_df_with_exchange',\n",
       "     'doc': 'Add transportation reactions between all locations of a set of molecular species by\\nincluding bidirectional exchange reactions through an exchange compartment. This function is modular and delegates to helper functions for each logical step:\\n- Finding new exchange compartmentalized species\\n- Adding new compartmentalized species\\n- Building the transport reaction edgelist\\n- Creating new reactions\\n- Creating new reaction species\\n- Updating and validating the sbml_dfs Parameters : species_needing_transport_rxns ( np.ndarray ) – Vector of molecular species (s_ids) with no or insufficient transportation reactions sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A mechanistic model containing a set of molecular species which exist\\nin multiple compartments and are interconverted by reactions exchange_compartment ( str , optional ) – The name of an exchange compartment matching a c_name from sbml_dfs.compartments Returns : The input sbml_dfs with additional transport reactions and compartmentalized species\\n(in the exchange compartment) added. Return type : sbml_dfs_core.SBML_dfs'}},\n",
       "   'classes': {}},\n",
       "  'pathwayannot': {'module': 'napistu.modify.pathwayannot',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.pathwayannot.html#module-napistu.modify.pathwayannot',\n",
       "   'functions': {'_add_complex_formation_compartmentalized_species': {'name': '_add_complex_formation_compartmentalized_species',\n",
       "     'signature': 'napistu.modify.pathwayannot._add_complex_formation_compartmentalized_species(sbml_dfs:SBML_dfs,merged_membership:DataFrame,new_species_for_sbml_dfs:DataFrame,complex_component_species_ids:DataFrame)→tuple[DataFrame,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot._add_complex_formation_compartmentalized_species',\n",
       "     'doc': 'Add Complex Formation - Compartmentalized Species Define all compartmentalized species in complexes and format newly created compartmentalized species Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network merged_membership ( pd.DataFrame ) – A table of complexes and their component members new_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.species complex_component_species_ids ( pd.DataFrame ) – All complex components Returns : new_compartmentalized_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.compartmentalized_species updated_compartmentalized_membership ( pd.DataFrame ) – Compartmentalized complex components with updated IDs'},\n",
       "    '_add_entity_sets_reactions': {'name': '_add_entity_sets_reactions',\n",
       "     'signature': 'napistu.modify.pathwayannot._add_entity_sets_reactions(sbml_dfs:SBML_dfs,new_compartmentalized_species_for_sbml_dfs:DataFrame,updated_compartmentalized_membership:DataFrame)→tuple[DataFrame,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot._add_entity_sets_reactions',\n",
       "     'doc': 'Add Entity Sets - Reactions Create reactions which indicate membership in an entity set Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network new_compartmentalized_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.compartmentalized_species updated_compartmentalized_membership ( pd.DataFrame ) – Compartmentalized complex components with updated IDs Returns : new_reactions_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.reactions new_reaction_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.reaction_species'},\n",
       "    '_add_entity_sets_species': {'name': '_add_entity_sets_species',\n",
       "     'signature': 'napistu.modify.pathwayannot._add_entity_sets_species(sbml_dfs:SBML_dfs,reactome_members:DataFrame)→tuple[DataFrame,DataFrame,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot._add_entity_sets_species',\n",
       "     'doc': 'Add Entity Sets - Species Define all species which are part of “entity sets” in the pathway Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network reactome_members ( pd.DataFrame ) – A table of all Reactome entity sets members - obtained using a Neo4j query Returns : merged_membership ( pd.DataFrame ) – A table of complexes and their component members new_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.species set_component_species_ids ( pd.DataFrame ) – All set components'},\n",
       "    '_merge_reactome_crossref_ids': {'name': '_merge_reactome_crossref_ids',\n",
       "     'signature': 'napistu.modify.pathwayannot._merge_reactome_crossref_ids(current_molecular_ids:DataFrame,select_reactome_ids:DataFrame)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot._merge_reactome_crossref_ids',\n",
       "     'doc': 'Merge Reactome CrossRef IDs Combine existing molecular IDs with Reactome crossref identifiers. Params \\uf0c1 current_molecular_ids: pd.DataFrame Molecular features in the current pathway model select_reactome_ids: pd.DataFrame Crossref identifiers produced by _format_reactome_crossref_ids() returns : merged_crossrefs – Molecular feature sids matched to crossref annotations rtype : pd.DataFrame'},\n",
       "    '_read_neo4j_members': {'name': '_read_neo4j_members',\n",
       "     'signature': 'napistu.modify.pathwayannot._read_neo4j_members(neo4j_members:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot._read_neo4j_members',\n",
       "     'doc': 'Read a table containing entity sets (members) derived from Reactome’s Neo4J database.'},\n",
       "    '_read_reactome_crossref_ids': {'name': '_read_reactome_crossref_ids',\n",
       "     'signature': 'napistu.modify.pathwayannot._read_reactome_crossref_ids(crossref_path:str)→DataFrame\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot._read_reactome_crossref_ids',\n",
       "     'doc': 'Format Reactome CrossRef IDs Read and reformat Reactome’s crossref identifiers Params \\uf0c1 crossref_path: str Path to the cross ref file extracted from Reactome’s Neo4j database returns : select_reactome_ids – Crossref identifiers rtype : pd.DataFrame'},\n",
       "    'add_complex_formation': {'name': 'add_complex_formation',\n",
       "     'signature': 'napistu.modify.pathwayannot.add_complex_formation(sbml_dfs:SBML_dfs)\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.add_complex_formation',\n",
       "     'doc': 'Add Complex Formation Using Reactome-style complex annotations,\\nwhere complex components are an attribute of complexes,\\nadd explicit complex formation reactions. Reactome represents complexers using BQB_HAS_PART\\nannotations, which are extracted into identifiers.Identifiers\\nobjects. This is sufficient to define membership but does\\nnot include stoichiometry. Also, in this approach components\\nare defined by their identifiers (URIs) rather than internal\\ns_ids/sc_ids.'},\n",
       "    'add_complex_formation_species': {'name': 'add_complex_formation_species',\n",
       "     'signature': 'napistu.modify.pathwayannot.add_complex_formation_species(sbml_dfs:SBML_dfs)→tuple[DataFrame,DataFrame,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.add_complex_formation_species',\n",
       "     'doc': 'Add Complex Formation - Species Define all species in complexes and format newly created species Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network Returns : merged_membership ( pd.DataFrame ) – A table of complexes and their component members new_species_for_sbml_dfs ( pd.DataFrame ) – New entries to add to sbml_dfs.species complex_component_species_ids ( pd.DataFrame ) – All complex components'},\n",
       "    'add_entity_sets': {'name': 'add_entity_sets',\n",
       "     'signature': 'napistu.modify.pathwayannot.add_entity_sets(sbml_dfs:SBML_dfs,neo4j_members:str)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.add_entity_sets',\n",
       "     'doc': 'Add Entity Sets Reactome represents some sets of interchangeable molecules as “entity sets”.\\nCommon examples are ligands for a receptor. This function add members\\nof each entity set as a “is a” style reaction. Parameters : sbml_dfs ( sbml_dfs_core.SBML_dfs ) – A relational mechanistic network neo4j_members ( str ) – Path to a table containing Reactome entity sets and corresponding members.\\nThis is currently extracted manually with Neo4j. Returns : sbml_dfs – An updated database which includes entity set species and formation reactions Return type : sbml_dfs_core.SBML_dfs'},\n",
       "    'add_reactome_identifiers': {'name': 'add_reactome_identifiers',\n",
       "     'signature': 'napistu.modify.pathwayannot.add_reactome_identifiers(sbml_dfs:SBML_dfs,crossref_path:str)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.add_reactome_identifiers',\n",
       "     'doc': 'Add Reactome Identifiers Add reactome-specific identifiers to existing species Params \\uf0c1 sbml_dfs: sbml_dfs_core.SBML_dfs A pathway model crossref_path: Path to the cross ref file extracted from Reactome’s Neo4j database returns : sbml_dfs – A pathway model with updated species’ identifiers rtype : sbml_dfs_core.SBML_dfs'},\n",
       "    'drop_cofactors': {'name': 'drop_cofactors',\n",
       "     'signature': 'napistu.modify.pathwayannot.drop_cofactors(sbml_dfs:SBML_dfs)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.drop_cofactors',\n",
       "     'doc': 'Drop Cofactors Remove reaction species when they are acting as cofactors Parameters: \\uf0c1 sbml_dfs: SBML_dfs A pathway model Returns: \\uf0c1 sbml_dfs (SBML_dfs): A pathway model with some reaction species filtered'},\n",
       "    'filter_one_reactions_cofactors': {'name': 'filter_one_reactions_cofactors',\n",
       "     'signature': 'napistu.modify.pathwayannot.filter_one_reactions_cofactors(one_rxns_species:DataFrame,filter_type:str,cofactor_filter:dict)→Series\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.filter_one_reactions_cofactors',\n",
       "     'doc': 'Filter One Reaction’s Cofactors Apply a cofactor filter to one reaction’s species Parameters: \\uf0c1 one_rxns_species (pd.DataFrame): Rows of reactions species containing cofactors filter_type: str Reason to filter species with this filter cofactor_filter: dict Species included in filter Returns: \\uf0c1 pd.Series with index of rsc_ids and values containing the reason why a reaction species is a cofactor, or None if filter was not triggered.'},\n",
       "    'identify_cofactors': {'name': 'identify_cofactors',\n",
       "     'signature': 'napistu.modify.pathwayannot.identify_cofactors(sbml_dfs:SBML_dfs)→Series\\uf0c1',\n",
       "     'id': 'napistu.modify.pathwayannot.identify_cofactors',\n",
       "     'doc': 'Identify Cofactors Find cofactors which are playing a supporting role in a reaction (e.g., ATP -> ADP or water). Parameters: \\uf0c1 sbml_dfs: SBML_dfs A pathway model Returns: \\uf0c1 pd.Series with index of rsc_ids and values containing the reason why a reaction species is a cofactor'}},\n",
       "   'classes': {}},\n",
       "  'uncompartmentalize': {'module': 'napistu.modify.uncompartmentalize',\n",
       "   'url': 'https://napistu.readthedocs.io/en/latest/generated/napistu.modify.uncompartmentalize.html#module-napistu.modify.uncompartmentalize',\n",
       "   'functions': {'_create_stubbed_index': {'name': '_create_stubbed_index',\n",
       "     'signature': 'napistu.modify.uncompartmentalize._create_stubbed_index()→PWIndex\\uf0c1',\n",
       "     'id': 'napistu.modify.uncompartmentalize._create_stubbed_index',\n",
       "     'doc': 'Create a default pathway index for the uncompartmentalized model.'},\n",
       "    '_create_stubbed_source': {'name': '_create_stubbed_source',\n",
       "     'signature': 'napistu.modify.uncompartmentalize._create_stubbed_source()→Source\\uf0c1',\n",
       "     'id': 'napistu.modify.uncompartmentalize._create_stubbed_source',\n",
       "     'doc': 'Create a default Source object for the uncompartmetnalized model.'},\n",
       "    '_filter_trivial_reactions': {'name': '_filter_trivial_reactions',\n",
       "     'signature': 'napistu.modify.uncompartmentalize._filter_trivial_reactions(rxn_consensus_species:pd.DataFrame,rxnspec_consensus_instances:pd.DataFrame)→tuple[pd.Dataframe,pd.DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.uncompartmentalize._filter_trivial_reactions',\n",
       "     'doc': 'Filter Trivial Reactions Filter reaction species which cancel out as substrates and products in the same reaction. Parameters : rxn_consensus_species ( pd.DataFrame ) – reactions rxnspec_consensus_instances ( pd.DataFrame ) – reaction species Returns : reactions with trivial reactions dropped\\nreaction_species (pd.DataFrame): reaction species with trivial reaction species dropped Return type : reactions (pd.DataFrame)'},\n",
       "    '_uncompartmentalize_cspecies': {'name': '_uncompartmentalize_cspecies',\n",
       "     'signature': 'napistu.modify.uncompartmentalize._uncompartmentalize_cspecies(sbml_dfs:sbml_dfs_core.SBML_dfs,stubbed_compartment:identifiers.Identifiers)→tuple[pd.Dataframe,pd.DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.uncompartmentalize._uncompartmentalize_cspecies',\n",
       "     'doc': 'Convert compartmetnalized species into uncompartmentalized ones.'},\n",
       "    '_uncompartmentalize_reactions': {'name': '_uncompartmentalize_reactions',\n",
       "     'signature': 'napistu.modify.uncompartmentalize._uncompartmentalize_reactions(sbml_dfs:SBML_dfs,compspec_lookup_table:Series)→tuple[DataFrame,DataFrame]\\uf0c1',\n",
       "     'id': 'napistu.modify.uncompartmentalize._uncompartmentalize_reactions',\n",
       "     'doc': 'Update reactions and reaction species to include uncompartmentalized species'},\n",
       "    'uncompartmentalize_sbml_dfs': {'name': 'uncompartmentalize_sbml_dfs',\n",
       "     'signature': 'napistu.modify.uncompartmentalize.uncompartmentalize_sbml_dfs(sbml_dfs:SBML_dfs)→SBML_dfs\\uf0c1',\n",
       "     'id': 'napistu.modify.uncompartmentalize.uncompartmentalize_sbml_dfs',\n",
       "     'doc': 'Uncompartmentalize SBML_dfs Take a compartmentalized mechanistic model and merge all of the compartments. Parameters : rxn_consensus_species ( pd.DataFrame ) – reactions rxnspec_consensus_instances ( pd.DataFrame ) – reaction species Returns : reactions with trivial reactions dropped\\nreaction_species (pd.DataFrame): reaction species with trivial reaction species dropped Return type : reactions (pd.DataFrame)'}},\n",
       "   'classes': {}}},\n",
       " 'napistu.rpy2': {}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtd_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "PACKAGE_DEFS = SimpleNamespace(\n",
    "    NAPISTU = \"napistu\",\n",
    ")\n",
    "package_name = \"napistu\"\n",
    "module_name = \"sbml_dfs_core\"\n",
    "if package_name is not PACKAGE_DEFS.NAPISTU:\n",
    "    package_name = f\"{PACKAGE_DEFS.NAPISTU}.{package_name}\"\n",
    "\n",
    "url = NAPISTU_PY_READTHEDOCS + \"/generated\" + modules_dict[package_name][module_name]\n",
    "css_selector = _create_module_css_selector(package_name=\"modify\", module_name=\"curation\", modules_dict=modules_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html = await documentation_utils.load_html_page(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag\n",
    "\n",
    "def extract_function_blocks(soup: BeautifulSoup) -> list[Tag]:\n",
    "    \"\"\"\n",
    "    Extract all function definition blocks (<dl class=\"py function\">) from the soup.\n",
    "    \"\"\"\n",
    "    return soup.find_all(\"dl\", class_=\"py function\")\n",
    "\n",
    "def extract_class_blocks(soup: BeautifulSoup) -> list[Tag]:\n",
    "    \"\"\"\n",
    "    Extract all class definition blocks (<dl class=\"py class\">) from the soup.\n",
    "    \"\"\"\n",
    "    return soup.find_all(\"dl\", class_=\"py class\")\n",
    "\n",
    "def parse_function_block(dl: Tag) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a <dl class=\"py function\"> block into a dict with name, signature, summary, and docstring.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    dt = dl.find(\"dt\")\n",
    "    if dt:\n",
    "        # Function name\n",
    "        name_span = dt.find(\"span\", class_=\"sig-name descname\")\n",
    "        result[\"name\"] = name_span.text if name_span else \"\"\n",
    "        # Signature\n",
    "        sig = dt.get_text(\" \", strip=True)\n",
    "        result[\"signature\"] = sig\n",
    "        # Doc URL (from id or headerlink)\n",
    "        result[\"doc_url\"] = \"#\" + dt.get(\"id\", \"\")\n",
    "    # Summary/Docstring\n",
    "    dd = dl.find(\"dd\")\n",
    "    if dd:\n",
    "        summary = dd.find(\"p\")\n",
    "        result[\"summary\"] = summary.text if summary else \"\"\n",
    "        # Optionally, get full docstring\n",
    "        result[\"docstring\"] = dd.get_text(\" \", strip=True)\n",
    "    return result\n",
    "\n",
    "def parse_class_block(dl: Tag) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a <dl class=\"py class\"> block into a dict with name, summary, and docstring.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    dt = dl.find(\"dt\")\n",
    "    if dt:\n",
    "        name_span = dt.find(\"span\", class_=\"sig-name descname\")\n",
    "        result[\"name\"] = name_span.text if name_span else \"\"\n",
    "        sig = dt.get_text(\" \", strip=True)\n",
    "        result[\"signature\"] = sig\n",
    "        result[\"doc_url\"] = \"#\" + dt.get(\"id\", \"\")\n",
    "    dd = dl.find(\"dd\")\n",
    "    if dd:\n",
    "        summary = dd.find(\"p\")\n",
    "        result[\"summary\"] = summary.text if summary else \"\"\n",
    "        result[\"docstring\"] = dd.get_text(\" \", strip=True)\n",
    "    return result\n",
    "\n",
    "def parse_rtd_module_page(html: str, url: str = None) -> dict:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    result = {\n",
    "        \"module\": None,\n",
    "        \"url\": url,\n",
    "        \"functions\": [],\n",
    "        \"classes\": []\n",
    "    }\n",
    "\n",
    "    # Get module name from <h1>\n",
    "    h1 = soup.find(\"h1\")\n",
    "    if h1:\n",
    "        # Remove headerlink icon if present\n",
    "        module_name = h1.get_text(strip=True).replace(\"\\uf0c1\", \"\").strip()\n",
    "        result[\"module\"] = module_name\n",
    "\n",
    "    # Parse top-level functions\n",
    "    for func_dl in soup.find_all(\"dl\", class_=\"py function\"):\n",
    "        func = {}\n",
    "        sig = func_dl.find(\"dt\")\n",
    "        if sig:\n",
    "            func[\"name\"] = sig.find(\"span\", class_=\"sig-name\").get_text(strip=True)\n",
    "            func[\"signature\"] = sig.get_text(strip=True)\n",
    "            func[\"id\"] = sig.get(\"id\")\n",
    "        doc = func_dl.find(\"dd\")\n",
    "        if doc:\n",
    "            func[\"doc\"] = doc.get_text(\" \", strip=True)\n",
    "        result[\"functions\"].append(func)\n",
    "\n",
    "    # Parse classes and their methods/attributes\n",
    "    for class_dl in soup.find_all(\"dl\", class_=\"py class\"):\n",
    "        cls = {\n",
    "            \"name\": None,\n",
    "            \"signature\": None,\n",
    "            \"id\": None,\n",
    "            \"doc\": None,\n",
    "            \"methods\": [],\n",
    "            \"attributes\": []\n",
    "        }\n",
    "        sig = class_dl.find(\"dt\")\n",
    "        if sig:\n",
    "            cls[\"name\"] = sig.find(\"span\", class_=\"sig-name\").get_text(strip=True)\n",
    "            cls[\"signature\"] = sig.get_text(strip=True)\n",
    "            cls[\"id\"] = sig.get(\"id\")\n",
    "        doc = class_dl.find(\"dd\")\n",
    "        if doc:\n",
    "            cls[\"doc\"] = doc.get_text(\" \", strip=True)\n",
    "            # Methods\n",
    "            for meth_dl in doc.find_all(\"dl\", class_=\"py method\"):\n",
    "                meth = {}\n",
    "                meth_sig = meth_dl.find(\"dt\")\n",
    "                if meth_sig:\n",
    "                    meth[\"name\"] = meth_sig.find(\"span\", class_=\"sig-name\").get_text(strip=True)\n",
    "                    meth[\"signature\"] = meth_sig.get_text(strip=True)\n",
    "                    meth[\"id\"] = meth_sig.get(\"id\")\n",
    "                meth_doc = meth_dl.find(\"dd\")\n",
    "                if meth_doc:\n",
    "                    meth[\"doc\"] = meth_doc.get_text(\" \", strip=True)\n",
    "                cls[\"methods\"].append(meth)\n",
    "            # Attributes\n",
    "            for attr_dl in doc.find_all(\"dl\", class_=\"py attribute\"):\n",
    "                attr = {}\n",
    "                attr_sig = attr_dl.find(\"dt\")\n",
    "                if attr_sig:\n",
    "                    attr[\"name\"] = attr_sig.find(\"span\", class_=\"sig-name\").get_text(strip=True)\n",
    "                    attr[\"signature\"] = attr_sig.get_text(strip=True)\n",
    "                    attr[\"id\"] = attr_sig.get(\"id\")\n",
    "                attr_doc = attr_dl.find(\"dd\")\n",
    "                if attr_doc:\n",
    "                    attr[\"doc\"] = attr_doc.get_text(\" \", strip=True)\n",
    "                cls[\"attributes\"].append(attr)\n",
    "        result[\"classes\"].append(cls)\n",
    "\n",
    "    return result\n",
    "\n",
    "x = parse_rtd_module_page(page_html)\n",
    "x[\"classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
